{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5aa21ad-6bb9-4990-ab4d-fb9435b0bc00",
   "metadata": {},
   "source": [
    "## Introducción a los sistemas de recomendación"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "815cecfb-6ed2-4522-a83d-29de9c4a8792",
   "metadata": {},
   "source": [
    "#### Sistemas de recomendación\n",
    "\n",
    "En este módulo consideraremos la aplicación de los _sistemas de recomendación_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e6e80a5-0f7b-4924-9d41-7c8305d304e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "# add pictures\n",
    "# this is pretty boring temporarily\n",
    "# make this one short"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b9ea003-8011-4799-a641-147e0e816cf4",
   "metadata": {},
   "source": [
    "#### Sistemas de recomendación\n",
    "\n",
    "Algunos ejemplos de sistemas de recomendación son\n",
    "\n",
    "- Recomendaciones de vídeo (por ejemplo, YouTube, Netflix)\n",
    "- Recomendaciones de compras en línea (por ejemplo, Amazon)\n",
    "- Cualquier otra recomendación de contenido que puedas encontrar, que esté personalizada para un usuario"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "651525e7-a5ea-47d8-8d33-c00d5e8abfce",
   "metadata": {},
   "source": [
    "#### Entorno de recomendación\n",
    "\n",
    "- En la configuración de un sistema de recomendación sencillo, sólo consideramos un paso de tiempo:\n",
    "  - ¿Qué debo recomendar a este usuario?\n",
    "- Podemos abordar esto con métodos de aprendizaje supervisado o no supervisado (por ejemplo, [filtrado colaborativo](https://en.wikipedia.org/wiki/Collaborative_filtering)\n",
    "- Sin embargo, en la realidad interactuamos con un usuario repetidamente a lo largo del tiempo.\n",
    "  - ¡Podemos abordar esto con RL!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea28cf7-7bfa-46a7-87f7-74cf3893d27d",
   "metadata": {},
   "source": [
    "#### Complejidades\n",
    "\n",
    "Los sistemas de recomendación son complejos en muchos, muchos aspectos. Por ejemplo:\n",
    "\n",
    "- Relaciones con los usuarios\n",
    "- Nuevos usuarios/artículos\n",
    "- Fuentes de datos\n",
    "- Tamaño de los datos\n",
    "- Recomendaciones de pizarra\n",
    "- **Estado de ánimo/concepto del usuario**\n",
    "\n",
    "Notas:\n",
    "\n",
    "- ¿Tratamos a los usuarios individualmente o aprendemos sobre los usuarios basándonos en otros usuarios?\n",
    "- ¿Cómo tratar a los nuevos usuarios o a los nuevos artículos (por ejemplo, programas de TV) que acaban de llegar?\n",
    "- ¿Qué fuentes de datos utilizamos para aprender sobre los usuarios, los artículos y sus interacciones?\n",
    "- ¿Cómo tratamos el enorme tamaño de los datos (potencialmente más de millones de usuarios/artículos)?\n",
    "- ¿Y si queremos recomendar varios artículos al mismo tiempo?\n",
    "- **¿Cómo tenemos en cuenta el estado de ánimo/la mentalidad del usuario y su evolución en el tiempo?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0af9012-7aec-423a-b272-703452bb39f7",
   "metadata": {},
   "source": [
    "#### Configuración del recomendador RL\n",
    "\n",
    "- Si tenemos 10 millones de artículos, el espacio de acción RL sería de 10 millones de opciones.\n",
    "- Esto es demasiado grande para ser factible.\n",
    "- Cuando utilicemos la RL para los recomendadores, usaremos algún otro método para preseleccionar algunos candidatos, y luego aplicaremos la RL \n",
    "- Por tanto, trabajaremos con un número reducido de candidatos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca012ec2-9ce1-4e98-92d0-bf239a4bcb13",
   "metadata": {},
   "source": [
    "#### Entrenamiento de RL\n",
    "\n",
    "- En este caso, el sistema real tiene a los humanos en el bucle (seleccionando entre los elementos recomendados).\n",
    "- Sin embargo, esto sería complejo, lento, caro y potencialmente haría malas recomendaciones.\n",
    "- Por tanto, como es habitual en RL, construiremos un _simulador_ (env).\n",
    "- Más adelante, también consideraremos el aprendizaje a partir de los datos del comportamiento del usuario cuando no se disponga de un simulador."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a065884d-1c9e-4815-985a-91f6faadf40e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### ¡Apliquemos lo que hemos aprendido!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eebcdd6-e039-4162-bb40-045879282931",
   "metadata": {},
   "source": [
    "## Beneficios de la RL para las recomendaciones\n",
    "<!-- multiple choice -->\n",
    "\n",
    "¿Cuál es la principal ventaja de utilizar la RL para un sistema de recomendación, en lugar de métodos más tradicionales como el filtrado colaborativo?\n",
    "\n",
    "- [ ] La RL es más escalable a grandes conjuntos de datos que el aprendizaje supervisado o no supervisado.\n",
    "- [ ] La RL nos permite trabajar con espacios de acción discretos, como la elección de qué elemento recomendar.\n",
    "- [ ] La RL nos permite tener en cuenta las recomendaciones secuenciales, en las que las recompensas dependen del historial de acciones.\n",
    "- [ ] La RL es la única opción cuando se trata de sistemas de recomendación."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "022719e4-f05f-4082-b434-0462ee1adc64",
   "metadata": {},
   "source": [
    "## Inconvenientes de la LR para las recomendaciones\n",
    "<!-- multiple choice -->\n",
    "\n",
    "¿Cuál es el inconveniente de utilizar la RL para un sistema de recomendación, en comparación con métodos más tradicionales como el filtrado colaborativo?\n",
    "\n",
    "- [ ] Los métodos supervisados y no supervisados no se han desarrollado a fondo para las aplicaciones de recomendación.\n",
    "- [x] La RL tiene dificultades para escalar a grandes espacios de acción. | Lo tienes.\n",
    "- [ ] La RL sólo se puede utilizar si se dispone de un simulador/evento. | Al final de este módulo, aprenderás otro enfoque\n",
    "- [| No hay software de código abierto de uso industrial para la RL. | Espera un momento... ¿qué pasa con RLlib?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74454c2d-e4ac-4dbf-88b5-b4a3a5d45ac0",
   "metadata": {},
   "source": [
    "## Dificultad de los sistemas de recomendación\n",
    "<!-- multiple choice -->\n",
    "\n",
    "Verdadero o falso: los sistemas de recomendación son un dominio fácil de resolver, sin demasiadas complejidades.\n",
    "\n",
    "- [ ] Verdadero\n",
    "- [x] ¡Falso!\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ray200]",
   "language": "python",
   "name": "conda-env-ray200-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
