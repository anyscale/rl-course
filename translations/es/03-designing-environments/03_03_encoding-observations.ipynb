{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e23df55-837b-4ec9-86ad-3b60c6a7f00d",
   "metadata": {},
   "source": [
    "## Observaciones de codificaci贸n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58bc4b75-8b99-4450-9b25-6af748253913",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HIDDEN\n",
    "import ray\n",
    "import logging\n",
    "ray.init(log_to_driver=False, ignore_reinit_error=True, logging_level=logging.ERROR); # logging.FATAL\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d95a9faf-9b2c-45ec-a347-3aadca399516",
   "metadata": {},
   "source": [
    "#### Revisi贸n: 驴qu茅 es una pol铆tica?\n",
    "\n",
    "- En RL intentamos aprender una pol铆tica, 驴qu茅 es esto exactamente?\n",
    "- Una pol铆tica asigna **observaciones** a **acciones**.\n",
    "- En otras palabras, las observaciones son todo lo que la pol铆tica \"ve\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cacebed5-729c-4ea8-8570-3ac70481723b",
   "metadata": {},
   "source": [
    "#### Pol铆ticas del lago aleatorio\n",
    "\n",
    "- 驴Qu茅 son las observaciones del lago aleatorio?\n",
    "- Son la ubicaci贸n del jugador, representada como un n煤mero entero de 0 a 15  \n",
    "- Como repaso del m贸dulo 1, una pol铆tica determinista podr铆a tener este aspecto\n",
    "\n",
    "| Observaci贸n | Acci贸n |\n",
    "|------|-------|\n",
    "| 0 | 0 |\n",
    "| 1 | 3 |\n",
    "| 2 | 1 |\n",
    "| 3 | 1 |\n",
    "| ... | ... |\n",
    "| 14 | 2 |\n",
    "| 15 | 2 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c0d4278-ce03-4e94-9f2a-667b88bf1e85",
   "metadata": {},
   "source": [
    "#### Pol铆ticas del lago aleatorio\n",
    "\n",
    "Y una pol铆tica no determinista podr铆a tener el siguiente aspecto\n",
    "\n",
    "| Observaci贸n | P(izquierda) | P(abajo) | P(derecha) | P(arriba) \n",
    "|------------|-------|-----------|---------|-------|\n",
    "| 0 | 0 | 0.9 | 0.01 | 0.04 | 0.05\n",
    "| 1 | 3 | 0.05 | 0.05 | 0.05 | 0.85\n",
    "| ... | ... | ... | ...      | ...      | ...\n",
    "| 15 | 2 | 0.0 | 0.0 | 0.99 | 0.01\n",
    "\n",
    "Por cierto, esto no significa que RLlib aprenda esa tabla, pero podemos pensar en ella conceptualmente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b044dbcb-f7a2-4792-aaf2-2c72bda18af2",
   "metadata": {},
   "source": [
    "#### Pol铆ticas del lago aleatorio\n",
    "\n",
    "- En el lago aleatorio, toda nuestra decisi贸n debe basarse en la posici贸n del jugador.\n",
    "- A veces esto es suficiente: desde la posici贸n 11, debes bajar.\n",
    "\n",
    "```\n",
    " 0 1 2 3\n",
    " 4 5 6 7\n",
    " 8 9 10 11\n",
    "12 13 14 15\n",
    "```\n",
    "\n",
    "- Pero 驴qu茅 pasa con la posici贸n 5, qu茅 debes hacer a partir de ah铆?\n",
    "- Respuesta: _depende_. Si hay un agujero en la posici贸n 9, no querr谩s bajar. Lo mismo ocurre con la 6 \n",
    "- 驴C贸mo puedo decidir _sin saber d贸nde est谩n los agujeros_?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fac00c2-6d9b-442f-ad3c-f9212a0dffac",
   "metadata": {},
   "source": [
    "#### Estado contra observaci贸n, un resumen\n",
    "\n",
    "- En el M贸dulo 1, definimos informalmente el estado como todo lo relacionado con el entorno.\n",
    "- Aqu铆, eso incluir铆a la ubicaci贸n del jugador y los agujeros.\n",
    "- La observaci贸n, en cambio, s贸lo codifica una parte del estado: en este caso, la ubicaci贸n del jugador."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afbe12b1-eded-4618-a5dc-77dfd9fb75a0",
   "metadata": {},
   "source": [
    "#### 驴Observaci贸n = estado? Problema 1.\n",
    "\n",
    "- Entonces, 驴por qu茅 no establecer la observaci贸n en el estado? \n",
    "- Aqu铆 hay dos problemas.\n",
    "- Problema 1: cuando se despliega el sistema de RL, es posible que no se conozca todo el estado.\n",
    "  - Ejemplo: en un sistema de recomendaci贸n, el agente (recomendador) no tiene acceso al estado de 谩nimo del usuario (parte del estado que afecta a los resultados)\n",
    "  - En el aprendizaje supervisado, no queremos entrenar sobre caracter铆sticas a las que no tendremos acceso en el despliegue\n",
    "    - Del mismo modo, aqu铆 la observaci贸n tiene que ser algo a lo que podamos acceder en el despliegue."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "617197ea-fcfe-457e-a567-a1f876b0bb86",
   "metadata": {},
   "source": [
    "#### 驴Observaci贸n = estado? Problema 2.\n",
    "\n",
    "- Problema 2: Puede ser dif铆cil generalizar a partir de una observaci贸n realmente compleja.\n",
    "  - Hay cientos de miles de estados posibles s贸lo en este peque帽o juego de lago aleatorio de 4x4.\n",
    "  - Demasiada informaci贸n podr铆a ser confusa para el agente o podr铆a requerir cantidades irrazonables de datos (simulaciones) para darle sentido."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b6e363c-9255-442c-a598-1d33199b317b",
   "metadata": {},
   "source": [
    "#### Observaciones sobre la codificaci贸n\n",
    "\n",
    "- Parte de nuestro trabajo como practicante de RL es elegir una representaci贸n (o codificaci贸n) para la observaci贸n.\n",
    "- A partir de la informaci贸n que el jugador permiti贸 conocer, encontrar una representaci贸n 煤til de lo que el jugador necesita saber.\n",
    "- En nuestro caso, probaremos una aproximaci贸n: el jugador consigue \"ver\" si los 4 espacios adyacentes son agujeros o no.\n",
    "- Codificaremos esto como 4 n煤meros binarios."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb9fb21-9ad8-4800-ab56-fc70eec7b5ec",
   "metadata": {},
   "source": [
    "#### Observaciones sobre la codificaci贸n\n",
    "\n",
    "```\n",
    ".OO.\n",
    "....\n",
    "O.P.\n",
    "...G\n",
    "```\n",
    "\n",
    "- En esta situaci贸n, no hay agujeros alrededor del jugador, por lo que el jugador \"ve\" `[0 0 0]` \n",
    "- En otras palabras, la observaci贸n aqu铆 es `[0 0 0 0]`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a2fb46-4e64-47d7-9a3c-2af76319760c",
   "metadata": {},
   "source": [
    "#### Observaciones sobre la codificaci贸n\n",
    "\n",
    "```\n",
    ".OO.\n",
    "..P.\n",
    "O.O.\n",
    "...G\n",
    "```\n",
    "\n",
    "- Aqu铆, el jugador \"ve\" agujeros arriba y abajo, por lo que la observaci贸n es `[0 1 0 1]` (izquierda, abajo, derecha, arriba)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "114c2ad7-dc3d-45c8-9f59-46e55fd87e07",
   "metadata": {},
   "source": [
    "#### Observaciones sobre la codificaci贸n\n",
    "\n",
    "驴Qu茅 pasa con las aristas?\n",
    "\n",
    "```\n",
    "....\n",
    "..OP\n",
    "O.OO\n",
    "...G\n",
    "```\n",
    "\n",
    "- Esta es nuestra elecci贸n al dise帽ar el espacio de observaci贸n.\n",
    "- Elegir茅 representar \"fuera de la red\" como agujeros, lo que significa que fingimos que el lago tiene este aspecto:\n",
    " \n",
    "```\n",
    "OOOOOO\n",
    "O....O\n",
    "O..OPO\n",
    "OO.OOO\n",
    "O...GO\n",
    "OOOOOO\n",
    "```\n",
    "\n",
    "- Aqu铆, el jugador ve agujeros a la izquierda, abajo y derecha, por lo que la observaci贸n es `[1 1 1 0]` (izquierda, abajo, derecha, arriba)\n",
    "- Sin embargo, puede haber enfoques mejores, porque caer en un agujero es peor (el episodio termina) que caminar por el borde (no pasa nada)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "415a2223-64cb-43ca-befb-2269d33f9639",
   "metadata": {},
   "source": [
    "#### Codificar nuestras observaciones\n",
    "\n",
    "- Ahora que tenemos un plan, 驴c贸mo modificamos el c贸digo?\n",
    "- Como hemos estructurado nuestra clase para que tenga un m茅todo de `observaci贸n`, eso es todo lo que tenemos que modificar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6046cff0-b83f-45b8-96ca-ab092b3c8599",
   "metadata": {},
   "outputs": [],
   "source": [
    "from envs_03 import RandomLake\n",
    "\n",
    "class RandomLakeObs(RandomLake):\n",
    "    def observation(self):\n",
    "        i, j = self.player\n",
    "\n",
    "        obs = []\n",
    "        obs.append(1 if j==0 else self.holes[i,j-1]) # left\n",
    "        obs.append(1 if i==3 else self.holes[i+1,j]) # down\n",
    "        obs.append(1 if j==3 else self.holes[i,j+1]) # right\n",
    "        obs.append(1 if i==0 else self.holes[i-1,j]) # up\n",
    "        \n",
    "        obs = np.array(obs, dtype=int) # cast to numpy array (optional)\n",
    "        return obs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ee30d8-f9f9-4655-817d-84aebd8ca444",
   "metadata": {},
   "source": [
    "- El c贸digo crea una variable `obs` en la que cada entrada es 1 si esa direcci贸n sale de la arista **o** hay un agujero en ella."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88f95238-ed09-4582-ab28-b9a85b48d992",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HIDDEN\n",
    "import gym"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53303bf5-5453-4798-92f3-618bb2774151",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Codificar nuestras observaciones\n",
    "\n",
    "- Es necesario un cambio m谩s en el c贸digo, que es el constructor donde se define el espacio de observaci贸n.\n",
    "- Nuestras observaciones eran antes un n煤mero entero de 0 a 15, por lo que utilizamos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0b2ebd3-1775-4bdf-9c93-c5af274dbc08",
   "metadata": {},
   "outputs": [],
   "source": [
    "observation_space = gym.spaces.Discrete(16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "459308c9-a85a-4fcb-a8da-02a91401113f",
   "metadata": {},
   "source": [
    "Y lo mismo para las acciones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3cc9d30-715e-40a6-baa4-03496e91f9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "action_space = gym.spaces.Discrete(4)      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53434076-3bb8-4fd1-9e8e-e23eb2be2808",
   "metadata": {},
   "source": [
    "- Sin embargo, nuestras observaciones son ahora matrices de 4 n煤meros en lugar de un 煤nico n煤mero.\n",
    "- Para indicarlo, utilizamos `gym.spaces.MultiDiscrete` en lugar de `gym.spaces.Discrete`.\n",
    "- Multi, porque tenemos varios n煤meros, pero sigue siendo discreto, porque cada uno de los 4 n煤meros s贸lo puede tomar 2 valores posibles (0 贸 1).\n",
    "- Este es el c贸digo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b119b15e-4d45-4087-8895-0ef3c694f62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomLakeObs(RandomLake):\n",
    "    def __init__(self, env_config=None):\n",
    "        self.observation_space = gym.spaces.MultiDiscrete([2,2,2,2])\n",
    "        self.action_space = gym.spaces.Discrete(4)      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47022e95-090c-494b-955e-7e4ccadf088e",
   "metadata": {},
   "source": [
    "(Ten en cuenta que `gym` tambi茅n tiene un tipo de espacio `MultiBinario`, pero actualmente no es compatible con RLlib)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f5ebb5-6a8a-448e-a692-335ae56f4377",
   "metadata": {},
   "source": [
    "#### Probando nuestro nuevo entorno\n",
    "\n",
    "隆Vamos a probarlo!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "466d94ac-5b1b-4ce5-96ec-2b99b6849c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HIDDEN\n",
    "import numpy as np\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "afccc03d-e0f8-4b8b-9be7-d13aad969084",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 1])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from envs_03 import RandomLakeObs\n",
    "\n",
    "env = RandomLakeObs()\n",
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "de7de150-479c-4a5c-98cf-4adf0abd378b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "仇仇仇\n",
      "仇\n",
      "斥筹\n"
     ]
    }
   ],
   "source": [
    "env.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b6f296-1805-4467-8b34-fd61ebcdd732",
   "metadata": {},
   "source": [
    "Aqu铆, vemos la observaci贸n esperada que indica \"agujeros\" a la izquierda, abajo y arriba.\n",
    "\n",
    "Notas \n",
    "\n",
    "La izquierda y el arriba son los bordes del mapa, y el abajo es un agujero real."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef2d1ac-4700-4dee-8aeb-23d09f18414f",
   "metadata": {},
   "source": [
    "#### Probando nuestro nuevo entorno\n",
    "\n",
    "Intentemos dar un paso a la derecha:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "db75ac7f-c4db-4e2e-8dbb-734fb0ff4ae5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 0, 1]), 0, False, {'player': (0, 1), 'goal': (3, 3)})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.step(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "24287850-3c51-469c-86cd-17f2faa8cf3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "仇仇仇\n",
      "仇\n",
      "斥筹\n"
     ]
    }
   ],
   "source": [
    "env.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5bac1dc-f61f-41c5-85d5-095f880079e8",
   "metadata": {},
   "source": [
    "Ahora vemos agujeros en las direcciones descendente y ascendente, de nuevo como se esperaba."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3483468e-5524-4e8b-912e-ed2ab4e5a1ba",
   "metadata": {},
   "source": [
    "#### Formaci贸n con nuestras nuevas observaciones\n",
    "\n",
    "- Nuestras nuevas observaciones parecen funcionar, pero 驴ayudan al agente a aprender?\n",
    "- Recordemos que con nuestro espacio de observaci贸n `Discreto(16)` no pudimos conseguir mucho m谩s que un 30% de 茅xito.\n",
    "- Intent茅moslo de nuevo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "83267540-3d6c-43a1-a834-9fb258d0dd7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HIDDEN\n",
    "from utils_03 import lake_default_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "232e7a87-3c60-4ef3-91eb-e3b26db1e257",
   "metadata": {},
   "outputs": [],
   "source": [
    "ppo = lake_default_config.build(env=RandomLakeObs)\n",
    "\n",
    "for i in range(8):\n",
    "    ppo.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ea82a7de-3556-4f7a-9e78-78ef708e3b2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6420454545454546"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ppo.evaluate()[\"evaluation\"][\"episode_reward_mean\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c7214d-f48c-4f13-8bb1-a6de0fb92411",
   "metadata": {},
   "source": [
    "- 隆Esto es mucho mejor que el ~30% que obten铆amos antes!\n",
    "- Lo cual tiene sentido... nuestro agente puede \"ver\" los agujeros ahora, en lugar de caminar a ciegas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86425828-0bef-4b47-ad0e-29d8afaf465d",
   "metadata": {},
   "source": [
    "#### 隆Apliquemos lo que hemos aprendido!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4842178d-aa77-46b2-9da3-7deaea3d40f9",
   "metadata": {},
   "source": [
    "## Analog铆a del aprendizaje supervisado: espacio de observaci贸n\n",
    "<!-- multiple choice -->\n",
    "\n",
    "En las diapositivas hemos cambiado el espacio de observaci贸n de nuestro agente y, como resultado, hemos conseguido mayores recompensas. 驴A qu茅 aspecto del proceso de aprendizaje supervisado es m谩s an谩logo?\n",
    "\n",
    "- [x] Ingenier铆a de caracter铆sticas | 隆Ya lo tienes! Nuestro espacio de observaci贸n act煤a como el espacio de caracter铆sticas sobre el que act煤a nuestra pol铆tica.\n",
    "- [ ] Selecci贸n de modelos | No del todo. Pero, como veremos, 隆la selecci贸n de modelos tambi茅n tiene cabida en la RL!\n",
    "- [Ajuste de los hiperpar谩metros: no es as铆. Pero, como veremos, 隆el ajuste de hiperpar谩metros tambi茅n tiene cabida en la RL!\n",
    "- [ ] Selecci贸n de una funci贸n de p茅rdida"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6438bf5-8970-4b51-a1b4-011f067d8903",
   "metadata": {},
   "source": [
    "## Incluyendo la ubicaci贸n del jugador\n",
    "<!-- multiple choice -->\n",
    "\n",
    "En nuestra nueva representaci贸n de la observaci贸n, en realidad _eliminamos_ la ubicaci贸n del jugador de la observaci贸n y _s贸lo_ incluimos la presencia de los agujeros cercanos. Si quisi茅ramos un espacio de observaci贸n que incluyera tanto las paredes cercanas _como_ la ubicaci贸n del jugador, 驴cu谩l de los siguientes espacios de gimnasio podr铆amos utilizar?\n",
    "\n",
    "- [ ] `gimnasio.espacios.Discreto(5)` | 隆Int茅ntalo de nuevo!\n",
    "- [x] `gimnasio.espacios.MultiDiscreto([2,2,2,2,16])` | 隆S铆! Los 4 primeros n煤meros representan los agujeros, y el 煤ltimo n煤mero representa la ubicaci贸n del jugador.\n",
    "- [ ] `gimnasio.espacios.MultiDiscreto([2,2,2,2]) + gimnasio.espacios.Discreto(16)` | Int茅ntalo de nuevo; lamentablemente no podemos a帽adir espacios de gimnasio.\n",
    "- [ ] `gimnasio.espacios.MultiDiscreto([32,32,32,32])` | Esto podr铆a funcionar, pero es una representaci贸n confusa/redundante."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c03e0f1b-e397-467a-8f62-8537173201c9",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Manejo de los bordes\n",
    "<!-- multiple choice -->\n",
    "\n",
    "En las diapositivas hemos decidido tratar las aristas como agujeros. Recuerda esta imagen:\n",
    "\n",
    "```\n",
    "OOOOOO\n",
    "O....O\n",
    "O..OPO\n",
    "OO.OOO\n",
    "O...GO\n",
    "OOOOOO\n",
    "```\n",
    "\n",
    "Sin embargo, los bordes y los agujeros son en realidad diferentes entre s铆: entrar en un borde no hace nada, mientras que entrar en un agujero hace que el episodio termine. sta podr铆a ser una distinci贸n importante, especialmente en una versi贸n \"resbaladiza\" del entorno, en la que los resultados de las acciones no son deterministas \n",
    "\n",
    "Para abordar esta cuesti贸n, decidimos cambiar el espacio de observaci贸n. El agente sigue \"viendo\" s贸lo los cuatro cuadrados que le rodean, pero ahora ve si cada cuadrado es un espacio vac铆o, un agujero o un borde. Para esta representaci贸n, 驴cu谩l de los siguientes espacios de observaci贸n del gimnasio podr铆amos utilizar?\n",
    "\n",
    "- [ ] `gimnasio.espacios.MultiDiscreto([2,2,2,2,2,2,2,2])` | Int茅ntalo de nuevo. Recuerda que el agente sigue \"viendo\" s贸lo 4 casillas.\n",
    "- [ ] `gym.spaces.MultiDiscrete([3,3,3,3,3,3,3,3])` | 隆Int茅ntalo de nuevo!\n",
    "- [ ] `gimnasio.espacios.MultiDiscreto([2,2,2,2])` | Esto es lo mismo que el espacio anterior, pero hemos hecho un cambio.\n",
    "- [x] `gimnasio.espacios.MultiDiscreto([3,3,3,3])` | 隆Ya lo tienes! Ahora hay 3 opciones posibles para lo que el agente puede \"ver\" en cada casilla."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "485875e4-6694-4330-838c-1a54ed0499de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO / note to self\n",
    "# query_policy(trainer, RandomLakeObs(), [1,1,1,1])\n",
    "# shows that it wants to go up. this is because the above \"hole\" is probably an edge based on its learning. fascinating."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c89bbb1-d5b4-41ef-bdd9-1f9ef08aa1eb",
   "metadata": {},
   "source": [
    "## Implementaci贸n de los bordes\n",
    "<!-- coding exercise -->\n",
    "\n",
    "El c贸digo siguiente muestra la funci贸n \"observaci贸n\" para el espacio de observaci贸n actual. Modifica el c贸digo para que utilice el nuevo espacio de observaci贸n, en el que 0 representa un espacio vac铆o, 1 representa un agujero y 2 representa una arista "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "87cf9e9c-550c-43cb-8725-aa60d0cb91ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "仇仇仇\n",
      "仇\n",
      "斥筹\n",
      "[1 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "# EXERCISE\n",
    "\n",
    "from envs_03 import RandomLake\n",
    "\n",
    "class RandomLakeObs2(RandomLakeObs):\n",
    "    def observation(self):\n",
    "        i, j = self.player\n",
    "\n",
    "        obs = []\n",
    "        obs.append(1 if j==0 else self.holes[i,j-1]) # left\n",
    "        obs.append(1 if i==3 else self.holes[i+1,j]) # down\n",
    "        obs.append(1 if j==3 else self.holes[i,j+1]) # right\n",
    "        obs.append(1 if i==0 else self.holes[i-1,j]) # up\n",
    "        \n",
    "        obs = np.array(obs, dtype=int) # cast to numpy array\n",
    "        return obs\n",
    "\n",
    "np.random.seed(42)\n",
    "env = RandomLakeObs2()\n",
    "obs = env.reset()\n",
    "env.render()\n",
    "print(obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "06328a38-f19c-4c71-82b6-31e056f28f94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "仇仇仇\n",
      "仇\n",
      "斥筹\n",
      "[2 1 0 2]\n"
     ]
    }
   ],
   "source": [
    "# SOLUTION\n",
    "\n",
    "from envs_03 import RandomLake\n",
    "\n",
    "class RandomLakeObs2(RandomLakeObs):\n",
    "    def observation(self):\n",
    "        i, j = self.player\n",
    "\n",
    "        obs = []\n",
    "        obs.append(2 if j==0 else self.holes[i,j-1]) # left\n",
    "        obs.append(2 if i==3 else self.holes[i+1,j]) # down\n",
    "        obs.append(2 if j==3 else self.holes[i,j+1]) # right\n",
    "        obs.append(2 if i==0 else self.holes[i-1,j]) # up\n",
    "        \n",
    "        obs = np.array(obs, dtype=int) # cast to numpy array\n",
    "        return obs\n",
    "\n",
    "np.random.seed(42)\n",
    "env = RandomLakeObs2()\n",
    "obs = env.reset()\n",
    "env.render()\n",
    "print(obs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a0f55b9-a660-4a04-8caf-52d13ced50e3",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Lo que ve el agente\n",
    "<!-- coding exercise -->\n",
    "\n",
    "Con nuestra nueva codificaci贸n del espacio de observaci贸n, el agente s贸lo \"ve\" los 4 espacios que le rodean y s贸lo dispone de esta informaci贸n para tomar sus decisiones. La celda de c贸digo siguiente crea una representaci贸n de lo que el agente \"ve\" mientras navega por el lago aleatorio. Puedes introducir acciones con el teclado escribiendo las palabras \"izquierda\", \"abajo\", \"derecha\" o \"arriba\" (o \"l\", \"d\", \"r\", \"u\" para abreviar) y la simulaci贸n te mostrar谩 el resultado. (Escribe \"quit\" para salir.) Juega hasta que llegues a la meta. A medida que avanzas, intenta trazar un mapa del lago (quiz谩s dibujando en un papel)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5d5b24c4-0df7-47e3-8155-895ccbb9e5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO / NOTE:\n",
    "# THIS EXERCISE DOES NOT HAVE A \"solution\"\n",
    "# the code is here ONLY to help them answer the multiple choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8341e39f-8684-4106-94cc-a4a422f476b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observation:\n",
      ".O.\n",
      "OP.\n",
      "...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# EXERCISE\n",
    "\n",
    "import numpy as np\n",
    "from envs_03 import RandomLakeObs\n",
    "\n",
    "actions = {\"left\" : 0, \"down\" : 1, \"right\" : 2, \"up\" : 3, \n",
    "           \"l\" : 0, \"d\" : 1, \"r\" : 2, \"u\" : 3}\n",
    "\n",
    "np.random.seed(45)\n",
    "env = RandomLakeObs()\n",
    "obs = env.reset()\n",
    "\n",
    "act = \"start\"\n",
    "done = False\n",
    "\n",
    "while not done:\n",
    "   \n",
    "    obs_print = [['.']*3 for i in range(3)]\n",
    "    obs_print[1][1] = \"P\"\n",
    "    if obs[0]:\n",
    "        obs_print[1][0] = \"O\"\n",
    "    if obs[1]:\n",
    "        obs_print[2][1] = \"O\"\n",
    "    if obs[2]:\n",
    "        obs_print[1][2] = \"O\"\n",
    "    if obs[3]:\n",
    "        obs_print[0][1] = \"O\"\n",
    "    print(\"Observation:\")\n",
    "    print(\"\\n\".join(list(map(lambda c: \"\".join(c), obs_print))))\n",
    "    print()\n",
    "    \n",
    "    while act != \"quit\" and act not in actions: \n",
    "        act = input() # gather keyboard input \n",
    "    \n",
    "    if act == \"quit\":\n",
    "        break\n",
    "        \n",
    "    obs, rew, done, _ = env.step(act)\n",
    "    \n",
    "if done:\n",
    "    if rew > 0:\n",
    "        print(\"You win! +1 reward \")\n",
    "    else:\n",
    "        print(\"You fell into the lake \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c8469b-8040-44db-82cd-174ca76b82c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION\n",
    "\n",
    "import numpy as np\n",
    "from envs_03 import RandomLakeObs\n",
    "\n",
    "actions = {\"left\" : 0, \"down\" : 1, \"right\" : 2, \"up\" : 3, \n",
    "           \"l\" : 0, \"d\" : 1, \"r\" : 2, \"u\" : 3}\n",
    "\n",
    "np.random.seed(45)\n",
    "env = RandomLakeObs()\n",
    "obs = env.reset()\n",
    "\n",
    "act = \"start\"\n",
    "done = False\n",
    "\n",
    "while not done:\n",
    "   \n",
    "    obs_print = [['.']*3 for i in range(3)]\n",
    "    obs_print[1][1] = \"P\"\n",
    "    if obs[0]:\n",
    "        obs_print[1][0] = \"O\"\n",
    "    if obs[1]:\n",
    "        obs_print[2][1] = \"O\"\n",
    "    if obs[2]:\n",
    "        obs_print[1][2] = \"O\"\n",
    "    if obs[3]:\n",
    "        obs_print[0][1] = \"O\"\n",
    "    print(\"Observation:\")\n",
    "    print(\"\\n\".join(list(map(lambda c: \"\".join(c), obs_print))))\n",
    "    print()\n",
    "    \n",
    "    while act != \"quit\" and act not in actions: \n",
    "        act = input() # gather keyboard input \n",
    "    \n",
    "    if act == \"quit\":\n",
    "        break\n",
    "        \n",
    "    obs, rew, done, _ = env.step(act)\n",
    "    \n",
    "if done:\n",
    "    if rew > 0:\n",
    "        print(\"You win! +1 reward \")\n",
    "    else:\n",
    "        print(\"You fell into the lake \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7024e752-4e71-4162-886e-c5be693c9ee5",
   "metadata": {},
   "source": [
    "#### 驴Qu茅 aspecto tiene el lago?\n",
    "\n",
    "Bas谩ndote en tus exploraciones, 驴cu谩l es el mapa correcto del lago en la pregunta anterior?\n",
    "\n",
    "```\n",
    " (A) (B) (C) (D)\n",
    "P..O P.OO P..O P.OO\n",
    "..OO .OOO ..OO .OOO\n",
    "O...     O...     O...     O..O\n",
    "...G ...G ..OG ...G\n",
    "```\n",
    "\n",
    "- [x] (A)\n",
    "- [ ] (B)\n",
    "- [ ] (C)\n",
    "- [ ] (D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbad4252-94ef-480a-938d-6e4858ed3675",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "# could also considering showing a BAD environment encoding to contrast with this reasonable one, as in the next slide deck!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ray200]",
   "language": "python",
   "name": "conda-env-ray200-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
