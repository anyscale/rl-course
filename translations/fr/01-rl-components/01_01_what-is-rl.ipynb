{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5aa21ad-6bb9-4990-ab4d-fb9435b0bc00",
   "metadata": {},
   "source": [
    "## Apprentissage supervisé vs apprentissage par renforcement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "281ff2e0-a58c-46a3-8250-aa0002f2ad9f",
   "metadata": {},
   "source": [
    "#### Remise à niveau de l'apprentissage supervisé\n",
    "\n",
    "- L'apprentissage supervisé apprend à prédire y (le plus souvent un nombre ou une catégorie) à partir de x (le plus souvent un vecteur de nombres ou une image) étant donné un ensemble de données.\n",
    "\n",
    "<br><br>\n",
    "\n",
    "➡️ Appuie sur la touche flèche droite pour passer à la diapositive suivante (et sur la touche échap pour voir toutes les diapositives)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb4df9c-fc80-4571-9f51-8efebc175d24",
   "metadata": {},
   "source": [
    "#### Exemples d'apprentissage supervisé\n",
    "\n",
    "- Prédire les prix des maisons en fonction de leurs caractéristiques\n",
    "- Classer un email comme spam ou non spam\n",
    "- Identifier si une image contient un chien\n",
    "\n",
    "Idée générale : prédire la sortie étant donné l'entrée"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e0f26a4-2313-4474-b173-26b32526eecf",
   "metadata": {},
   "source": [
    "#### L'\"API\" de l'apprentissage supervisé\n",
    "\n",
    "[](img/SL-API.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c2d25f-02fe-495f-9529-7117d2b91f5c",
   "metadata": {},
   "source": [
    "#### L'\"API\" de l'apprentissage par renforcement\n",
    "\n",
    "[](img/SL-vs-RL.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f2188e-0756-4fc7-a038-83b1d54fac8f",
   "metadata": {},
   "source": [
    "#### Apprentissage par renforcement\n",
    "\n",
    "- Entrée RL : un **environnement** \n",
    "- Sortie RL : une **politique** qui prend des décisions\n",
    "\n",
    "Nous définirons les environnements et les politiques plus tard dans ce module !"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b566b4-2ef9-4545-834f-903a520c855c",
   "metadata": {},
   "source": [
    "\n",
    "#### Exemples d'apprentissage par renforcement\n",
    "\n",
    "- Une voiture autopilotée qui apprend à conduire\n",
    "  - Env : les conditions de la route, la façon dont la voiture conduit. Politique : l'algorithme de conduite autonome\n",
    "- Apprendre à jouer à un jeu vidéo\n",
    "  - Env : le jeu. Politique : l'IA du jeu\n",
    "- Apprendre la \"meilleure\" séquence de films à recommander à un utilisateur\n",
    "  - Env : préférences/comportements de l'utilisateur en matière de films. Politique : le système de recommandation\n",
    "\n",
    "Idée générale : tu dois prendre une séquence de décisions et tu veux agir de manière optimale à chaque étape.\n",
    "\n",
    "Ces décisions affectent les entrées/sorties futures (contrairement à SL).\n",
    "\n",
    "Notes :\n",
    "\n",
    "- L'entrée de l'apprentissage supervisé est un ensemble de données\n",
    "- La sortie est le modèle formé qui peut faire des prédictions\n",
    "- Le modèle lui-même a des entrées et des sorties ($x$ et $y$)\n",
    "- Note que, là encore, la sortie est une fonction qui peut être utilisée pour calculer/prédire quelque chose.\n",
    "- Dans la prochaine section, nous nous pencherons sur les environnements et les politiques.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d070eb2b-121b-4925-b30e-80e8d2b1283b",
   "metadata": {},
   "source": [
    "#### Appliquons ce que nous avons appris !"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6714de6-59d5-428a-90d5-caa45d222203",
   "metadata": {},
   "source": [
    "## Apprentissage supervisé ou apprentissage par renforcement\n",
    "<!-- multiple choice -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c20387-a7d2-4697-895a-57e97d4c1013",
   "metadata": {},
   "source": [
    "#### Résoudrais-tu ce problème avec SL ou RL ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956a69c9-859d-4a9f-8f49-ca69bdf64876",
   "metadata": {},
   "source": [
    "_Classification des espèces à partir de l'image d'un arbre_\n",
    "\n",
    "- [x] SL \n",
    "- [ ] RL | Essaie à nouveau - il s'agit d'une prédiction unique plutôt que d'une séquence d'actions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aec3e2f-b3b2-48fb-b466-fc81a2447655",
   "metadata": {},
   "source": [
    "#### Résoudrais-tu ce problème avec SL ou RL ?\n",
    "\n",
    "_Créer une IA qui joue aux échecs_\n",
    "\n",
    "- [ ] SL | Essaie encore -- l'IA qui joue aux échecs doit agir de manière optimale à chaque étape d'une séquence.\n",
    "- [x] RL "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c21b1192-8d52-4178-9921-aef09cbd0286",
   "metadata": {},
   "source": [
    "#### Résoudrais-tu ce problème avec SL ou RL ?\n",
    "\n",
    "_Prédire si un utilisateur va aimer ou non un film_\n",
    "\n",
    "- [x] SL \n",
    "- [ ] RL | Essaie encore - il s'agit d'une prédiction unique plutôt que d'une séquence d'actions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67cacbff-c6d3-4b5d-9ea7-4d4cd1e3e3a8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# TODO\n",
    "# start the course by showing some really cool results.\n",
    "# not sure yet whether that should be here, or at the end of module 1 (maybe a section 1.4)\n",
    "# let's see...\n",
    "\n",
    "# Also TODO:\n",
    "# Talk about simulations since we can't usually do RL training in a \"real\" environment\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ray200]",
   "language": "python",
   "name": "conda-env-ray200-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
