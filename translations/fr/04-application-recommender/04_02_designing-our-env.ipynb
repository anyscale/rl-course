{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5aa21ad-6bb9-4990-ab4d-fb9435b0bc00",
   "metadata": {},
   "source": [
    "## Recommender env : design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fdd0ce7d-4a5b-4d03-8d93-b176de9e4db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HIDDEN\n",
    "import gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd89af26-eb12-45d8-95b1-14fdd7027deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: adapt images from Sven for this"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0293f36-0ca4-40d4-8c4f-456c07627269",
   "metadata": {},
   "source": [
    "#### Simuler le comportement de l'utilisateur\n",
    "\n",
    "- Simule le comportement de l'utilisateur lorsqu'il répond de façon **répétée** aux recommandations d'articles.\n",
    "- Le comportement clé à simuler :\n",
    "\n",
    "&gt; Recommander des articles de \"malbouffe\" est bon à court terme, mais mauvais à long terme.\n",
    "\n",
    "- C'est entièrement notre choix en tant que concepteur de l'environnement \n",
    "- Tu voudras peut-être simuler/capturer un autre type de comportement d'utilisateur.\n",
    "  - Ou bien, tire des enseignements des données sur le comportement des utilisateurs - plus d'informations à ce sujet plus tard !\n",
    "- Mais ceci sera notre exemple courant pour l'instant."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cbb31ad-3891-4d9a-91be-09854ff73c31",
   "metadata": {},
   "source": [
    "#### Chocolat\n",
    "\n",
    "- Nous modéliserons chaque article comme ayant un niveau de \"douceur\" \n",
    "- Nous appellerons les articles à forte teneur en sucre des \"bonbons\".\n",
    "\n",
    "[](img/candy.jpg)\n",
    "\n",
    "- Il peut s'agir de vidéos courtes et stupides, de bibelots bon marché en solde, etc.\n",
    "- Les utilisateurs aiment les bonbons à court terme, mais trop de chocolat entraîne une insatisfaction à long terme."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d7aee0e-e60a-419b-bdd0-b0680b5d2f0c",
   "metadata": {},
   "source": [
    "#### Veggies\n",
    "\n",
    "- Nous appellerons les articles à faible teneur en sucre des \"légumes\".\n",
    "\n",
    "[](img/veggies.jpg)\n",
    "\n",
    "- Il peut s'agir de documentaires éducatifs, d'articles ennuyeux mais utiles, etc.\n",
    "- Les utilisateurs n'apprécient pas beaucoup les végés à court terme, mais ils augmentent la satisfaction à long terme."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58280654-1e51-492c-96da-4764c0ceba37",
   "metadata": {},
   "source": [
    "#### Niveau de sucre\n",
    "\n",
    "- Nous allons modéliser nos utilisateurs comme ayant un **niveau de sucre** qui mesure la quantité de bonbons qu'ils ont mangés récemment.\n",
    "- Le taux de sucre de l'utilisateur (ou la notion de taux de sucre) _ne sera pas connu de l'agent_ !\n",
    "- Mais pour l'instant, nous sommes en train de concevoir le simulateur, donc nous sommes omniscients."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ddc3a6-98b4-4a61-a229-4b0ae27c62fd",
   "metadata": {},
   "source": [
    "#### Dynamique du niveau de sucre\n",
    "\n",
    "- Nous devons décider comment le niveau de sucre change avec la consommation de l'article.\n",
    "- Une approche simple est la suivante :\n",
    "\n",
    "&gt; Lorsqu'un article est consommé, le niveau de sucre se déplace vers le goût sucré de cet article.\n",
    "\n",
    "Exemples :\n",
    "\n",
    "- Si ton taux de sucre est de 0,2 et que tu consommes un article avec un pouvoir sucrant de 0,5, ton taux de sucre augmente ⬆️\n",
    "- Si ton taux de sucre est de 0,2 et que tu consommes un article ayant un pouvoir sucrant de 0,1, ton taux de sucre diminue ⬇️"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f5fb6ed-8479-40ae-a489-b279f03a61ac",
   "metadata": {},
   "source": [
    "#### Dynamique du niveau de sucre\n",
    "\n",
    "- Comment pouvons-nous représenter cela mathématiquement ?\n",
    "- Nous pouvons essayer ceci :\n",
    "\n",
    "&gt; nouveau niveau de sucre = ⍺ (ancien niveau de sucre) + (1 - ⍺) (douceur de l'article)\n",
    "\n",
    "- Ici, ⍺ est un nombre entre 0 et 1 qui contrôle le degré de \"ténacité\" du niveau de sucre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce8adf56-8b56-4dc7-bb3d-3a2cebfe6f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HIDDEN \n",
    "# note the slide above and below are partially the same - just want to hide the bottom half at first"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b8ebcf-d522-42e6-8777-a32b516259e4",
   "metadata": {},
   "source": [
    "#### Dynamique du niveau de sucre\n",
    "\n",
    "- Comment pouvons-nous représenter cela mathématiquement ?\n",
    "- Nous pouvons essayer ceci :\n",
    "\n",
    "&gt; nouveau niveau de sucre = ⍺ (ancien niveau de sucre) + (1 - ⍺) (douceur de l'article)\n",
    "\n",
    "- Ici, ⍺ est un nombre entre 0 et 1 qui contrôle le degré de \"ténacité\" du niveau de sucre.\n",
    "- Par exemple, si ⍺=1, alors l'équation ci-dessus devient la suivante\n",
    "\n",
    "&gt; nouveau taux de sucre = ancien taux de sucre\n",
    "\n",
    "et le taux de sucre ne change jamais. Si ⍺=0, alors nous avons\n",
    "\n",
    "&gt; nouveau niveau de sucre = douceur de l'article\n",
    "\n",
    "ce qui signifie qu'un seul article peut complètement changer le niveau de sucre de l'utilisateur.\n",
    "\n",
    "- Pour les ⍺ entre 0 et 1, nous avons une combinaison de l'ancien niveau de sucre et de la douceur de l'article."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fca4d06-9168-41b9-8ab2-fc1fd34ce0d1",
   "metadata": {},
   "source": [
    "#### Dynamique du niveau de sucre\n",
    "\n",
    "Nous pouvons mettre en œuvre ce qui précède en utilisant cette fonction :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7821a2f-b42f-4c64-a3d7-a02c7658120f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_sugar_level(sugar_level, item_sweetness, alpha=0.9):\n",
    "    return alpha * sugar_level + (1 - alpha) * item_sweetness"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "796a261f-2cf0-48f4-ab95-c8ff4c7800be",
   "metadata": {},
   "source": [
    "Testons-le pour nous assurer que le comportement a du sens (en utilisant la valeur par défaut de ⍺=0,9) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b934fd76-bda0-4e6d-ad2e-17de12d3b4e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.26"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sugar_level = 0.2\n",
    "sugar_level = update_sugar_level(sugar_level, 0.8)\n",
    "sugar_level"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eda542e-c236-4906-bf8f-fa5f7ab5d238",
   "metadata": {},
   "source": [
    "L'article était sucré (0,8), donc le taux de sucre a beaucoup augmenté."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e9e6f2a-ee8a-4458-82eb-afb57e858676",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.264"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sugar_level = update_sugar_level(sugar_level, 0.3)\n",
    "sugar_level"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d9bda3-2c8f-44f8-8cf0-4e3a31cfb404",
   "metadata": {},
   "source": [
    "La douceur de l'article était légèrement supérieure au niveau de sucre, donc le niveau de sucre a légèrement augmenté."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27253dfb-a220-4d0f-9816-1fb542f1045b",
   "metadata": {},
   "source": [
    "#### Dynamique du niveau de sucre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c8c863a1-c37e-4c29-8136-0529501118b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2386"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sugar_level = update_sugar_level(sugar_level, 0.01)\n",
    "sugar_level"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eeb5116-a9ab-49d9-8748-d751662a994b",
   "metadata": {},
   "source": [
    "L'article n'était pas sucré, donc le taux de sucre a baissé."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c20efd-9ca1-43be-8529-aacb7244ad4c",
   "metadata": {},
   "source": [
    "#### Effet de l'alpha\n",
    "\n",
    "Nous pouvons voir qu'avec un alpha plus petit, le niveau de sucre change beaucoup plus rapidement :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b684f74b-3519-4300-b4f2-5ff68c0199e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1193"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sugar_level = update_sugar_level(sugar_level, 0.0, alpha=0.5)\n",
    "sugar_level"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea5d8350-5daa-4377-9ec4-79819528d0bb",
   "metadata": {},
   "source": [
    "#### Récompense\n",
    "\n",
    "- Ok super, nous avons résolu la question de la dynamique du taux de sucre !\n",
    "- La deuxième pièce majeure du puzzle est la récompense.\n",
    "- Ce que nous voulons :\n",
    "\n",
    "1. Un taux de sucre plus élevé dans l'article entraîne une plus grande récompense (miam, des bonbons !)\n",
    "2. Un taux de sucre plus élevé entraîne une récompense plus faible (ahh, trop de bonbons !)\n",
    "\n",
    "Un moyen simple de combiner ces effets est de les multiplier ensemble :\n",
    "\n",
    "&gt; récompense = douceur de l'article * (1 - niveau de sucre)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f6d77a-2458-4a51-91c4-070d074c1978",
   "metadata": {},
   "source": [
    "#### Mise en œuvre des récompenses\n",
    "\n",
    "&gt; récompense = douceur de l'article * (1 - niveau de sucre)\n",
    "\n",
    "Nous pouvons coder cela comme suit :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "258777c5-b896-4ec4-b999-38c4aadafdbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reward(sugar_level, item_sweetness):\n",
    "    return item_sweetness * (1 - sugar_level)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a1eeea-f027-419c-8f80-756eec6be9ea",
   "metadata": {},
   "source": [
    "Nous utiliserons ces pièces dans la prochaine section lorsque nous mettrons en place notre environnement !"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c68cf7-4dc6-4ab4-86c5-93b10fced0ae",
   "metadata": {},
   "source": [
    "#### Espace d'observation\n",
    "\n",
    "- Ensuite, nous devrons mettre en place les observations \n",
    "- Nos observations seront les _caractéristiques des articles candidats_.\n",
    "- Pour simplifier, nous supposerons qu'il n'y a qu'une seule caractéristique, la douceur de l'article.\n",
    "- Ainsi, l'agent verra un tas de niveaux de douceur et en choisira un."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb5cadd-bbdc-4a19-931c-522c8902407f",
   "metadata": {},
   "source": [
    "#### Espace d'action\n",
    "\n",
    "- Dans cet environnement, l'action est l'élément choisi à recommander, étant donné les candidats."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f7ccbd3-57d6-4914-94a0-7fb03fa0b96e",
   "metadata": {},
   "source": [
    "#### Appliquons ce que nous avons appris !"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bebfec4-9043-498b-b3da-bc91700a74bf",
   "metadata": {},
   "source": [
    "## Grande vision\n",
    "<!-- multiple choice -->\n",
    "\n",
    "Lequel des points suivants est **NON** vrai à propos de l'environnement RL de recommandation simulé que nous créons ?\n",
    "\n",
    "- [ ] L'environnement contient un modèle très simplifié du comportement des utilisateurs, mais un agent entraîné peut tout de même être utile pour faire des recommandations.\n",
    "- [ ] L'environnement représente avec précision le comportement des vrais utilisateurs.\n",
    "- [ ] L'environnement est un bon point de départ et nous voudrons peut-être ajouter de la complexité au fur et à mesure que notre travail avance.\n",
    "- [ ] L'environnement capture la notion selon laquelle les utilisateurs réagiront différemment à différents éléments, et cette réaction peut dépendre de leur historique."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe02b60a-f753-4299-9953-2a6109b77f8a",
   "metadata": {},
   "source": [
    "## Recommander des récompenses\n",
    "<!-- multiple choice -->\n",
    "\n",
    "Rappelle-toi que notre fonction de récompense est\n",
    "\n",
    "&gt; récompense = douceur de l'article * (1 - niveau de sucre)\n",
    "\n",
    "#### Satisfaction à court terme\n",
    "\n",
    "Vrai ou faux : à tout moment, la récompense _immédiate_ est _toujours_ plus grande pour les bonbons que pour les légumes.\n",
    "\n",
    "- [ ] Vrai | La récompense immédiate est directement proportionnelle à la douceur de l'article.\n",
    "- [ ] Faux | Regarde de plus près la formule ci-dessus !"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e512009-9deb-4c39-a055-3e82a7acdf14",
   "metadata": {},
   "source": [
    "#### Satisfaction à long terme\n",
    "\n",
    "Vrai ou faux : à tout moment, la récompense _totale à long terme_ est _toujours_ plus grande pour recommander des légumes que pour des bonbons.\n",
    "\n",
    "- [ ] Vrai | Il est compliqué de déterminer ce qui sera le mieux à long terme - c'est ce que notre agent doit apprendre !\n",
    "- [x] Faux"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2622b06b-90fc-4fc7-9448-a782be431d63",
   "metadata": {},
   "source": [
    "## Accident de sucre\n",
    "<!-- coding exercise -->\n",
    "\n",
    "Supposons que ton taux de sucre commence à 0,5 et qu'à chaque étape, tu n'as le choix qu'entre deux aliments, le méga-légume (goût sucré = 0) et le méga-bonbon (goût sucré = 1). Tu feras 3 recommandations à la suite, en utilisant alpha = 0,7. Utilise la fenêtre de codage ci-dessous pour jouer avec différentes options et trouver la meilleure séquence de recommandations en termes de récompense _totale_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d8695dc5-2538-4158-95fa-50a9135b42f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Received reward 0.00000, new sugar level 0.35000\n",
      "  Received reward 0.00000, new sugar level 0.24500\n",
      "  Received reward 0.00000, new sugar level 0.17150\n",
      "Total reward after 5 recommendations: 0.0\n"
     ]
    }
   ],
   "source": [
    "# EXERCISE\n",
    "\n",
    "def update_sugar_level(sugar_level, item_sweetness, alpha=0.9):\n",
    "    return alpha * sugar_level + (1 - alpha) * item_sweetness\n",
    "\n",
    "def reward(sugar_level, item_sweetness):\n",
    "    return item_sweetness * (1 - sugar_level)\n",
    "\n",
    "# MODIFY THIS LIST\n",
    "# But make sure it always contains 3 items, each 0 or 1\n",
    "recommendations = [0, 0, 0]\n",
    "\n",
    "# starting sugar level\n",
    "sugar_level = 0.5\n",
    "\n",
    "total_reward = 0\n",
    "\n",
    "for item_sweetness in recommendations:\n",
    "    \n",
    "    # add reward\n",
    "    immediate_reward = reward(sugar_level, item_sweetness)\n",
    "    total_reward += immediate_reward\n",
    "    \n",
    "    # update sugar level\n",
    "    sugar_level = update_sugar_level(sugar_level, item_sweetness, alpha=0.7)\n",
    "    \n",
    "    print(f\"  Received reward {immediate_reward:.5f}, new sugar level {sugar_level:.5f}\")\n",
    "    \n",
    "print(\"Total reward after 5 recommendations:\", total_reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d2d62233-1f33-47fe-b155-15e12dd9a8ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Received reward 0.00000, new sugar level 0.35000\n",
      "  Received reward 0.65000, new sugar level 0.54500\n",
      "  Received reward 0.45500, new sugar level 0.68150\n",
      "Total reward after 5 recommendations 1.105\n"
     ]
    }
   ],
   "source": [
    "# SOLUTION\n",
    "\n",
    "def update_sugar_level(sugar_level, item_sweetness, alpha=0.9):\n",
    "    return alpha * sugar_level + (1 - alpha) * item_sweetness\n",
    "\n",
    "def reward(sugar_level, item_sweetness):\n",
    "    return item_sweetness * (1 - sugar_level)\n",
    "\n",
    "# MODIFY THIS LIST\n",
    "# But make sure it always contains 3 items, each 0 or 1\n",
    "recommendations = [0,1,1]\n",
    "\n",
    "# starting sugar level\n",
    "sugar_level = 0.5\n",
    "\n",
    "total_reward = 0\n",
    "\n",
    "for item_sweetness in recommendations:\n",
    "    \n",
    "    # add reward\n",
    "    immediate_reward = reward(sugar_level, item_sweetness)\n",
    "    total_reward += immediate_reward\n",
    "    \n",
    "    # update sugar level\n",
    "    sugar_level = update_sugar_level(sugar_level, item_sweetness, alpha=0.7)\n",
    "    \n",
    "    print(f\"  Received reward {immediate_reward:.5f}, new sugar level {sugar_level:.5f}\")\n",
    "    \n",
    "print(\"Total reward after 5 recommendations\", total_reward)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a377412-aefd-4b85-8b94-de3869d0858a",
   "metadata": {},
   "source": [
    "#### Quelle était la meilleure stratégie dans cet exemple ?\n",
    "\n",
    "- [ x ] 1 légume pour faire baisser le taux de sucre, puis 2 bonbons pour cette douce récompense.\n",
    "- [ ] Des bonbons, puis des légumes pour être en bonne santé, puis encore des bonbons.\n",
    "- [ ] Légumes à volonté !\n",
    "- [ ] Bonbons à volonté !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080aeba6-d6fd-461c-8ab7-c6420f692f93",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ray200]",
   "language": "python",
   "name": "conda-env-ray200-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
