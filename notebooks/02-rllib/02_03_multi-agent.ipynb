{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90c01ab9-1cd0-47d8-a198-e07e36e2c1fc",
   "metadata": {
    "tags": []
   },
   "source": [
    "## RLlib for multi-agent RL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e74417a3-63bc-4000-951a-72ab882b689e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HIDDEN\n",
    "import gym\n",
    "import numpy as np\n",
    "\n",
    "# References for this notebook:\n",
    "# https://github.com/sven1977/rllib_tutorials/blob/main/ray_summit_2021/tutorial_notebook.ipynb\n",
    "# https://github.com/anyscale/ray-summit-2022-training/blob/main/ray-rllib/ex_02_create_multiagent_rllib_env.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19622972-1ae8-4288-af47-b9d268edb5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HIDDEN\n",
    "import ray\n",
    "import logging\n",
    "ray.init(log_to_driver=False, ignore_reinit_error=True, logging_level=logging.ERROR) # logging.FATAL\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0f0d1b5-2e3e-4e35-b65c-1ade016763d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HIDDEN\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['font.size'] = 14"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87867cf7-c998-4627-8592-a9535054c16b",
   "metadata": {},
   "source": [
    "#### Multi-agent RL\n",
    "\n",
    "- So far we've dealt with one agent\n",
    "- Multi-agent RL deals with multiple agents\n",
    "- This could be competitive, e.g. two parties engaging in monetary transactions\n",
    "- It could be cooperative, e.g. two robots trying to complete a task together\n",
    "- See [this fun video](https://www.youtube.com/watch?v=Lu56xVlZ40M) for a competitive hide and seek game!\n",
    "\n",
    "Notes:\n",
    "\n",
    "Relationship to game theory, especially in the competitive scenarios."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a94916c-f649-4de7-b15c-69ca2e7bed09",
   "metadata": {},
   "source": [
    "#### Multi agent arena\n",
    "\n",
    "![](img/multi-agent-arena-6x6.png)\n",
    "\n",
    "Notes:\n",
    "\n",
    "This arena game will be our running example.\n",
    "\n",
    "We have two agents, agent 1 and agent 2. In this case they have the same actions spaces and observations spaces but (critically) different reward functions. Agent 1 gets positive rewards if it explores a new square field, and a negative reward if it collides with agent 2. Agent 2 gets positive reward if it collides with agent 2. So in a way this is a game of tag, with agent 2 trying to catch agent 1, but agent 1 also has the additional goal of trying to explore territory rather than purely just running away. Since the field is 6x6, there are 36 squares. Our observation space is MultiDiscrete(36,36) because it contains the location of agent 1 (discrete 36) and agent 2 (also discrete 36).\n",
    "\n",
    "Agent 2 moves first at each time step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec5bbbc9-2700-437d-827b-d18d393645b7",
   "metadata": {},
   "source": [
    "#### Testing out the multi-agent env\n",
    "\n",
    "We import the env (code available on the course GitHub):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb272d1c-c4fc-439d-beee-ddfcb40e5310",
   "metadata": {},
   "outputs": [],
   "source": [
    "from envs_02 import MultiAgentArena"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29a9d01f-9437-4e6c-8e12-2eb6f181ea79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'agent1': array([ 0, 35]), 'agent2': array([35,  0])}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = MultiAgentArena()\n",
    "env.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d97243-f8a9-472c-9ac3-a550bb763d13",
   "metadata": {},
   "source": [
    "What is the observation space?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d2b7a39-5b24-4bab-92d8-92015ba6433f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiDiscrete([36 36])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ec63aa-60ee-40fa-bae0-fa2850b21aa4",
   "metadata": {},
   "source": [
    "- We see that it's `MultiDiscrete([36 36])`.\n",
    "- Actually it is `MultiDiscrete([36 36])` _for each agent_.\n",
    "- The 36 comes from the 6x6 grid, and represents one location.\n",
    "- Both agents observe the locations of both agents.\n",
    "- In this particular env, both agents observe the same thing, though each agent sees itself \"first\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb1ef26-ee87-40b6-9342-7d67aac0295c",
   "metadata": {},
   "source": [
    "#### Testing out the multi-agent env\n",
    "\n",
    "Let's look at the action space now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "64e9ef51-15d2-45d3-aa98-1d2ab2552d31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discrete(4)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c327f0cf-cd21-490b-993b-ade2ee7f5758",
   "metadata": {},
   "source": [
    "- Again, this is for each agent.\n",
    "- The env uses the same convention as Frozen Lake: 0=left, 1=down, 2=right, 3=up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "78b6b8c3-f6ab-4a1a-8cfa-c1abfbf77cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs, rewards, dones, _ = env.step({\"agent1\": 1, \"agent2\": 0}) # agent 1: down, agent2: left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "07423354-aad5-4ef9-a493-47591f65c441",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________\n",
      "|.     |\n",
      "|1     |\n",
      "|      |\n",
      "|      |\n",
      "|      |\n",
      "|    2 |\n",
      "‾‾‾‾‾‾‾‾\n",
      "\n",
      "R1= 1.0\n",
      "R2=-0.1 (0 collisions)\n",
      "Env timesteps=1/50\n"
     ]
    }
   ],
   "source": [
    "env.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c7eda38-fcd3-4176-8709-0f5bacdf6099",
   "metadata": {},
   "source": [
    "#### Testing out the multi-agent env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b2322127-1d21-49a8-973f-2844198ed107",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________\n",
      "|.     |\n",
      "|1     |\n",
      "|      |\n",
      "|      |\n",
      "|      |\n",
      "|    2 |\n",
      "‾‾‾‾‾‾‾‾\n",
      "\n",
      "R1= 1.0\n",
      "R2=-0.1 (0 collisions)\n",
      "Env timesteps=1/50\n"
     ]
    }
   ],
   "source": [
    "env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "08cf16a6-c851-45ea-a006-e3c573192753",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'agent1': array([ 6, 34]), 'agent2': array([34,  6])}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69429196-8301-401a-99a2-12bed7092cdb",
   "metadata": {},
   "source": [
    "#### Testing out the multi-agent env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "69207fa9-f54b-4731-8343-aca08cd69495",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'agent1': array([ 6, 34]), 'agent2': array([34,  6])}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec17dbbd-fc32-448a-a17b-2f843c366a7f",
   "metadata": {},
   "source": [
    "This makes sense given the observation space mapping:\n",
    "\n",
    "```\n",
    "--------------------\n",
    "| 0  1  2  3  4  5 |\n",
    "| 6  7  8  9 10 11 |\n",
    "|12 13 14 15 16 17 |\n",
    "|18 19 20 21 22 23 |\n",
    "|24 25 26 27 28 29 |\n",
    "|30 31 32 33 34 35 |\n",
    "--------------------\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cd3c60ff-3e42-4c26-a886-ffe2e256c1ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "| 0  1  2  3  4  5 |\n",
      "| 6  7  8  9 10 11 |\n",
      "|12 13 14 15 16 17 |\n",
      "|18 19 20 21 22 23 |\n",
      "|24 25 26 27 28 29 |\n",
      "|30 31 32 33 34 35 |\n",
      "--------------------"
     ]
    }
   ],
   "source": [
    "# HIDDEN\n",
    "\n",
    "n = 6\n",
    "for i in range(20):\n",
    "    print(\"-\", end=\"\")\n",
    "print()\n",
    "for i in range(n):\n",
    "    print(\"|\", end=\"\")\n",
    "    for j in range(n):\n",
    "        print(f\"{j + i*n:2d}\", end=\" \")\n",
    "    print(\"|\")\n",
    "for i in range(20):\n",
    "    print(\"-\", end=\"\")\n",
    "    \n",
    "    \n",
    "# --------------------------------\n",
    "# | 0  1  2  3  4  5  6  7  8  9 |\n",
    "# |10 11 12 13 14 15 16 17 18 19 |\n",
    "# |20 21 22 23 24 25 26 27 28 29 |\n",
    "# |30 31 32 33 34 35 36 37 38 39 |\n",
    "# |40 41 42 43 44 45 46 47 48 49 |\n",
    "# |50 51 52 53 54 55 56 57 58 59 |\n",
    "# |60 61 62 63 64 65 66 67 68 69 |\n",
    "# |70 71 72 73 74 75 76 77 78 79 |\n",
    "# |80 81 82 83 84 85 86 87 88 89 |\n",
    "# |90 91 92 93 94 95 96 97 98 99 |\n",
    "# --------------------------------\n",
    "\n",
    "# ------------------------\n",
    "# | 0  1  2  3  4  5  6  7 |\n",
    "# | 8  9 10 11 12 13 14 15 |\n",
    "# |16 17 18 19 20 21 22 23 |\n",
    "# |24 25 26 27 28 29 30 31 |\n",
    "# |32 33 34 35 36 37 38 39 |\n",
    "# |40 41 42 43 44 45 46 47 |\n",
    "# |48 49 50 51 52 53 54 55 |\n",
    "# |56 57 58 59 60 61 62 63 |\n",
    "# ------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a53cae9-cbef-429a-bdab-1aee7aa7cf7d",
   "metadata": {},
   "source": [
    "#### Testing out the multi-agent env\n",
    "\n",
    "Let's also look at the rewards and dones returned by `step()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e699ba08-f263-4038-b59f-5171446ea08b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'agent1': 1.0, 'agent2': -0.1}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rewards"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da41fc58-e865-4a65-bd3f-293406f1cddc",
   "metadata": {},
   "source": [
    "Here we see agent 1 collected reward of +1 for exploring whereas agent 2 collected -0.1 for a regular move."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e20a3596-e706-43f5-b15e-4675e0f5c14d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'agent1': False, 'agent2': False, '__all__': False}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ced2be-b0c1-4f86-8031-ab15cb2ff49e",
   "metadata": {},
   "source": [
    "The `\"__all__\"` is True when both (all) agents are done."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ec6c92-65be-48bb-87a0-faa77188ec9f",
   "metadata": {},
   "source": [
    "Notes:\n",
    "\n",
    "In this environment, episodes end after 50 time steps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a5d662-5194-458a-8da2-df5f2abd1895",
   "metadata": {},
   "source": [
    "#### Multi-agent training with RLlib\n",
    "\n",
    "We can see that PPO supports multi-agent training from the Ray docs [here](https://docs.ray.io/en/latest/rllib/rllib-algorithms.html#available-algorithms-overview)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e2a132b6-a5c3-4886-9ef1-17020d2d357b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HIDDEN\n",
    "from ray.rllib.algorithms.ppo import PPOConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c8334f57-e390-4a67-8ef3-9946481c9fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the same as before\n",
    "ppo_config = (\n",
    "    PPOConfig()\\\n",
    "    .framework(\"torch\")\\\n",
    "    .rollouts(create_env_on_local_worker=True)\\\n",
    "    .debugging(seed=0, log_level=\"ERROR\")\\\n",
    "    .training(model={\"fcnet_hiddens\" : [64, 64]})\\\n",
    ")\n",
    "# This is new\n",
    "ppo_config = ppo_config.multi_agent(\n",
    "    policies=[\"policy1\", \"policy2\"],\n",
    "    policy_mapping_fn=lambda agent_id, episode, worker, **kwargs: \"policy1\" if agent_id == \"agent1\" else \"policy2\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d50cf7ac-873e-4d29-aeb0-1351a5f5af00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "# use a default config for the above, to make it cleaner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d387cf1-58ab-4442-89dc-d7d8bf9bfddf",
   "metadata": {},
   "source": [
    "- We name the policies and map the agent ids to policy ids.\n",
    "- The policy ids must match in the two lines above.\n",
    "- The agent ids must match the env:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7987bff1-e666-433e-87e2-c482d5c2a636",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'agent1': array([ 6, 34]), 'agent2': array([34,  6])}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d18e54e-1f13-4342-afb2-ea89b11a4f30",
   "metadata": {},
   "source": [
    "#### Multi-policy\n",
    "\n",
    "- In multi-agent RL, the two agents might share the same policy, or they might not.\n",
    "- In this case, we want _separate policies_.\n",
    "- This was specified in the code on the previous slide via the config.\n",
    "\n",
    "![](img/from_single_agent_to_multi_agent.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "882c9ae4-1fe2-4d45-b0dd-712defe26194",
   "metadata": {},
   "source": [
    "#### Training\n",
    "\n",
    "Let's build the algorithm and train for 20 iterations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f5af9d8c-cc7c-4572-a0dc-ff4c22cf388d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ppo = ppo_config.build(env=MultiAgentArena)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f929c4fc-3e8d-47cf-b44e-9c61830bbd90",
   "metadata": {},
   "outputs": [],
   "source": [
    "rewards1 = []\n",
    "rewards2 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "73cff77b-9864-4e75-937b-29e3c4431c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(20):\n",
    "    result = ppo.train()\n",
    "    rewards1.append(result['policy_reward_mean']['policy1'])\n",
    "    rewards2.append(result['policy_reward_mean']['policy2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5669198d-70db-41bd-8ab5-8c85e4bd5647",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HIDDEN\n",
    "# rewards1 = np.array(rewards1)\n",
    "# rewards2 = np.array(rewards2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d089bd7d-4681-44d2-8789-182bec431a0b",
   "metadata": {},
   "source": [
    "#### Training curve\n",
    "\n",
    "It looks like learning is happening!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "30d80ea8-89c6-4bf2-a59c-607f8dd5859f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 400x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(4,3))\n",
    "plt.plot(rewards1, label=\"Agent 1\")\n",
    "plt.plot(rewards2, label=\"Agent 2\")\n",
    "plt.plot(np.array(rewards1)+np.array(rewards2), label=\"Total reward\", linewidth=3, color=\"black\")\n",
    "plt.legend(fontsize=12)\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylabel(\"Reward\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71746f6a-8fd1-45ba-bce1-9eb0a6c5efec",
   "metadata": {},
   "source": [
    "Notes:\n",
    "\n",
    "It is just coincidence that the two agents end up with a similar reward."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eac4c21-78b9-46dc-9c68-d45537b3d52a",
   "metadata": {},
   "source": [
    "#### A constantly changing environment\n",
    "\n",
    "- From each agent's perspective, the environment keeps changes (as the other agent learns).\n",
    "- As one agent learns new strategies, the other agent has to learn about and counter them.\n",
    "- This makes multi-agent RL quite special!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1c5285-f02b-48e4-ad4c-0b1f62e1de41",
   "metadata": {},
   "source": [
    "#### Actions\n",
    "\n",
    "When we want to use the trained agents, we still use `compute_single_action` but once for each agent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2d6bf26a-2e08-4196-809d-24b2d8ffb953",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b9a71f41-3ad8-4997-be6e-1ace02a8ccf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HIDDEN\n",
    "# env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4d4032cf-0c76-445f-a0e5-b15082bddb92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ppo.compute_single_action(obs[\"agent1\"], policy_id=\"policy1\", explore=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e88d7111-47fe-4afb-bb3c-a5a8e6d82cd7",
   "metadata": {},
   "source": [
    "Agent 1 moves  right (0=left, 1=down, 2=right, 3=up)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e2c5770c-bdab-42cd-b0c7-a3cfdd5bf8f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ppo.compute_single_action(obs[\"agent2\"], policy_id=\"policy2\", explore=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2414f80f-2b16-4174-81f4-7906f1438348",
   "metadata": {},
   "source": [
    "Agent 2 moves up."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "329274ee-0f18-4278-bf1e-1c25948a566a",
   "metadata": {},
   "source": [
    "We need to pass in the observation for that agent, and also the correct policy since we are using separate policies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d205da70-1255-437c-8a99-6ea8a5e8d2a0",
   "metadata": {},
   "source": [
    "#### Let's apply what we learned!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "76c284ef-6058-4a05-b4c9-709014f34885",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HIDDEN\n",
    "# ppo.save(\"models/MultiAgent20\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "660798a8-c360-48ac-bd9a-f023157d4908",
   "metadata": {},
   "source": [
    "## Multi-agent RL use cases\n",
    "<!-- multiple choice -->\n",
    "\n",
    "Which of the following is **NOT** a reasonable use case of multi-agent RL?\n",
    "\n",
    "- [ ] Multiple competing agents learning to play an adversarial game.\n",
    "- [ ] Multiple cooperative agents learning to play a cooperative game.\n",
    "- [ ] Learning to operate in a financial market with multiple stakeholders.\n",
    "- [x] Frozen Lake"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c06797-db39-42cc-96c4-48537827c16a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## What do the agents share?\n",
    "<!-- multiple choice -->\n",
    "\n",
    "#### Observations and actions: our example\n",
    "\n",
    "Which of the following is true **about our arena example specifically**?\n",
    "\n",
    "- [ ] The agents share the same observation space but have different action spaces.\n",
    "- [ ] The agents share the same action space but have different observation spaces.\n",
    "- [x] The agents share the same observation and action spaces.\n",
    "- [ ] The agents have different observation and action spaces.\n",
    "\n",
    "#### Observations and actions: in general\n",
    "\n",
    "Which of the following is true **about multi-agent RL in general**?\n",
    "\n",
    "- [ ] The agents always share the same observation space but may have different action spaces.\n",
    "- [ ] The agents always share the same action space but may have different observation spaces.\n",
    "- [ ] The agents always share the same observation and action spaces.\n",
    "- [x] The agents may have different observation and action spaces.\n",
    "\n",
    "#### Rewards and policies: our example\n",
    "\n",
    "Which of the following is true **about our arena example specifically**?\n",
    "\n",
    "- [ ] The agents have the same goals but different policies.\n",
    "- [ ] The agents have the same policies but different goals.\n",
    "- [ ] The agents have the same goals and the same policies. \n",
    "- [x] The agents have different goals and different policies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a6a315b-2271-4484-959c-483e40dc5f22",
   "metadata": {},
   "source": [
    "## Visualizing the trained arena agent\n",
    "<!-- coding exercise -->\n",
    "\n",
    "In the slides we trained two agents to play the arena game. In the code below, we restore the agent that was trained in the slides. Fill in the missing code so that we can watch the trained agents play the game. Then, answer the multiple choice question below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df51067-0dcb-4758-acc0-ac7c44af7067",
   "metadata": {
    "tags": [
     "raises-exception"
    ]
   },
   "outputs": [],
   "source": [
    "# EXERCISE\n",
    "\n",
    "from envs_02 import MultiAgentArena\n",
    "from ray.rllib.algorithms.ppo import PPOConfig\n",
    "import time\n",
    "\n",
    "ppo_config = (\n",
    "    PPOConfig()\\\n",
    "    .framework(\"torch\")\\\n",
    "    .rollouts(create_env_on_local_worker=True)\\\n",
    "    .debugging(seed=0, log_level=\"ERROR\")\\\n",
    "    .training(model={\"fcnet_hiddens\" : [64, 64]})\\\n",
    "    .multi_agent(\n",
    "        ____=[\"policy1\", \"policy2\"],\n",
    "        ____=lambda agent_id, episode, worker, **kwargs: \"policy1\" if agent_id == \"agent1\" else \"policy2\"\n",
    "    )\n",
    ")\n",
    "\n",
    "ppo_arena = ppo_config.build(env=MultiAgentArena)\n",
    "\n",
    "ppo_arena.restore(\"models/MultiAgent20/checkpoint_000020\")\n",
    "\n",
    "env = MultiAgentArena(config={\"render\": True})\n",
    "obs = env.reset()\n",
    "dones = {\"__all__\" : False}\n",
    "    \n",
    "while not dones[\"__all__\"]:\n",
    "\n",
    "    action1 = ppo_arena.compute_single_action(____, policy_id=\"policy1\")\n",
    "    action2 = ppo_arena.compute_single_action(____, policy_id=\"policy2\")\n",
    "\n",
    "    obs, rewards, dones, infos = env.step({\"agent1\": ____, \"agent2\": ____})\n",
    "\n",
    "    env.render()\n",
    "    time.sleep(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5a9df7e2-2962-417c-94ee-9a48e50c56c2",
   "metadata": {},
   "outputs": [
    {
     "ename": "RaySystemError",
     "evalue": "System error: No module named 'envs'\ntraceback: Traceback (most recent call last):\n  File \"/Users/mike/git/anyscale/ray/python/ray/_private/serialization.py\", line 352, in deserialize_objects\n    obj = self._deserialize_object(data, metadata, object_ref)\n  File \"/Users/mike/git/anyscale/ray/python/ray/_private/serialization.py\", line 241, in _deserialize_object\n    return self._deserialize_msgpack_data(data, metadata_fields)\n  File \"/Users/mike/git/anyscale/ray/python/ray/_private/serialization.py\", line 196, in _deserialize_msgpack_data\n    python_objects = self._deserialize_pickle5_data(pickle5_data)\n  File \"/Users/mike/git/anyscale/ray/python/ray/_private/serialization.py\", line 186, in _deserialize_pickle5_data\n    obj = pickle.loads(in_band)\nModuleNotFoundError: No module named 'envs'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRayActorError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[0;32m~/git/anyscale/ray/python/ray/rllib/algorithms/algorithm.py:418\u001b[0m, in \u001b[0;36mAlgorithm.setup\u001b[0;34m(self, config)\u001b[0m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 418\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mworkers \u001b[38;5;241m=\u001b[39m \u001b[43mWorkerSet\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    419\u001b[0m \u001b[43m        \u001b[49m\u001b[43menv_creator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv_creator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    420\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidate_env\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate_env\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    421\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpolicy_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_default_policy_class\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    422\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrainer_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    423\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnum_workers\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    424\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_worker\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    425\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogdir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlogdir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    426\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    427\u001b[0m \u001b[38;5;66;03m# WorkerSet creation possibly fails, if some (remote) workers cannot\u001b[39;00m\n\u001b[1;32m    428\u001b[0m \u001b[38;5;66;03m# be initialized properly (due to some errors in the RolloutWorker's\u001b[39;00m\n\u001b[1;32m    429\u001b[0m \u001b[38;5;66;03m# constructor).\u001b[39;00m\n",
      "File \u001b[0;32m~/git/anyscale/ray/python/ray/rllib/evaluation/worker_set.py:125\u001b[0m, in \u001b[0;36mWorkerSet.__init__\u001b[0;34m(self, env_creator, validate_env, policy_class, trainer_config, num_workers, local_worker, logdir, _setup)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_remote_workers \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 125\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_workers\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrainer_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvalidate_workers_after_construction\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;66;03m# Create a local worker, if needed.\u001b[39;00m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;66;03m# If num_workers > 0 and we don't have an env on the local worker,\u001b[39;00m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;66;03m# get the observation- and action spaces for each policy from\u001b[39;00m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;66;03m# the first remote worker (which does have an env).\u001b[39;00m\n",
      "File \u001b[0;32m~/git/anyscale/ray/python/ray/rllib/evaluation/worker_set.py:269\u001b[0m, in \u001b[0;36mWorkerSet.add_workers\u001b[0;34m(self, num_workers, validate)\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m validate:\n\u001b[0;32m--> 269\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforeach_worker\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mw\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mw\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43massert_healthy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/git/anyscale/ray/python/ray/rllib/evaluation/worker_set.py:391\u001b[0m, in \u001b[0;36mWorkerSet.foreach_worker\u001b[0;34m(self, func)\u001b[0m\n\u001b[1;32m    390\u001b[0m     local_result \u001b[38;5;241m=\u001b[39m [func(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlocal_worker())]\n\u001b[0;32m--> 391\u001b[0m remote_results \u001b[38;5;241m=\u001b[39m \u001b[43mray\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mw\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mremote\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mw\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mremote_workers\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    392\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m local_result \u001b[38;5;241m+\u001b[39m remote_results\n",
      "File \u001b[0;32m~/git/anyscale/ray/python/ray/_private/client_mode_hook.py:105\u001b[0m, in \u001b[0;36mclient_mode_hook.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(ray, func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 105\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/git/anyscale/ray/python/ray/_private/worker.py:2247\u001b[0m, in \u001b[0;36mget\u001b[0;34m(object_refs, timeout)\u001b[0m\n\u001b[1;32m   2246\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2247\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m value\n\u001b[1;32m   2249\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_individual_id:\n",
      "\u001b[0;31mRayActorError\u001b[0m: The actor died because of an error raised in its creation task, \u001b[36mray::RolloutWorker.__init__()\u001b[39m (pid=58429, ip=127.0.0.1, repr=<ray.rllib.evaluation.rollout_worker.RolloutWorker object at 0x1259f2370>)\n  At least one of the input arguments for this task could not be computed:\nray.exceptions.RaySystemError: System error: No module named 'envs'\ntraceback: Traceback (most recent call last):\nModuleNotFoundError: No module named 'envs'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRaySystemError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [33]\u001b[0m, in \u001b[0;36m<cell line: 21>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtime\u001b[39;00m\n\u001b[1;32m      9\u001b[0m ppo_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     10\u001b[0m     PPOConfig()\\\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;241m.\u001b[39mframework(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch\u001b[39m\u001b[38;5;124m\"\u001b[39m)\\\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     18\u001b[0m     )\n\u001b[1;32m     19\u001b[0m )\n\u001b[0;32m---> 21\u001b[0m ppo_arena \u001b[38;5;241m=\u001b[39m \u001b[43mppo_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mMultiAgentArena\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m ppo_arena\u001b[38;5;241m.\u001b[39mrestore(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodels/MultiAgent20/checkpoint_000020\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     25\u001b[0m env \u001b[38;5;241m=\u001b[39m MultiAgentArena(config\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrender\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m})\n",
      "File \u001b[0;32m~/git/anyscale/ray/python/ray/rllib/algorithms/algorithm_config.py:307\u001b[0m, in \u001b[0;36mAlgorithmConfig.build\u001b[0;34m(self, env, logger_creator)\u001b[0m\n\u001b[1;32m    304\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m logger_creator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    305\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger_creator \u001b[38;5;241m=\u001b[39m logger_creator\n\u001b[0;32m--> 307\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43malgo_class\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    308\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    309\u001b[0m \u001b[43m    \u001b[49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    310\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlogger_creator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlogger_creator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/git/anyscale/ray/python/ray/rllib/algorithms/algorithm.py:308\u001b[0m, in \u001b[0;36mAlgorithm.__init__\u001b[0;34m(self, config, env, logger_creator, **kwargs)\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[38;5;66;03m# Initialize common evaluation_metrics to nan, before they become\u001b[39;00m\n\u001b[1;32m    297\u001b[0m \u001b[38;5;66;03m# available. We want to make sure the metrics are always present\u001b[39;00m\n\u001b[1;32m    298\u001b[0m \u001b[38;5;66;03m# (although their values may be nan), so that Tune does not complain\u001b[39;00m\n\u001b[1;32m    299\u001b[0m \u001b[38;5;66;03m# when we use these as stopping criteria.\u001b[39;00m\n\u001b[1;32m    300\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluation_metrics \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    301\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mevaluation\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\n\u001b[1;32m    302\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepisode_reward_max\u001b[39m\u001b[38;5;124m\"\u001b[39m: np\u001b[38;5;241m.\u001b[39mnan,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    305\u001b[0m     }\n\u001b[1;32m    306\u001b[0m }\n\u001b[0;32m--> 308\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogger_creator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogger_creator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    310\u001b[0m \u001b[38;5;66;03m# Check, whether `training_iteration` is still a tune.Trainable property\u001b[39;00m\n\u001b[1;32m    311\u001b[0m \u001b[38;5;66;03m# and has not been overridden by the user in the attempt to implement the\u001b[39;00m\n\u001b[1;32m    312\u001b[0m \u001b[38;5;66;03m# algos logic (this should be done now inside `training_step`).\u001b[39;00m\n\u001b[1;32m    313\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/git/anyscale/ray/python/ray/tune/trainable/trainable.py:157\u001b[0m, in \u001b[0;36mTrainable.__init__\u001b[0;34m(self, config, logger_creator, remote_checkpoint_dir, custom_syncer)\u001b[0m\n\u001b[1;32m    155\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_local_ip \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_current_ip()\n\u001b[0;32m--> 157\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msetup\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    158\u001b[0m setup_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m setup_time \u001b[38;5;241m>\u001b[39m SETUP_TIME_THRESHOLD:\n",
      "File \u001b[0;32m~/git/anyscale/ray/python/ray/rllib/algorithms/algorithm.py:443\u001b[0m, in \u001b[0;36mAlgorithm.setup\u001b[0;34m(self, config)\u001b[0m\n\u001b[1;32m    430\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m RayActorError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    431\u001b[0m     \u001b[38;5;66;03m# In case of an actor (remote worker) init failure, the remote worker\u001b[39;00m\n\u001b[1;32m    432\u001b[0m     \u001b[38;5;66;03m# may still exist and will be accessible, however, e.g. calling\u001b[39;00m\n\u001b[1;32m    433\u001b[0m     \u001b[38;5;66;03m# its `sample.remote()` would result in strange \"property not found\"\u001b[39;00m\n\u001b[1;32m    434\u001b[0m     \u001b[38;5;66;03m# errors.\u001b[39;00m\n\u001b[1;32m    435\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m e\u001b[38;5;241m.\u001b[39mactor_init_failed:\n\u001b[1;32m    436\u001b[0m         \u001b[38;5;66;03m# Raise the original error here that the RolloutWorker raised\u001b[39;00m\n\u001b[1;32m    437\u001b[0m         \u001b[38;5;66;03m# during its construction process. This is to enforce transparency\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    441\u001b[0m         \u001b[38;5;66;03m# - e.args[0].args[2]: The original Exception (e.g. a ValueError due\u001b[39;00m\n\u001b[1;32m    442\u001b[0m         \u001b[38;5;66;03m# to a config mismatch) thrown inside the actor.\u001b[39;00m\n\u001b[0;32m--> 443\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m    444\u001b[0m     \u001b[38;5;66;03m# In any other case, raise the RayActorError as-is.\u001b[39;00m\n\u001b[1;32m    445\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    446\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "\u001b[0;31mRaySystemError\u001b[0m: System error: No module named 'envs'\ntraceback: Traceback (most recent call last):\n  File \"/Users/mike/git/anyscale/ray/python/ray/_private/serialization.py\", line 352, in deserialize_objects\n    obj = self._deserialize_object(data, metadata, object_ref)\n  File \"/Users/mike/git/anyscale/ray/python/ray/_private/serialization.py\", line 241, in _deserialize_object\n    return self._deserialize_msgpack_data(data, metadata_fields)\n  File \"/Users/mike/git/anyscale/ray/python/ray/_private/serialization.py\", line 196, in _deserialize_msgpack_data\n    python_objects = self._deserialize_pickle5_data(pickle5_data)\n  File \"/Users/mike/git/anyscale/ray/python/ray/_private/serialization.py\", line 186, in _deserialize_pickle5_data\n    obj = pickle.loads(in_band)\nModuleNotFoundError: No module named 'envs'\n"
     ]
    }
   ],
   "source": [
    "# SOLUTION\n",
    "from envs import MultiAgentArena\n",
    "from ray.rllib.algorithms.ppo import PPOConfig\n",
    "import time\n",
    "\n",
    "ppo_config = (\n",
    "    PPOConfig()\\\n",
    "    .framework(\"torch\")\\\n",
    "    .rollouts(create_env_on_local_worker=True)\\\n",
    "    .debugging(seed=0, log_level=\"ERROR\")\\\n",
    "    .training(model={\"fcnet_hiddens\" : [64, 64]})\\\n",
    "    .multi_agent(\n",
    "        policies=[\"policy1\", \"policy2\"],\n",
    "        policy_mapping_fn=lambda agent_id, episode, worker, **kwargs: \"policy1\" if agent_id == \"agent1\" else \"policy2\"\n",
    "    )\n",
    ")\n",
    "\n",
    "ppo_arena = ppo_config.build(env=MultiAgentArena)\n",
    "\n",
    "ppo_arena.restore(\"models/MultiAgent20/checkpoint_000020\")\n",
    "\n",
    "env = MultiAgentArena(config={\"render\": True})\n",
    "obs = env.reset()\n",
    "dones = {\"__all__\" : False}\n",
    "    \n",
    "while not dones[\"__all__\"]:\n",
    "\n",
    "    action1 = ppo_arena.compute_single_action(obs[\"agent1\"], policy_id=\"policy1\")\n",
    "    action2 = ppo_arena.compute_single_action(obs[\"agent2\"], policy_id=\"policy2\")\n",
    "\n",
    "    obs, rewards, dones, infos = env.step({\"agent1\": action1, \"agent2\": action2})\n",
    "\n",
    "    env.render()\n",
    "    time.sleep(0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "079e7363-6ba8-4333-94c8-62bd1fd8e985",
   "metadata": {},
   "source": [
    "#### Choose the option below that best describes the agents' behavior.\n",
    "\n",
    "- [x] Agent 2 appears to \"guard\" some of the unexplored territory from Agent 1. \n",
    "- [ ] Agent 1 manages to explore the entire arena in the given number of time steps.\n",
    "- [ ] Agent 1 manages to avoid colliding with Agent 2 in the given number of time steps.\n",
    "- [ ] The agents appear to ignore each other. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ray200]",
   "language": "python",
   "name": "conda-env-ray200-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
