{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90c01ab9-1cd0-47d8-a198-e07e36e2c1fc",
   "metadata": {
    "tags": []
   },
   "source": [
    "## RLlib for multi-agent RL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e74417a3-63bc-4000-951a-72ab882b689e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HIDDEN\n",
    "import gym\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['font.size'] = 16\n",
    "# https://github.com/sven1977/rllib_tutorials/blob/main/ray_summit_2021/tutorial_notebook.ipynb\n",
    "# https://github.com/anyscale/ray-summit-2022-training/blob/main/ray-rllib/ex_02_create_multiagent_rllib_env.ipynb\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87867cf7-c998-4627-8592-a9535054c16b",
   "metadata": {},
   "source": [
    "#### Multi-agent RL\n",
    "\n",
    "- So far we've dealt with one agent\n",
    "- Multi-agent RL deals with multiple agents\n",
    "- This could be competitive, e.g. two parties engaging in monetary transactions\n",
    "- It could be cooperative, e.g. two robots trying to complete a task together\n",
    "- See [this fun video](https://www.youtube.com/watch?v=Lu56xVlZ40M) for a competitive hide and seek game!\n",
    "\n",
    "Notes:\n",
    "\n",
    "Relationship to game theory, especially in the competitive scenarios."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a94916c-f649-4de7-b15c-69ca2e7bed09",
   "metadata": {},
   "source": [
    "#### Multi agent arena\n",
    "\n",
    "![](img/multi-agent-arena.png)\n",
    "\n",
    "Notes:\n",
    "\n",
    "This arena game will be our running example.\n",
    "\n",
    "We have two agents, agent 1 and agent 2. In this case they have the same actions spaces and observations spaces but (critically) different reward functions. Agent 1 gets positive rewards if it explores a new square field, and a negative reward if it collides with agent 2. Agent 2 gets positive reward if it collides with agent 2. So in a way this is a game of tag, with agent 2 trying to catch agent 1, but agent 1 also has the additional goal of trying to explore territory rather than purely just running away. Since the field is 8x8, there are 64 squares. Our observation space is MultiDiscrete(64,64) because it contains the location of agent 1 (discrete 64) and agent 2 (also discrete 64)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec5bbbc9-2700-437d-827b-d18d393645b7",
   "metadata": {},
   "source": [
    "#### Testing out the multi-agent env\n",
    "\n",
    "We import the env (code available on the course GitHub):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb272d1c-c4fc-439d-beee-ddfcb40e5310",
   "metadata": {},
   "outputs": [],
   "source": [
    "from envs import MultiAgentArena"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29a9d01f-9437-4e6c-8e12-2eb6f181ea79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'agent1': array([ 0, 99]), 'agent2': array([99,  0])}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = MultiAgentArena()\n",
    "env.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d97243-f8a9-472c-9ac3-a550bb763d13",
   "metadata": {},
   "source": [
    "What is the observation space?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d2b7a39-5b24-4bab-92d8-92015ba6433f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiDiscrete([100 100])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ec63aa-60ee-40fa-bae0-fa2850b21aa4",
   "metadata": {},
   "source": [
    "- We see that it's `MultiDiscrete([100 100])`.\n",
    "- Actually it is `MultiDiscrete([100 100])` _for each agent_.\n",
    "- The 100 comes from the 10x10 grid, and represents one location.\n",
    "- Agent 1 observes the locations of Agents 1 and 2.\n",
    "- Agent 2 observes the locations of Agents 1 and 2.\n",
    "- In this particular env, both agents observe the same thing, though each agent sees itself \"first\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb1ef26-ee87-40b6-9342-7d67aac0295c",
   "metadata": {},
   "source": [
    "#### Testing out the multi-agent env\n",
    "\n",
    "Let's look at the action space now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64e9ef51-15d2-45d3-aa98-1d2ab2552d31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discrete(4)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c327f0cf-cd21-490b-993b-ade2ee7f5758",
   "metadata": {},
   "source": [
    "- Again, this is for each agent.\n",
    "- The env uses the same convention as Frozen Lake: 0=left, 1=down, 2=right, 3=up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "78b6b8c3-f6ab-4a1a-8cfa-c1abfbf77cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs, rewards, dones, _ = env.step({\"agent1\": 1, \"agent2\": 3}) # agent 1: down, agent2: up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "07423354-aad5-4ef9-a493-47591f65c441",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________\n",
      "|.         |\n",
      "|1         |\n",
      "|          |\n",
      "|          |\n",
      "|          |\n",
      "|          |\n",
      "|          |\n",
      "|          |\n",
      "|         2|\n",
      "|          |\n",
      "‾‾‾‾‾‾‾‾‾‾‾‾\n",
      "\n",
      "R1= 1.0\n",
      "R2=-0.1 (0 collisions)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "env.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c7eda38-fcd3-4176-8709-0f5bacdf6099",
   "metadata": {},
   "source": [
    "#### Testing out the multi-agent env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "08cf16a6-c851-45ea-a006-e3c573192753",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'agent1': array([10, 89]), 'agent2': array([89, 10])}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec17dbbd-fc32-448a-a17b-2f843c366a7f",
   "metadata": {},
   "source": [
    "This makes sense given the observation space mapping:\n",
    "\n",
    "```\n",
    "--------------------------------\n",
    "| 0  1  2  3  4  5  6  7  8  9 |\n",
    "|10 11 12 13 14 15 16 17 18 19 |\n",
    "|20 21 22 23 24 25 26 27 28 29 |\n",
    "|30 31 32 33 34 35 36 37 38 39 |\n",
    "|40 41 42 43 44 45 46 47 48 49 |\n",
    "|50 51 52 53 54 55 56 57 58 59 |\n",
    "|60 61 62 63 64 65 66 67 68 69 |\n",
    "|70 71 72 73 74 75 76 77 78 79 |\n",
    "|80 81 82 83 84 85 86 87 88 89 |\n",
    "|90 91 92 93 94 95 96 97 98 99 |\n",
    "--------------------------------\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cd3c60ff-3e42-4c26-a886-ffe2e256c1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HIDDEN\n",
    "\n",
    "# for i in range(32):\n",
    "#     print(\"-\", end=\"\")\n",
    "# print()\n",
    "# for i in range(10):\n",
    "#     print(\"|\", end=\"\")\n",
    "#     for j in range(10):\n",
    "#         print(f\"{j + i*10:2d}\", end=\" \")\n",
    "#     print(\"|\")\n",
    "# for i in range(32):\n",
    "#     print(\"-\", end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a53cae9-cbef-429a-bdab-1aee7aa7cf7d",
   "metadata": {},
   "source": [
    "#### Testing out the multi-agent env\n",
    "\n",
    "Let's also look at the rewards and dones returned by `step()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e699ba08-f263-4038-b59f-5171446ea08b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'agent1': 1.0, 'agent2': -0.1}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rewards"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da41fc58-e865-4a65-bd3f-293406f1cddc",
   "metadata": {},
   "source": [
    "Here we see how agent 1 collected reward of +1 for exploring whereas agent 2 collected -0.1 for a regular move."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e20a3596-e706-43f5-b15e-4675e0f5c14d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'agent1': False, 'agent2': False, '__all__': False}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ced2be-b0c1-4f86-8031-ab15cb2ff49e",
   "metadata": {},
   "source": [
    "The `\"__all__\"` is True when both (all) agents are done."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1953c7e-8b44-49e5-bae1-c927f1effba7",
   "metadata": {},
   "source": [
    "Note how agent 1 collected reward of +1 for exploring whereas agent 2 collected -0.1 for a regular move."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a5d662-5194-458a-8da2-df5f2abd1895",
   "metadata": {},
   "source": [
    "#### Multi-agent training with RLlib\n",
    "\n",
    "We can see that PPO support multi-agent from the Ray docs [here](https://docs.ray.io/en/latest/rllib/rllib-algorithms.html#available-algorithms-overview)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e2a132b6-a5c3-4886-9ef1-17020d2d357b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HIDDEN\n",
    "from ray.rllib.algorithms.ppo import PPOConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c8334f57-e390-4a67-8ef3-9946481c9fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the same as before\n",
    "ppo_config = (\n",
    "    PPOConfig()\\\n",
    "    .framework(\"torch\")\\\n",
    "    .rollouts(create_env_on_local_worker=True)\\\n",
    "    .debugging(seed=0, log_level=\"ERROR\")\\\n",
    "    .training(model={\"fcnet_hiddens\" : [64, 64]})\\\n",
    ")\n",
    "\n",
    "# This is new\n",
    "ppo_config = ppo_config.multi_agent(\n",
    "    policies=[\"policy1\", \"policy2\"],\n",
    "    policy_mapping_fn=lambda agent_id, episode, worker, **kwargs: \"policy1\" if agent_id == \"agent1\" else \"policy2\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d50cf7ac-873e-4d29-aeb0-1351a5f5af00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "# use a default config for the above, to make it cleaner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d387cf1-58ab-4442-89dc-d7d8bf9bfddf",
   "metadata": {},
   "source": [
    "- We name the policies and map the agent ids to policy ids.\n",
    "- The policy ids must match in the two lines above.\n",
    "- The agent ids must match the env:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7987bff1-e666-433e-87e2-c482d5c2a636",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'agent1': array([10, 89]), 'agent2': array([89, 10])}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d18e54e-1f13-4342-afb2-ea89b11a4f30",
   "metadata": {},
   "source": [
    "#### Multi-policy\n",
    "\n",
    "![](img/from_single_agent_to_multi_agent.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535d4f8c-7112-44d2-8c36-ab9a13b9993e",
   "metadata": {},
   "source": [
    "In the previous code, we defined _separate policies_ for the two agents."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "882c9ae4-1fe2-4d45-b0dd-712defe26194",
   "metadata": {},
   "source": [
    "#### Training\n",
    "\n",
    "Let's build the algorithm and train for 20 iterations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f5af9d8c-cc7c-4572-a0dc-ff4c22cf388d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ppo = ppo_config.build(env=MultiAgentArena)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "73cff77b-9864-4e75-937b-29e3c4431c43",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RolloutWorker pid=62038)\u001b[0m /Users/mike/git/anyscale/ray/python/ray/rllib/utils/debug/deterministic.py:42: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=62038)\u001b[0m   if LooseVersion(torch.__version__) >= LooseVersion(\"1.8.0\"):\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=62038)\u001b[0m /Users/mike/miniconda3/envs/ray2beta/lib/python3.9/site-packages/gym/core.py:268: DeprecationWarning: \u001b[33mWARN: Function `env.seed(seed)` is marked as deprecated and will be removed in the future. Please use `env.reset(seed=seed)` instead.\u001b[0m\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=62038)\u001b[0m   deprecation(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=62037)\u001b[0m /Users/mike/git/anyscale/ray/python/ray/rllib/utils/debug/deterministic.py:42: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=62037)\u001b[0m   if LooseVersion(torch.__version__) >= LooseVersion(\"1.8.0\"):\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=62037)\u001b[0m /Users/mike/miniconda3/envs/ray2beta/lib/python3.9/site-packages/gym/core.py:268: DeprecationWarning: \u001b[33mWARN: Function `env.seed(seed)` is marked as deprecated and will be removed in the future. Please use `env.reset(seed=seed)` instead.\u001b[0m\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=62037)\u001b[0m   deprecation(\n"
     ]
    }
   ],
   "source": [
    "rewards1 = []\n",
    "rewards2 = []\n",
    "for i in range(20):\n",
    "    result = ppo.train()\n",
    "    rewards1.append(result['policy_reward_mean']['policy1'])\n",
    "    rewards2.append(result['policy_reward_mean']['policy2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5669198d-70db-41bd-8ab5-8c85e4bd5647",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HIDDEN\n",
    "rewards1 = np.array(rewards1)\n",
    "rewards2 = np.array(rewards2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d089bd7d-4681-44d2-8789-182bec431a0b",
   "metadata": {},
   "source": [
    "#### Training curve\n",
    "\n",
    "It looks like learning is happening!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "30d80ea8-89c6-4bf2-a59c-607f8dd5859f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,6));\n",
    "plt.plot(rewards1, label=\"Agent 1\")\n",
    "plt.plot(rewards2, label=\"Agent 2\")\n",
    "plt.plot(rewards1+rewards2, label=\"Total reward\", linewidth=3, color=\"black\")\n",
    "plt.legend(fontsize=12);\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylabel(\"Reward\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f109bd-d171-4ebc-bb2c-5a625a0b599c",
   "metadata": {},
   "source": [
    "Notes:\n",
    "\n",
    "Note that in an adversarial multi-agent setup, an agent benefits from the other agent's failures and vice-versa: agents receive negative rewards the better the other agent is doing. This highlights some important aspects of multi-agent training:\n",
    "\n",
    "- From each agent's perspective, the environment is not as static as in respective single-agent scenarios (the other agent's behavior is probably harder to predict than the environment's own inherent dynamics/physics).\n",
    "- As one agent learns how to behave more intelligently, the other agent has to counter this new behavior of its opponent and become smarter as well. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1c5285-f02b-48e4-ad4c-0b1f62e1de41",
   "metadata": {},
   "source": [
    "#### Actions\n",
    "\n",
    "When we want to use the trained agents, we still use `compute_single_action` but twice:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2d6bf26a-2e08-4196-809d-24b2d8ffb953",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4d4032cf-0c76-445f-a0e5-b15082bddb92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ppo.compute_single_action(obs[\"agent1\"], policy_id=\"policy1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e88d7111-47fe-4afb-bb3c-a5a8e6d82cd7",
   "metadata": {},
   "source": [
    "Agent 1 moves  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e2c5770c-bdab-42cd-b0c7-a3cfdd5bf8f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ppo.compute_single_action(obs[\"agent2\"], policy_id=\"policy2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2414f80f-2b16-4174-81f4-7906f1438348",
   "metadata": {},
   "source": [
    "Agent 2 moves "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "329274ee-0f18-4278-bf1e-1c25948a566a",
   "metadata": {},
   "source": [
    "We need to pass in the observation for that agent, and also the correct policy since we are using separate policies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eac4c21-78b9-46dc-9c68-d45537b3d52a",
   "metadata": {},
   "source": [
    "## TODO\n",
    "\n",
    "why are they moving in weird directions?\n",
    "\n",
    "also, we should have a slide to think more intuitively about how the environment changes for each agent during training!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d205da70-1255-437c-8a99-6ea8a5e8d2a0",
   "metadata": {},
   "source": [
    "#### Let's apply what we learned!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "660798a8-c360-48ac-bd9a-f023157d4908",
   "metadata": {},
   "source": [
    "## Multi-agent RL use cases\n",
    "<!-- multiple choice -->\n",
    "\n",
    "Which of the following is **NOT** a reasonable use case of multi-agent RL?\n",
    "\n",
    "- [ ] Multiple competing agents learning to play an adversarial game.\n",
    "- [ ] Multiple cooperative agents learning to play a cooperative game.\n",
    "- [ ] Learning to operate in a financial market with multiple stakeholders.\n",
    "- [x] Frozen Lake"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c06797-db39-42cc-96c4-48537827c16a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## What do the agents share?\n",
    "<!-- multiple choice -->\n",
    "\n",
    "#### Observations and actions: our example\n",
    "\n",
    "Which of the following is true **about our arena example specifically**?\n",
    "\n",
    "- [ ] The agents share the same observation space but have different action spaces.\n",
    "- [ ] The agents share the same action space but have different observation spaces.\n",
    "- [x] The agents share the same observation and action spaces.\n",
    "- [ ] The agents have different observation and action spaces.\n",
    "\n",
    "#### Observations and actions: in general\n",
    "\n",
    "Which of the following is true **about multi-agent RL in general**?\n",
    "\n",
    "- [ ] The agents always share the same observation space but may have different action spaces.\n",
    "- [ ] The agents always share the same action space but may have different observation spaces.\n",
    "- [ ] The agents always share the same observation and action spaces.\n",
    "- [x] The agents may have different observation and action spaces.\n",
    "\n",
    "#### Rewards and policies: our example\n",
    "\n",
    "Which of the following is true **about our arena example specifically**?\n",
    "\n",
    "- [ ] The agents have the same goals but different policies.\n",
    "- [ ] The agents have the same policies but different goals.\n",
    "- [ ] The agents have the same goals and the same policies. \n",
    "- [x] The agents have different goals and different policies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a6a315b-2271-4484-959c-483e40dc5f22",
   "metadata": {},
   "source": [
    "## Visualizing the trained arena agent\n",
    "<!-- coding exercise -->\n",
    "\n",
    "In the slides we trained two agents to play the arena game. In the code below, we restore the agent that was trained in the slides. Fill in the missing code so that we can watch the trained agents play the game. Then, answer the multiple choice question below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1df51067-0dcb-4758-acc0-ac7c44af7067",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXERCISE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5a9df7e2-2962-417c-94ee-9a48e50c56c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RolloutWorker pid=43284)\u001b[0m /Users/mike/git/anyscale/ray/python/ray/rllib/utils/debug/deterministic.py:42: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=43284)\u001b[0m   if LooseVersion(torch.__version__) >= LooseVersion(\"1.8.0\"):\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=43284)\u001b[0m /Users/mike/miniconda3/envs/ray2beta/lib/python3.9/site-packages/gym/core.py:268: DeprecationWarning: \u001b[33mWARN: Function `env.seed(seed)` is marked as deprecated and will be removed in the future. Please use `env.reset(seed=seed)` instead.\u001b[0m\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=43284)\u001b[0m   deprecation(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=43283)\u001b[0m /Users/mike/git/anyscale/ray/python/ray/rllib/utils/debug/deterministic.py:42: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=43283)\u001b[0m   if LooseVersion(torch.__version__) >= LooseVersion(\"1.8.0\"):\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=43283)\u001b[0m /Users/mike/miniconda3/envs/ray2beta/lib/python3.9/site-packages/gym/core.py:268: DeprecationWarning: \u001b[33mWARN: Function `env.seed(seed)` is marked as deprecated and will be removed in the future. Please use `env.reset(seed=seed)` instead.\u001b[0m\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=43283)\u001b[0m   deprecation(\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can't convert np.ndarray of type numpy.object_. The only supported types are: float64, float32, float16, complex64, complex128, int64, int32, int16, int8, uint8, and bool.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [14]\u001b[0m, in \u001b[0;36m<cell line: 19>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m ppo_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m      6\u001b[0m     PPOConfig()\\\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;241m.\u001b[39mframework(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch\u001b[39m\u001b[38;5;124m\"\u001b[39m)\\\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     14\u001b[0m     )\n\u001b[1;32m     15\u001b[0m )\n\u001b[1;32m     17\u001b[0m ppo \u001b[38;5;241m=\u001b[39m ppo_config\u001b[38;5;241m.\u001b[39mbuild(env\u001b[38;5;241m=\u001b[39mMultiAgentArena)\n\u001b[0;32m---> 19\u001b[0m \u001b[43mppo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrestore\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodels/MultiAgent/checkpoint-20\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/git/anyscale/ray/python/ray/tune/trainable/trainable.py:585\u001b[0m, in \u001b[0;36mTrainable.restore\u001b[0;34m(self, checkpoint_path, checkpoint_node_ip)\u001b[0m\n\u001b[1;32m    583\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mload_checkpoint(checkpoint_dict)\n\u001b[1;32m    584\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 585\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_checkpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheckpoint_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    586\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time_since_restore \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m    587\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timesteps_since_restore \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m~/git/anyscale/ray/python/ray/rllib/algorithms/algorithm.py:1444\u001b[0m, in \u001b[0;36mAlgorithm.load_checkpoint\u001b[0;34m(self, checkpoint_path)\u001b[0m\n\u001b[1;32m   1441\u001b[0m \u001b[38;5;129m@override\u001b[39m(Trainable)\n\u001b[1;32m   1442\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_checkpoint\u001b[39m(\u001b[38;5;28mself\u001b[39m, checkpoint_path: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1443\u001b[0m     extra_data \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;28mopen\u001b[39m(checkpoint_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m-> 1444\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__setstate__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mextra_data\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/git/anyscale/ray/python/ray/rllib/algorithms/algorithm.py:2199\u001b[0m, in \u001b[0;36mAlgorithm.__setstate__\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m   2197\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__setstate__\u001b[39m(\u001b[38;5;28mself\u001b[39m, state: \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m   2198\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mworkers\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mworker\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m state:\n\u001b[0;32m-> 2199\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlocal_worker\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrestore\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mworker\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2200\u001b[0m         remote_state \u001b[38;5;241m=\u001b[39m ray\u001b[38;5;241m.\u001b[39mput(state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mworker\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m   2201\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mworkers\u001b[38;5;241m.\u001b[39mremote_workers():\n",
      "File \u001b[0;32m~/git/anyscale/ray/python/ray/rllib/evaluation/rollout_worker.py:1575\u001b[0m, in \u001b[0;36mRolloutWorker.restore\u001b[0;34m(self, objs)\u001b[0m\n\u001b[1;32m   1567\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_policy(\n\u001b[1;32m   1568\u001b[0m             policy_id\u001b[38;5;241m=\u001b[39mpid,\n\u001b[1;32m   1569\u001b[0m             policy_cls\u001b[38;5;241m=\u001b[39mpol_spec\u001b[38;5;241m.\u001b[39mpolicy_class,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1572\u001b[0m             config\u001b[38;5;241m=\u001b[39mpol_spec\u001b[38;5;241m.\u001b[39mconfig,\n\u001b[1;32m   1573\u001b[0m         )\n\u001b[1;32m   1574\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1575\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpolicy_map\u001b[49m\u001b[43m[\u001b[49m\u001b[43mpid\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_state\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/git/anyscale/ray/python/ray/rllib/policy/torch_mixins.py:113\u001b[0m, in \u001b[0;36mKLCoeffMixin.set_state\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkl_coeff \u001b[38;5;241m=\u001b[39m state\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcurrent_kl_coeff\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkl_coeff\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    112\u001b[0m \u001b[38;5;66;03m# Call super's set_state with rest of the state dict.\u001b[39;00m\n\u001b[0;32m--> 113\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_state\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/git/anyscale/ray/python/ray/rllib/policy/torch_policy_v2.py:914\u001b[0m, in \u001b[0;36mTorchPolicyV2.set_state\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m    912\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(optimizer_vars) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizers)\n\u001b[1;32m    913\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m o, s \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizers, optimizer_vars):\n\u001b[0;32m--> 914\u001b[0m         optim_state_dict \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_to_torch_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    915\u001b[0m         o\u001b[38;5;241m.\u001b[39mload_state_dict(optim_state_dict)\n\u001b[1;32m    916\u001b[0m \u001b[38;5;66;03m# Set exploration's state.\u001b[39;00m\n",
      "File \u001b[0;32m~/git/anyscale/ray/python/ray/rllib/utils/torch_utils.py:178\u001b[0m, in \u001b[0;36mconvert_to_torch_tensor\u001b[0;34m(x, device)\u001b[0m\n\u001b[1;32m    175\u001b[0m         tensor \u001b[38;5;241m=\u001b[39m tensor\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[1;32m    176\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tensor \u001b[38;5;28;01mif\u001b[39;00m device \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m tensor\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m--> 178\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_structure\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmapping\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ray2beta/lib/python3.9/site-packages/tree/__init__.py:430\u001b[0m, in \u001b[0;36mmap_structure\u001b[0;34m(func, *structures, **kwargs)\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m other \u001b[38;5;129;01min\u001b[39;00m structures[\u001b[38;5;241m1\u001b[39m:]:\n\u001b[1;32m    428\u001b[0m   assert_same_structure(structures[\u001b[38;5;241m0\u001b[39m], other, check_types\u001b[38;5;241m=\u001b[39mcheck_types)\n\u001b[1;32m    429\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m unflatten_as(structures[\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m--> 430\u001b[0m                     [func(\u001b[38;5;241m*\u001b[39margs) \u001b[38;5;28;01mfor\u001b[39;00m args \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mmap\u001b[39m(flatten, structures))])\n",
      "File \u001b[0;32m~/miniconda3/envs/ray2beta/lib/python3.9/site-packages/tree/__init__.py:430\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m other \u001b[38;5;129;01min\u001b[39;00m structures[\u001b[38;5;241m1\u001b[39m:]:\n\u001b[1;32m    428\u001b[0m   assert_same_structure(structures[\u001b[38;5;241m0\u001b[39m], other, check_types\u001b[38;5;241m=\u001b[39mcheck_types)\n\u001b[1;32m    429\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m unflatten_as(structures[\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m--> 430\u001b[0m                     [\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m args \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mmap\u001b[39m(flatten, structures))])\n",
      "File \u001b[0;32m~/git/anyscale/ray/python/ray/rllib/utils/torch_utils.py:172\u001b[0m, in \u001b[0;36mconvert_to_torch_tensor.<locals>.mapping\u001b[0;34m(item)\u001b[0m\n\u001b[1;32m    169\u001b[0m         tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(item)\n\u001b[1;32m    170\u001b[0m \u001b[38;5;66;03m# Everything else: Convert to numpy, then wrap as torch tensor.\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 172\u001b[0m     tensor \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;66;03m# Floatify all float64 tensors.\u001b[39;00m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tensor\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m torch\u001b[38;5;241m.\u001b[39mdouble:\n",
      "\u001b[0;31mTypeError\u001b[0m: can't convert np.ndarray of type numpy.object_. The only supported types are: float64, float32, float16, complex64, complex128, int64, int32, int16, int8, uint8, and bool."
     ]
    }
   ],
   "source": [
    "# SOLUTION\n",
    "from envs import MultiAgentArena\n",
    "from ray.rllib.algorithms.ppo import PPOConfig\n",
    "\n",
    "ppo_config = (\n",
    "    PPOConfig()\\\n",
    "    .framework(\"torch\")\\\n",
    "    .rollouts(create_env_on_local_worker=True)\\\n",
    "    .debugging(seed=0, log_level=\"ERROR\")\\\n",
    "    .training(model={\"fcnet_hiddens\" : [64, 64]})\\\n",
    "    .multi_agent(\n",
    "        policies=[\"policy1\", \"policy2\"],\n",
    "        policy_mapping_fn=lambda agent_id, episode, worker, **kwargs: \"policy1\" if agent_id == \"agent1\" else \"policy2\"\n",
    "    )\n",
    ")\n",
    "\n",
    "ppo_arena = ppo_config.build(env=MultiAgentArena)\n",
    "\n",
    "ppo_arena.restore(\"models/MultiAgent/checkpoint-20\")\n",
    "\n",
    "env = MultiAgentArena(config={\"render\": True})\n",
    "env.reset()\n",
    "dones = {\"__all__\" : False}\n",
    "with env.out:\n",
    "    \n",
    "    while not dones[\"__all__\"]:\n",
    "\n",
    "        action1 = ppo_arena.compute_single_action(obs[\"agent1\"], policy_id=\"policy1\")\n",
    "        action2 = ppo_arena.compute_single_action(obs[\"agent2\"], policy_id=\"policy2\")\n",
    "        \n",
    "        obs, rewards, dones, infos = env.step({\"agent1\": action1, \"agent2\": action2})\n",
    "        env.render()\n",
    "\n",
    "\n",
    "print(\"Agent1's x/y position={}\".format(env.agent1_pos))\n",
    "print(\"Agent2's x/y position={}\".format(env.agent2_pos))\n",
    "print(\"Env timesteps={}\".format(env.timesteps))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "079e7363-6ba8-4333-94c8-62bd1fd8e985",
   "metadata": {},
   "source": [
    "#### Choose the option below that best describes the agents' behavior.\n",
    "\n",
    "- [x] \n",
    "- [ ] \n",
    "- [ ] \n",
    "- [ ] "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ray2beta]",
   "language": "python",
   "name": "conda-env-ray2beta-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
