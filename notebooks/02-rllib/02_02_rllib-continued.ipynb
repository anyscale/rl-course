{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90c01ab9-1cd0-47d8-a198-e07e36e2c1fc",
   "metadata": {
    "tags": []
   },
   "source": [
    "## RLlib continued"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e74417a3-63bc-4000-951a-72ab882b689e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HIDDEN\n",
    "import gym\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['font.size'] = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27a0a477-40eb-44e1-b3aa-59e4f6f31fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HIDDEN\n",
    "import ray\n",
    "import logging\n",
    "ray.init(log_to_driver=False, ignore_reinit_error=True, logging_level=logging.ERROR); # logging.FATAL\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08a296a4-e50a-4530-8034-c8bc1e27671c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HIDDEN\n",
    "from ray.rllib.algorithms.ppo import PPO, PPOConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f67da7-14aa-456a-84bb-5813db493143",
   "metadata": {},
   "source": [
    "#### RLlib features\n",
    "\n",
    "- So far we've seen training, evaluation, and \"prediction\" with RLlib.\n",
    "- Next we'll explore a few more features:\n",
    "   - Algorithm configs\n",
    "   - Saving/restoring models\n",
    "   - Interpreting stochastic policies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e07d9e0-cc95-43f0-81b4-2b937070a7f2",
   "metadata": {},
   "source": [
    "#### Algorithm configs\n",
    "\n",
    "Remember this code?\n",
    "\n",
    "```python\n",
    "from ray.rllib.algorithms.ppo import PPO, PPOConfig\n",
    "ppo = PPO(env=\"FrozenLake-v1\", config=ppo_config)\n",
    "```\n",
    "\n",
    "Previously, we hid the `ppo_config`. Now we'll delve into it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6e49ba6-315f-42d5-949a-6ae5d98ae758",
   "metadata": {},
   "outputs": [],
   "source": [
    "ppo_config = PPOConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae2a8631-271c-4f85-8715-6cf1f95393f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# HIDDEN - this shows up in module 5 instead\n",
    "# The number of options is way too many to read:\n",
    "# len(ppo_config.to_dict())\n",
    "# # ppo_config.to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af4f47b-ef9a-4443-9dad-d5bb2e533b3b",
   "metadata": {},
   "source": [
    "#### Algorithm configs\n",
    "\n",
    "- When we instantiate a `PPOConfig()` we get the default config values.\n",
    "- There are a few values that we changed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0308301b-4f37-4218-8360-862b18574c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ppo_config = ppo_config.framework(\"torch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e78fb6f4-36b4-424d-8535-9473934b7e88",
   "metadata": {},
   "source": [
    "⬆️ Changes the framework from tensorflow (default) to pytorch for the policy model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d746f6bf-d5d0-41b6-b717-796d91a45f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "ppo_config = ppo_config.debugging(seed=0, log_level=\"ERROR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ca478e-2c3b-4c47-beba-94014f376469",
   "metadata": {},
   "source": [
    "⬆️ Sets a random seed for reproducibility of the course, reduces the warnings displayed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b8890eef-bbad-41a7-af8e-7fac509eb04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ppo_config = ppo_config.training(model={\"fcnet_hiddens\" : [32, 32]})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b4ecc0b-0d85-4aec-8011-28a2adc309f3",
   "metadata": {},
   "source": [
    "⬆️ Sets the policy neural network to have a smaller-than-default architecture, which helps the course materials run faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "098f8aa8-16b3-455e-9a92-4d92063da388",
   "metadata": {},
   "outputs": [],
   "source": [
    "ppo_config = ppo_config.rollouts(create_env_on_local_worker=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a68b5322-8fb4-4d07-9913-6696aa8905cf",
   "metadata": {},
   "source": [
    "⬆️ This relates to Ray, which we will touch on briefly in Module 5, but skip for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4e215df8-9e3e-4607-a831-b083cd949cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "ppo_config = ppo_config.environment(env_config={\"is_slippery\" : False})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc6380d-b76e-4960-a3c0-9e1618109ebd",
   "metadata": {},
   "source": [
    "⬆️ This is how we set env parameters, in this case specifying the non-slippery Frozen Lake."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "322b9bd0-8426-4648-80c0-479f96f6cddc",
   "metadata": {},
   "source": [
    "Notes:\n",
    "\n",
    "Remember, the policy is a function from observations to actions, and this function is a neural network. That is why we need a deep learning framework like pytorch.\n",
    "\n",
    "The random seed is only for the algorithm itself, e.g. randomness in the neural network optimization. It doesn't set the random seed for the environment's own randomness. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e834f6c3-0b1f-49dc-8c65-136e8b93fa5f",
   "metadata": {},
   "source": [
    "#### Algorithm configs\n",
    "\n",
    "We can also generate this config in one giant line of Python as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "447b397b-a875-417b-8bc7-ef862229ca64",
   "metadata": {},
   "outputs": [],
   "source": [
    "ppo_config = (\n",
    "    PPOConfig()\\\n",
    "    .framework(\"torch\")\\\n",
    "    .rollouts(create_env_on_local_worker=True)\\\n",
    "    .debugging(seed=0, log_level=\"ERROR\")\\\n",
    "    .training(model={\"fcnet_hiddens\" : [32, 32]})\\\n",
    "    .environment(env_config={\"is_slippery\" : False})\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7254e6af-7f07-4afc-b46d-575214eed645",
   "metadata": {},
   "source": [
    "(The `\\` character just means the line of Python continues below.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8cfa9d1-fbfa-455f-a722-950b634d4d45",
   "metadata": {},
   "source": [
    "Notes:\n",
    "\n",
    "We'll discuss tuning in Module 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "30eb0986-9e52-4656-9819-7c43b6d083a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HIDDEN\n",
    "algo_config = (\n",
    "    PPOConfig()\\\n",
    "    .framework(\"torch\")\\\n",
    "    .rollouts(create_env_on_local_worker=True)\\\n",
    "    .debugging(seed=0, log_level=\"ERROR\")\\\n",
    "    .training(model={\"fcnet_hiddens\" : [32, 32]})\\\n",
    "    .environment(env_config={\"is_slippery\" : False})\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "185074d6-c847-4790-94ba-381030616f56",
   "metadata": {},
   "source": [
    "#### Building an algorithm from the config\n",
    "\n",
    "We previously instantiated our PPO algorithm like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3f8b977e-e59d-4afd-9d82-2010be65ed40",
   "metadata": {},
   "outputs": [],
   "source": [
    "ppo = PPO(env=\"FrozenLake-v1\", config=ppo_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "499bf30c-c42a-40d5-957c-477686ee7ee7",
   "metadata": {},
   "source": [
    "The preferred syntax in the latest release of Ray/RLlib is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "217ddfaf-0332-42a8-8178-23c949a80b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ppo = ppo_config.build(env=\"FrozenLake-v1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e483661-3f65-4f61-8db4-3ac3a650619d",
   "metadata": {},
   "source": [
    "As a third option, you can also specify the environment in the config rather than as an argument to `build`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b2be522c-6b40-4b0d-8cf3-c473b420c325",
   "metadata": {},
   "outputs": [],
   "source": [
    "ppo_config.environment(env=\"FrozenLake-v1\")\n",
    "\n",
    "ppo = ppo_config.build()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef84da1-19ef-4300-8555-7e6e65b3e3b7",
   "metadata": {},
   "source": [
    "The end result is the same whichever way you choose."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e3069d-b826-447f-ad34-24eb1d912c4a",
   "metadata": {},
   "source": [
    "#### Saving models\n",
    "\n",
    "- We may want to save trained agents for future use.\n",
    "- This is also called _checkpointing_, especially when done during a training loop.\n",
    "- In RLlib, this can be done simply with:\n",
    "\n",
    "```python\n",
    "algo.save(path_to_checkpoint)\n",
    "```\n",
    "\n",
    "It can then be later restored with\n",
    "\n",
    "```python\n",
    "algo.restore(path_to_checkpoint)\n",
    "```\n",
    "\n",
    "Just make sure you create the trainer with the same environment and parameters when restoring from a checkpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c7ec02f5-d9f0-4b67-a69c-83a075b49cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # HIDDEN\n",
    "# for i in range(30):\n",
    "#     ppo.train()\n",
    "# \n",
    "# ppo.save(\"models/FrozenLakeSlippery-256-Ray2\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27092e6c-772e-4940-b140-fa77b8469397",
   "metadata": {},
   "source": [
    "#### Restoring models\n",
    "\n",
    "- Let's restore a PPO algorithm object\n",
    "- We need to set it up with the same config first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517db53e-410c-441f-8823-53b76a3cf825",
   "metadata": {},
   "outputs": [],
   "source": [
    "ppo_config = (\n",
    "    PPOConfig()\\\n",
    "    .framework(\"torch\")\\\n",
    "    .rollouts(create_env_on_local_worker=True)\\\n",
    "    .debugging(seed=0, log_level=\"ERROR\")\\\n",
    "    .training(model={\"fcnet_hiddens\" : [64,64]})\n",
    "    .environment(env_config={\"is_slippery\" : True})\\\n",
    "    .evaluation(evaluation_config = {\"explore\" : False})\n",
    ")\n",
    "\n",
    "ppo = ppo_config.build(\"FrozenLake-v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e39804d-b683-404c-9a7a-443569b284d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ppo.restore(\"models/FrozenLakeSlippery-256-Ray2/checkpoint-50\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db71b112-0918-4b7c-9275-f6bb38417640",
   "metadata": {},
   "source": [
    "Notes:\n",
    "\n",
    "Apparently, it was trained for 30 iterations, 124k time steps, 1 minute, 17k episodes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370d6ffb-b48b-4209-b7b8-ce0cb4d45e8c",
   "metadata": {},
   "source": [
    "#### Viewing stochastic policies\n",
    "\n",
    "- If we want to see what a policy does, we can use `compute_single action`\n",
    "- But, some RL algorithms, including PPO, learn _stochastic policies_.\n",
    "- We may wish to look at these _action probabilities_.\n",
    "- The code can be viewed on GitHub, but is hidden here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bc24efa0-bc12-4d99-b9c6-88fc9bf10550",
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7096f91a-7a14-4b9a-905b-603583d46c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"FrozenLake-v1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81533301-9caa-4fcc-a354-45ac8f98dabc",
   "metadata": {},
   "source": [
    "We'll use the trainer we just restored:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9cd397c9-9182-4391-a997-b1e8f23d1c5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.0708601e-04, 8.6194783e-01, 1.3743131e-01, 3.1362689e-04],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs = utils.query_policy(ppo, env, obs=0)\n",
    "probs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b92923e7-e5a9-40e2-8df3-3870306456c0",
   "metadata": {},
   "source": [
    "Actions: left (0), down (1), right (2), up (3)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17dbf19d-6ce9-4410-893e-9d0bd8bc2b3b",
   "metadata": {},
   "source": [
    "#### Viewing stochastic policies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "dc50e996-b713-4fd5-a9ce-62fb24148e68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Left:   0.03%\n",
      "Down:  86.19%\n",
      "Right: 13.74%\n",
      "Up:     0.03%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Left:  {probs[0]*100:5.2f}%\")\n",
    "print(f\"Down:  {probs[1]*100:5.2f}%\")\n",
    "print(f\"Right: {probs[2]*100:5.2f}%\")\n",
    "print(f\"Up:    {probs[3]*100:5.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c43dbb9c-06f8-4e5e-8c7f-5349d39623c4",
   "metadata": {},
   "source": [
    "Arena:\n",
    "\n",
    "```\n",
    "SFFF\n",
    "FHFH\n",
    "FFFH\n",
    "HFFG\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e800476-34c2-4fe4-bb1e-7f9c7e77e94a",
   "metadata": {},
   "source": [
    "Notes:\n",
    "    \n",
    "What we see here are the action probabilities. From the top-left, the agent considers moving left down or right, but not up. Presumably left is preferred to up because slipping down is preferred to slipping right.\n",
    "\n",
    "For a continuous action space this would be different."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44268a54-4855-434d-ac21-d2801f46a322",
   "metadata": {},
   "source": [
    "#### Viewing stochastic policies\n",
    "\n",
    "Let's view all the probabilities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d4a0e388-5ec4-489b-a4cd-53531859fe9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HIDDEN\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a8fdedc6-f162-4c92-a674-648f7ae154c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>left</th>\n",
       "      <th>down</th>\n",
       "      <th>right</th>\n",
       "      <th>up</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000307</td>\n",
       "      <td>0.861948</td>\n",
       "      <td>0.137431</td>\n",
       "      <td>0.000314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001545</td>\n",
       "      <td>0.000129</td>\n",
       "      <td>0.997325</td>\n",
       "      <td>0.001000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000614</td>\n",
       "      <td>0.997883</td>\n",
       "      <td>0.000648</td>\n",
       "      <td>0.000855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.021768</td>\n",
       "      <td>0.002684</td>\n",
       "      <td>0.961310</td>\n",
       "      <td>0.014238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.999648</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>0.000145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.008260</td>\n",
       "      <td>0.198169</td>\n",
       "      <td>0.786407</td>\n",
       "      <td>0.007165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000059</td>\n",
       "      <td>0.999218</td>\n",
       "      <td>0.000640</td>\n",
       "      <td>0.000084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.041046</td>\n",
       "      <td>0.286452</td>\n",
       "      <td>0.634076</td>\n",
       "      <td>0.038426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000334</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>0.999394</td>\n",
       "      <td>0.000197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000094</td>\n",
       "      <td>0.029428</td>\n",
       "      <td>0.970416</td>\n",
       "      <td>0.000063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.000061</td>\n",
       "      <td>0.999676</td>\n",
       "      <td>0.000174</td>\n",
       "      <td>0.000088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.001793</td>\n",
       "      <td>0.586685</td>\n",
       "      <td>0.409775</td>\n",
       "      <td>0.001747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.003990</td>\n",
       "      <td>0.652142</td>\n",
       "      <td>0.340331</td>\n",
       "      <td>0.003536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.000092</td>\n",
       "      <td>0.011372</td>\n",
       "      <td>0.988473</td>\n",
       "      <td>0.000064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.000092</td>\n",
       "      <td>0.001204</td>\n",
       "      <td>0.998647</td>\n",
       "      <td>0.000057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.001608</td>\n",
       "      <td>0.627634</td>\n",
       "      <td>0.369347</td>\n",
       "      <td>0.001412</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        left      down     right        up\n",
       "0   0.000307  0.861948  0.137431  0.000314\n",
       "1   0.001545  0.000129  0.997325  0.001000\n",
       "2   0.000614  0.997883  0.000648  0.000855\n",
       "3   0.021768  0.002684  0.961310  0.014238\n",
       "4   0.000100  0.999648  0.000107  0.000145\n",
       "5   0.008260  0.198169  0.786407  0.007165\n",
       "6   0.000059  0.999218  0.000640  0.000084\n",
       "7   0.041046  0.286452  0.634076  0.038426\n",
       "8   0.000334  0.000075  0.999394  0.000197\n",
       "9   0.000094  0.029428  0.970416  0.000063\n",
       "10  0.000061  0.999676  0.000174  0.000088\n",
       "11  0.001793  0.586685  0.409775  0.001747\n",
       "12  0.003990  0.652142  0.340331  0.003536\n",
       "13  0.000092  0.011372  0.988473  0.000064\n",
       "14  0.000092  0.001204  0.998647  0.000057\n",
       "15  0.001608  0.627634  0.369347  0.001412"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_probs = {obs : query_policy(ppo, env, obs) for obs in range(16)}\n",
    "pd.DataFrame(action_probs, index=[\"left\", \"down\", \"right\", \"up\"]).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d83f8b3-a489-4da1-b000-402cbf192497",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Viewing stochastic policies\n",
    "\n",
    "We can also view this as an image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "67a7b13e-82f5-4c51-a3ad-e0b27410aa44",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# HIDDEN\n",
    "# df = pd.DataFrame(action_probs, index=[\"left\", \"down\", \"right\", \"up\"]).T\n",
    "# plt.figure(figsize=(8,4))\n",
    "# plt.imshow(df.values.T);\n",
    "# plt.yticks(np.arange(4), labels=[\"left\", \"down\", \"up\", \"right\"]);\n",
    "# plt.xticks(np.arange(16), labels=np.arange(16));\n",
    "# plt.setp(plt.gca().get_xticklabels(), rotation=45, ha=\"right\",\n",
    "#          rotation_mode=\"anchor\");\n",
    "# plt.xlabel(\"observations\");\n",
    "# plt.ylabel(\"actions\");\n",
    "# plt.colorbar(location=\"bottom\");\n",
    "# plt.tight_layout();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "08aed05b-ced6-465f-bc0e-636daf0a0b36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 216x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "utils.plot_action_probs(action_probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e860de2e-9b73-4968-a99f-07da50e5978c",
   "metadata": {},
   "source": [
    "Notes:\n",
    "    \n",
    "This is transposed to fit on the screen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d9e3b1-6715-4883-995b-963d9f2e5c3b",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Acting stochastically\n",
    "\n",
    "`compute_single_action` will act according to these probabilities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "098512e5-5290-4736-99aa-5663d4c3bc12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.0708601e-04, 8.6194783e-01, 1.3743131e-01, 3.1362689e-04],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_probs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "700ac122-31cc-4718-98e0-215e58190c17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "counts = np.bincount([ppo.compute_single_action(0) for _ in range(10_000)])\n",
    "plt.bar([0,1,2,3], counts/10_000)\n",
    "plt.xticks([0,1,2,3]);\n",
    "plt.xlabel(\"Action\");\n",
    "plt.ylabel(\"Empirical dist\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab2dc857-33bd-42e4-a002-797cf8beee3f",
   "metadata": {},
   "source": [
    "#### Acting deterministically\n",
    "\n",
    "We can also tell the agent to act deterministically with `explore=False`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d2c8797d-7eb8-480b-887f-470c46901f9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ppo.compute_single_action(0, explore=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "046bbdf5-ca03-46f9-b6be-2547653d7eff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "print([ppo.compute_single_action(0, explore=False) for _ in range(100)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df58d2f-8ad0-4b16-b3e8-058016123bf4",
   "metadata": {},
   "source": [
    "Often this is desirable, but **sometimes the optimal policy is stochastic**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d576256-a969-4b77-a204-2bb8219450cd",
   "metadata": {},
   "source": [
    "Notes:\n",
    "\n",
    "During training, exploration is a fundamental concept in RL. We will discuss it in Module 4!\n",
    "\n",
    "In Module 4 we'll also see an example where the optimal policy is stochastic, so we would definitely not want to set `explore=False` in deployment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d205da70-1255-437c-8a99-6ea8a5e8d2a0",
   "metadata": {},
   "source": [
    "#### Let's apply what we learned!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd539d44-aa7c-4958-b448-7759f3adc20e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## RLlib config syntax\n",
    "<!-- multiple choice -->\n",
    "\n",
    "Which of the following is **NOT** correct RLlib syntax for instantiating a PPO algorithm instance? Assume the following import has already been run:\n",
    "\n",
    "```python\n",
    "from ray.rllib.algorithms.ppo import PPO, PPOConfig\n",
    "```\n",
    "\n",
    "- [ ] PPOConfig().build(env=\"FrozenLake-v1\")\n",
    "- [ ] PPOConfig().environment(env=\"FrozenLake-v1\").build()\n",
    "- [x] PPOConfig(env=\"FrozenLake-v1\").build()\n",
    "- [ ] PPO(env=\"FrozenLake-v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46809a96-dc1f-4d56-ad40-226c68d70a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # HIDDEN\n",
    "# from ray.rllib.algorithms.ppo import PPO, PPOConfig\n",
    "\n",
    "# PPOConfig().framework(\"torch\").build(env=\"FrozenLake-v1\")\n",
    "# PPOConfig().framework(\"torch\").environment(env=\"FrozenLake-v1\").build()\n",
    "# PPO(env=\"FrozenLake-v1\", config={\"framework\" : \"torch\"})\n",
    "# PPOConfig(env=\"FrozenLake-v1\").framework(\"torch\").build()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce5cbd1-2669-4470-abd7-573ac1b8205a",
   "metadata": {},
   "source": [
    "## Saving/restoring models\n",
    "<!-- multiple choice -->\n",
    "\n",
    "Which of the following is **NOT** a plausible use of saving (\"checkpointing\") models in RLlib?\n",
    "\n",
    "- [x] Checkpointing generates cryptocurrency.\n",
    "- [ ] In a course like this, loading a checkpoint means you don't always have to wait for models to train.\n",
    "- [ ] Saved models can be stored, shared, copied and/or moved for deployment.\n",
    "- [ ] Training can be resumed from a checkpoint in case it fails and needs to be restarted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e27b60-beab-4bd8-a978-198920b26d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "# now that we have the fancier plotting code from module 5 (DQN), we could use it here also"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a2dd37-444e-4bfc-a7eb-220271154672",
   "metadata": {},
   "source": [
    "## Cartpole environment\n",
    "<!-- coding exercise -->\n",
    "\n",
    "A famous benchmark environment in RL is the _Cartpole_ environment, in which the agent must balance an [inverted pendulum](https://en.wikipedia.org/wiki/Inverted_pendulum) by applying force on the cart (at the bottom) to keep it stable. More information is available in the gym documentation [here](https://www.gymlibrary.ml/environments/classic_control/cart_pole/).\n",
    "\n",
    "Note: the code below imports the env `MyCartPole`. This is identical to gym's `'CartPole-v1'` except that the rendering method has been overridden with something that can be displayed inside of this interactive course platform. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c47b1f3a-66b1-463f-9e59-2b3c903cb377",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION\n",
    "import numpy as np\n",
    "import time\n",
    "from IPython import display\n",
    "\n",
    "from envs import MyCartPole\n",
    "from ray.rllib.algorithms.ppo import PPO, PPOConfig\n",
    "\n",
    "config = (\n",
    "    PPOConfig()\\\n",
    "    .framework(\"torch\")\\\n",
    "    .rollouts(create_env_on_local_worker=True)\\\n",
    "    .debugging(seed=0, log_level=\"ERROR\")\\\n",
    "    .training(model={\"fcnet_hiddens\" : [32,32]})\n",
    ")\n",
    "\n",
    "ppo = config.build(env=MyCartPole);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337c5eba-1698-44d4-9a45-3e38eb6765f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rewards = []\n",
    "for i in range(50):\n",
    "    out = ppo.train()\n",
    "    rewards.append(out[\"episode_reward_mean\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d102289-3f41-4dce-b6ca-a649820450db",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = MyCartPole()\n",
    "obs = env.reset()\n",
    "\n",
    "for i in range(20):\n",
    "    \n",
    "    action = ppo.compute_single_action(obs)\n",
    "    \n",
    "    obs, reward, done, _ = env.step(action)\n",
    "\n",
    "    env.render()\n",
    "    time.sleep(0.2)\n",
    "\n",
    "display.clear_output(wait=True);\n",
    "\n",
    "# make a plot of prob(push left) vs. angle??"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2dc421-4a02-45e3-974d-49d30b1dfe67",
   "metadata": {},
   "source": [
    "# TODO\n",
    "\n",
    "need to be able to load a trained model here, which is currently not working. then, split this up into 2 coding exercises, one with the video and one with the plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5a7f1a-4fd7-4182-b4f9-2a23fb5618de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import query_policy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "angle_range_deg = np.arange(-15,15,0.1)\n",
    "push_left_probs = 0*angle_range_deg\n",
    "\n",
    "for i, angle_deg in enumerate(angle_range_deg):\n",
    "    angle_rad = angle_deg/180*np.pi\n",
    "    \n",
    "    obs = np.zeros(4)\n",
    "    obs[2] = angle_rad\n",
    "\n",
    "    push_left_probs[i] = query_policy(ppo, env, obs, actions=[0,1])[0]\n",
    "\n",
    "plt.plot(angle_range_deg, push_left_probs);\n",
    "plt.xlabel(\"pole angle (degrees)\")\n",
    "plt.ylabel(\"probability of pushing left\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a14614-d1c5-4319-9559-543ecf432699",
   "metadata": {},
   "source": [
    "#### Interpreting the plot\n",
    "\n",
    "How does the observed pole angle affect the trained agent's probability of pushing left?\n",
    "\n",
    "- [ ] Positive pole angles (leaning right) result in the agent pushing the cart left. | The agent wants to push the cart underneath the top of the pole.\n",
    "- [x] Negative pole angles (leaning left) result in the agent pushing the cart left.\n",
    "- [ ] The agent's probability of pushing left is not significantly affected by the pole angle.\n",
    "- [ ] None of the above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2370b6-7abb-4d23-adad-ada45068d3c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ray2beta]",
   "language": "python",
   "name": "conda-env-ray2beta-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
