{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90c01ab9-1cd0-47d8-a198-e07e36e2c1fc",
   "metadata": {
    "tags": []
   },
   "source": [
    "## RLlib continued"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e74417a3-63bc-4000-951a-72ab882b689e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HIDDEN\n",
    "import gym\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['font.size'] = 16\n",
    "from ray import rllib\n",
    "from ray.rllib.algorithms.ppo import PPO, PPOConfig\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f67da7-14aa-456a-84bb-5813db493143",
   "metadata": {},
   "source": [
    "#### RLlib features\n",
    "\n",
    "- So far we've seen training, evaluation, and \"prediction\" with RLlib.\n",
    "- Next we'll explore a few more features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e07d9e0-cc95-43f0-81b4-2b937070a7f2",
   "metadata": {},
   "source": [
    "#### Algorithm configs\n",
    "\n",
    "Remember this code?\n",
    "\n",
    "```python\n",
    "from ray.rllib.algorithms.ppo import PPO, PPOConfig\n",
    "ppo = PPO(env=\"FrozenLake-v1\", config=ppo_config)\n",
    "```\n",
    "\n",
    "Previously, we hid the `ppo_config`. Now we'll delve into it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6e49ba6-315f-42d5-949a-6ae5d98ae758",
   "metadata": {},
   "outputs": [],
   "source": [
    "ppo_config = PPOConfig()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c0eec80-c3e8-4bf9-8fa5-a913ad32ebaf",
   "metadata": {},
   "source": [
    "The number of options is way too many to read:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ae2a8631-271c-4f85-8715-6cf1f95393f5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "125"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ppo_config.to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "84d1087e-c1fb-4b1e-abb5-c9d7520c87dd",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'extra_python_environs_for_driver': {},\n",
       " 'extra_python_environs_for_worker': {},\n",
       " 'num_gpus': 0,\n",
       " 'num_cpus_per_worker': 1,\n",
       " 'num_gpus_per_worker': 0,\n",
       " '_fake_gpus': False,\n",
       " 'custom_resources_per_worker': {},\n",
       " 'placement_strategy': 'PACK',\n",
       " 'eager_tracing': False,\n",
       " 'eager_max_retraces': 20,\n",
       " 'tf_session_args': {'intra_op_parallelism_threads': 2,\n",
       "  'inter_op_parallelism_threads': 2,\n",
       "  'gpu_options': {'allow_growth': True},\n",
       "  'log_device_placement': False,\n",
       "  'device_count': {'CPU': 1},\n",
       "  'allow_soft_placement': True},\n",
       " 'local_tf_session_args': {'intra_op_parallelism_threads': 8,\n",
       "  'inter_op_parallelism_threads': 8},\n",
       " 'env': None,\n",
       " 'env_config': {'is_slippery': False},\n",
       " 'observation_space': None,\n",
       " 'action_space': None,\n",
       " 'env_task_fn': None,\n",
       " 'render_env': False,\n",
       " 'clip_rewards': None,\n",
       " 'normalize_actions': True,\n",
       " 'clip_actions': False,\n",
       " 'disable_env_checking': False,\n",
       " 'num_workers': 2,\n",
       " 'num_envs_per_worker': 1,\n",
       " 'sample_collector': ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector,\n",
       " 'sample_async': False,\n",
       " 'rollout_fragment_length': 200,\n",
       " 'batch_mode': 'truncate_episodes',\n",
       " 'remote_worker_envs': False,\n",
       " 'remote_env_batch_wait_ms': 0,\n",
       " 'validate_workers_after_construction': True,\n",
       " 'ignore_worker_failures': False,\n",
       " 'recreate_failed_workers': False,\n",
       " 'restart_failed_sub_environments': False,\n",
       " 'num_consecutive_worker_failures_tolerance': 100,\n",
       " 'horizon': None,\n",
       " 'soft_horizon': False,\n",
       " 'no_done_at_end': False,\n",
       " 'preprocessor_pref': 'deepmind',\n",
       " 'observation_filter': 'NoFilter',\n",
       " 'synchronize_filters': True,\n",
       " 'compress_observations': False,\n",
       " 'gamma': 0.99,\n",
       " 'lr': 5e-05,\n",
       " 'train_batch_size': 4000,\n",
       " 'model': {'fcnet_hiddens': [32, 32]},\n",
       " 'optimizer': {},\n",
       " 'explore': True,\n",
       " 'exploration_config': {'type': 'StochasticSampling'},\n",
       " 'input_config': {},\n",
       " 'actions_in_input_normalized': False,\n",
       " 'off_policy_estimation_methods': {},\n",
       " 'postprocess_inputs': False,\n",
       " 'shuffle_buffer_size': 0,\n",
       " 'output': None,\n",
       " 'output_config': {},\n",
       " 'output_compress_columns': ['obs', 'new_obs'],\n",
       " 'output_max_file_size': 67108864,\n",
       " 'evaluation_interval': None,\n",
       " 'evaluation_duration': 10,\n",
       " 'evaluation_duration_unit': 'episodes',\n",
       " 'evaluation_parallel_to_training': False,\n",
       " 'evaluation_config': {},\n",
       " 'evaluation_num_workers': 0,\n",
       " 'always_attach_evaluation_results': False,\n",
       " 'in_evaluation': False,\n",
       " 'sync_filters_on_rollout_workers_timeout_s': 60.0,\n",
       " 'keep_per_episode_custom_metrics': False,\n",
       " 'metrics_episode_collection_timeout_s': 180,\n",
       " 'metrics_num_episodes_for_smoothing': 100,\n",
       " 'min_time_s_per_iteration': None,\n",
       " 'min_train_timesteps_per_iteration': 0,\n",
       " 'min_sample_timesteps_per_iteration': 0,\n",
       " 'logger_creator': None,\n",
       " 'logger_config': None,\n",
       " 'log_level': 'ERROR',\n",
       " 'log_sys_usage': True,\n",
       " 'fake_sampler': False,\n",
       " 'seed': 0,\n",
       " '_tf_policy_handles_more_than_one_loss': False,\n",
       " '_disable_preprocessor_api': False,\n",
       " '_disable_action_flattening': False,\n",
       " '_disable_execution_plan_api': True,\n",
       " 'simple_optimizer': -1,\n",
       " 'monitor': -1,\n",
       " 'evaluation_num_episodes': -1,\n",
       " 'metrics_smoothing_episodes': -1,\n",
       " 'timesteps_per_iteration': -1,\n",
       " 'min_iter_time_s': -1,\n",
       " 'collect_metrics_timeout': -1,\n",
       " 'buffer_size': -1,\n",
       " 'prioritized_replay': -1,\n",
       " 'learning_starts': -1,\n",
       " 'replay_batch_size': -1,\n",
       " 'replay_sequence_length': None,\n",
       " 'prioritized_replay_alpha': -1,\n",
       " 'prioritized_replay_beta': -1,\n",
       " 'prioritized_replay_eps': -1,\n",
       " 'min_time_s_per_reporting': -1,\n",
       " 'min_train_timesteps_per_reporting': -1,\n",
       " 'min_sample_timesteps_per_reporting': -1,\n",
       " 'input_evaluation': -1,\n",
       " 'lr_schedule': None,\n",
       " 'use_critic': True,\n",
       " 'use_gae': True,\n",
       " 'kl_coeff': 0.2,\n",
       " 'sgd_minibatch_size': 128,\n",
       " 'num_sgd_iter': 30,\n",
       " 'shuffle_sequences': True,\n",
       " 'vf_loss_coeff': 1.0,\n",
       " 'entropy_coeff': 0.0,\n",
       " 'entropy_coeff_schedule': None,\n",
       " 'clip_param': 0.3,\n",
       " 'vf_clip_param': 10.0,\n",
       " 'grad_clip': None,\n",
       " 'kl_target': 0.01,\n",
       " 'vf_share_layers': -1,\n",
       " 'lambda': 1.0,\n",
       " 'input': 'sampler',\n",
       " 'multiagent': {'policies': {},\n",
       "  'policy_map_capacity': 100,\n",
       "  'policy_map_cache': None,\n",
       "  'policy_mapping_fn': None,\n",
       "  'policies_to_train': None,\n",
       "  'observation_fn': None,\n",
       "  'replay_mode': 'independent',\n",
       "  'count_steps_by': 'env_steps'},\n",
       " 'callbacks': ray.rllib.algorithms.callbacks.DefaultCallbacks,\n",
       " 'create_env_on_driver': True,\n",
       " 'custom_eval_function': None,\n",
       " 'framework': 'torch',\n",
       " 'num_cpus_for_driver': 1}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ppo_config.to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af4f47b-ef9a-4443-9dad-d5bb2e533b3b",
   "metadata": {},
   "source": [
    "#### Algorithm configs\n",
    "\n",
    "- When we instantiate a `PPOConfig()` we get the default config values.\n",
    "- There are a few values that we changed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0308301b-4f37-4218-8360-862b18574c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ppo_config = ppo_config.framework(\"torch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e78fb6f4-36b4-424d-8535-9473934b7e88",
   "metadata": {},
   "source": [
    "⬆️ Changes the framework from tensorflow (default) to pytorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d746f6bf-d5d0-41b6-b717-796d91a45f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "ppo_config = ppo_config.debugging(seed=0, log_level=\"ERROR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ca478e-2c3b-4c47-beba-94014f376469",
   "metadata": {},
   "source": [
    "⬆️ Sets a random seed for reproducibility of the course, reduces the warnings displayed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b8890eef-bbad-41a7-af8e-7fac509eb04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ppo_config = ppo_config.training(model={\"fcnet_hiddens\" : [32, 32]})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b4ecc0b-0d85-4aec-8011-28a2adc309f3",
   "metadata": {},
   "source": [
    "⬆️ Sets the policy neural network to have a smaller-than-default architecture, which helps the course materials run faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "098f8aa8-16b3-455e-9a92-4d92063da388",
   "metadata": {},
   "outputs": [],
   "source": [
    "ppo_config = ppo_config.rollouts(create_env_on_local_worker=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a68b5322-8fb4-4d07-9913-6696aa8905cf",
   "metadata": {},
   "source": [
    "⬆️ This relates to Ray, which we will touch on briefly in Module 5, but skip for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4e215df8-9e3e-4607-a831-b083cd949cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "ppo_config = ppo_config.environment(env_config={\"is_slippery\" : False})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc6380d-b76e-4960-a3c0-9e1618109ebd",
   "metadata": {},
   "source": [
    "⬆️ This is how we set env parameters, in this case specifying the non-slippery Frozen Lake."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "322b9bd0-8426-4648-80c0-479f96f6cddc",
   "metadata": {},
   "source": [
    "Notes:\n",
    "\n",
    "The random seed is only for the algorithm itself, e.g. randomness in the neural network optimization. It doesn't set the random seed for the environment's own randomness. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e834f6c3-0b1f-49dc-8c65-136e8b93fa5f",
   "metadata": {},
   "source": [
    "#### Algorithm configs\n",
    "\n",
    "We can also generate this config in one giant line of Python as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "447b397b-a875-417b-8bc7-ef862229ca64",
   "metadata": {},
   "outputs": [],
   "source": [
    "ppo_config = (\n",
    "    PPOConfig()\\\n",
    "    .framework(\"torch\")\\\n",
    "    .rollouts(create_env_on_local_worker=True)\\\n",
    "    .debugging(seed=0, log_level=\"ERROR\")\\\n",
    "    .training(model={\"fcnet_hiddens\" : [32, 32]})\\\n",
    "    .environment(env_config={\"is_slippery\" : False})\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7254e6af-7f07-4afc-b46d-575214eed645",
   "metadata": {},
   "source": [
    "(The `\\` character just means the line of Python continues below.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8cfa9d1-fbfa-455f-a722-950b634d4d45",
   "metadata": {},
   "source": [
    "Notes:\n",
    "\n",
    "We'll discuss tuning in Module 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30eb0986-9e52-4656-9819-7c43b6d083a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HIDDEN\n",
    "algo_config = (\n",
    "    PPOConfig()\\\n",
    "    .framework(\"torch\")\\\n",
    "    .rollouts(create_env_on_local_worker=True)\\\n",
    "    .debugging(seed=0, log_level=\"ERROR\")\\\n",
    "    .training(model={\"fcnet_hiddens\" : [32, 32]})\\\n",
    "    .environment(env_config={\"is_slippery\" : False})\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "185074d6-c847-4790-94ba-381030616f56",
   "metadata": {},
   "source": [
    "#### Building an algorithm from the config\n",
    "\n",
    "We previously instantiated our PPO algorithm like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3f8b977e-e59d-4afd-9d82-2010be65ed40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RolloutWorker pid=22500)\u001b[0m /Users/mike/git/anyscale/ray/python/ray/rllib/utils/debug/deterministic.py:42: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=22500)\u001b[0m   if LooseVersion(torch.__version__) >= LooseVersion(\"1.8.0\"):\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=22499)\u001b[0m /Users/mike/git/anyscale/ray/python/ray/rllib/utils/debug/deterministic.py:42: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=22499)\u001b[0m   if LooseVersion(torch.__version__) >= LooseVersion(\"1.8.0\"):\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=22500)\u001b[0m /Users/mike/miniconda3/envs/ray2beta/lib/python3.9/site-packages/gym/core.py:329: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=22500)\u001b[0m   deprecation(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=22500)\u001b[0m /Users/mike/miniconda3/envs/ray2beta/lib/python3.9/site-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=22500)\u001b[0m   deprecation(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=22500)\u001b[0m /Users/mike/miniconda3/envs/ray2beta/lib/python3.9/site-packages/gym/core.py:268: DeprecationWarning: \u001b[33mWARN: Function `env.seed(seed)` is marked as deprecated and will be removed in the future. Please use `env.reset(seed=seed)` instead.\u001b[0m\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=22500)\u001b[0m   deprecation(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=22499)\u001b[0m /Users/mike/miniconda3/envs/ray2beta/lib/python3.9/site-packages/gym/core.py:329: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=22499)\u001b[0m   deprecation(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=22499)\u001b[0m /Users/mike/miniconda3/envs/ray2beta/lib/python3.9/site-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=22499)\u001b[0m   deprecation(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=22499)\u001b[0m /Users/mike/miniconda3/envs/ray2beta/lib/python3.9/site-packages/gym/core.py:268: DeprecationWarning: \u001b[33mWARN: Function `env.seed(seed)` is marked as deprecated and will be removed in the future. Please use `env.reset(seed=seed)` instead.\u001b[0m\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=22499)\u001b[0m   deprecation(\n"
     ]
    }
   ],
   "source": [
    "ppo = PPO(env=\"FrozenLake-v1\", config=ppo_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "499bf30c-c42a-40d5-957c-477686ee7ee7",
   "metadata": {},
   "source": [
    "The preferred syntax in the latest release of Ray/RLlib is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "217ddfaf-0332-42a8-8178-23c949a80b3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RolloutWorker pid=22649)\u001b[0m /Users/mike/git/anyscale/ray/python/ray/rllib/utils/debug/deterministic.py:42: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=22649)\u001b[0m   if LooseVersion(torch.__version__) >= LooseVersion(\"1.8.0\"):\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=22649)\u001b[0m /Users/mike/miniconda3/envs/ray2beta/lib/python3.9/site-packages/gym/core.py:329: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=22649)\u001b[0m   deprecation(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=22649)\u001b[0m /Users/mike/miniconda3/envs/ray2beta/lib/python3.9/site-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=22649)\u001b[0m   deprecation(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=22649)\u001b[0m /Users/mike/miniconda3/envs/ray2beta/lib/python3.9/site-packages/gym/core.py:268: DeprecationWarning: \u001b[33mWARN: Function `env.seed(seed)` is marked as deprecated and will be removed in the future. Please use `env.reset(seed=seed)` instead.\u001b[0m\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=22649)\u001b[0m   deprecation(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=22650)\u001b[0m /Users/mike/git/anyscale/ray/python/ray/rllib/utils/debug/deterministic.py:42: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=22650)\u001b[0m   if LooseVersion(torch.__version__) >= LooseVersion(\"1.8.0\"):\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=22650)\u001b[0m /Users/mike/miniconda3/envs/ray2beta/lib/python3.9/site-packages/gym/core.py:329: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=22650)\u001b[0m   deprecation(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=22650)\u001b[0m /Users/mike/miniconda3/envs/ray2beta/lib/python3.9/site-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=22650)\u001b[0m   deprecation(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=22650)\u001b[0m /Users/mike/miniconda3/envs/ray2beta/lib/python3.9/site-packages/gym/core.py:268: DeprecationWarning: \u001b[33mWARN: Function `env.seed(seed)` is marked as deprecated and will be removed in the future. Please use `env.reset(seed=seed)` instead.\u001b[0m\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=22650)\u001b[0m   deprecation(\n"
     ]
    }
   ],
   "source": [
    "ppo = ppo_config.build(env=\"FrozenLake-v1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e483661-3f65-4f61-8db4-3ac3a650619d",
   "metadata": {},
   "source": [
    "As a third option, you can also specify the environment in the config rather than as an argument to `build`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b2be522c-6b40-4b0d-8cf3-c473b420c325",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RolloutWorker pid=8200)\u001b[0m /Users/mike/git/anyscale/ray/python/ray/rllib/utils/debug/deterministic.py:42: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=8200)\u001b[0m   if LooseVersion(torch.__version__) >= LooseVersion(\"1.8.0\"):\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=8200)\u001b[0m /Users/mike/miniconda3/envs/ray2beta/lib/python3.9/site-packages/gym/core.py:329: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=8200)\u001b[0m   deprecation(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=8200)\u001b[0m /Users/mike/miniconda3/envs/ray2beta/lib/python3.9/site-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=8200)\u001b[0m   deprecation(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=8200)\u001b[0m /Users/mike/miniconda3/envs/ray2beta/lib/python3.9/site-packages/gym/core.py:268: DeprecationWarning: \u001b[33mWARN: Function `env.seed(seed)` is marked as deprecated and will be removed in the future. Please use `env.reset(seed=seed)` instead.\u001b[0m\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=8200)\u001b[0m   deprecation(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=8201)\u001b[0m /Users/mike/git/anyscale/ray/python/ray/rllib/utils/debug/deterministic.py:42: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=8201)\u001b[0m   if LooseVersion(torch.__version__) >= LooseVersion(\"1.8.0\"):\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=8201)\u001b[0m /Users/mike/miniconda3/envs/ray2beta/lib/python3.9/site-packages/gym/core.py:329: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=8201)\u001b[0m   deprecation(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=8201)\u001b[0m /Users/mike/miniconda3/envs/ray2beta/lib/python3.9/site-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=8201)\u001b[0m   deprecation(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=8201)\u001b[0m /Users/mike/miniconda3/envs/ray2beta/lib/python3.9/site-packages/gym/core.py:268: DeprecationWarning: \u001b[33mWARN: Function `env.seed(seed)` is marked as deprecated and will be removed in the future. Please use `env.reset(seed=seed)` instead.\u001b[0m\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=8201)\u001b[0m   deprecation(\n",
      "*** SIGTERM received at time=1658795347 ***\n",
      "PC: @        0x195ef0c20  (unknown)  kevent\n",
      "[2022-07-25 17:29:07,686 E 21608 1787749] logging.cc:325: *** SIGTERM received at time=1658795347 ***\n",
      "[2022-07-25 17:29:07,814 E 21608 1787749] logging.cc:325: PC: @        0x195ef0c20  (unknown)  kevent\n"
     ]
    }
   ],
   "source": [
    "ppo_config.environment(env=\"FrozenLake-v1\")\n",
    "\n",
    "ppo = ppo_config.build()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef84da1-19ef-4300-8555-7e6e65b3e3b7",
   "metadata": {},
   "source": [
    "The end result is the same whichever way you choose."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e3069d-b826-447f-ad34-24eb1d912c4a",
   "metadata": {},
   "source": [
    "#### Saving models\n",
    "\n",
    "- We may want to save trained agents for future use.\n",
    "- This is also called _checkpointing_, especially when done during a training loop.\n",
    "- In RLlib, this can be done simply with:\n",
    "\n",
    "```python\n",
    "algo.save(path_to_checkpoint)\n",
    "```\n",
    "\n",
    "It can then be later restored with\n",
    "\n",
    "```python\n",
    "algo.restore(path_to_checkpoint)\n",
    "```\n",
    "\n",
    "Just make sure you create the trainer with the same environment and parameters when restoring from a checkpoint."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27092e6c-772e-4940-b140-fa77b8469397",
   "metadata": {},
   "source": [
    "#### Restoring models\n",
    "\n",
    "- Let's restore a PPO algorithm object\n",
    "- We need to set it up with the same config first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "517db53e-410c-441f-8823-53b76a3cf825",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RolloutWorker pid=32621)\u001b[0m /Users/mike/git/anyscale/ray/python/ray/rllib/utils/debug/deterministic.py:42: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=32621)\u001b[0m   if LooseVersion(torch.__version__) >= LooseVersion(\"1.8.0\"):\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=32621)\u001b[0m /Users/mike/miniconda3/envs/ray2beta/lib/python3.9/site-packages/gym/core.py:329: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=32621)\u001b[0m   deprecation(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=32621)\u001b[0m /Users/mike/miniconda3/envs/ray2beta/lib/python3.9/site-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=32621)\u001b[0m   deprecation(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=32621)\u001b[0m /Users/mike/miniconda3/envs/ray2beta/lib/python3.9/site-packages/gym/core.py:268: DeprecationWarning: \u001b[33mWARN: Function `env.seed(seed)` is marked as deprecated and will be removed in the future. Please use `env.reset(seed=seed)` instead.\u001b[0m\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=32621)\u001b[0m   deprecation(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=32622)\u001b[0m /Users/mike/git/anyscale/ray/python/ray/rllib/utils/debug/deterministic.py:42: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=32622)\u001b[0m   if LooseVersion(torch.__version__) >= LooseVersion(\"1.8.0\"):\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=32622)\u001b[0m /Users/mike/miniconda3/envs/ray2beta/lib/python3.9/site-packages/gym/core.py:329: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=32622)\u001b[0m   deprecation(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=32622)\u001b[0m /Users/mike/miniconda3/envs/ray2beta/lib/python3.9/site-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=32622)\u001b[0m   deprecation(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=32622)\u001b[0m /Users/mike/miniconda3/envs/ray2beta/lib/python3.9/site-packages/gym/core.py:268: DeprecationWarning: \u001b[33mWARN: Function `env.seed(seed)` is marked as deprecated and will be removed in the future. Please use `env.reset(seed=seed)` instead.\u001b[0m\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=32622)\u001b[0m   deprecation(\n"
     ]
    }
   ],
   "source": [
    "ppo_config = (\n",
    "    PPOConfig()\\\n",
    "    .framework(\"torch\")\\\n",
    "    .rollouts(create_env_on_local_worker=True)\\\n",
    "    .debugging(seed=0, log_level=\"ERROR\")\\\n",
    "    .training(model={\"fcnet_hiddens\" : [64,64]})\n",
    "    .environment(env_config={\"is_slippery\" : True})\\\n",
    "    .evaluation(evaluation_config = {\"explore\" : False})\n",
    ")\n",
    "\n",
    "ppo = ppo_config.build(\"FrozenLake-v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2e39804d-b683-404c-9a7a-443569b284d7",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't convert np.ndarray of type numpy.object_. The only supported types are: float64, float32, float16, complex64, complex128, int64, int32, int16, int8, uint8, and bool.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [34]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mppo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrestore\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodels/FrozenLakeSlippery-256-Ray2/checkpoint-50\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/git/anyscale/ray/python/ray/tune/trainable/trainable.py:585\u001b[0m, in \u001b[0;36mTrainable.restore\u001b[0;34m(self, checkpoint_path, checkpoint_node_ip)\u001b[0m\n\u001b[1;32m    583\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mload_checkpoint(checkpoint_dict)\n\u001b[1;32m    584\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 585\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_checkpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheckpoint_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    586\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time_since_restore \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m    587\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timesteps_since_restore \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m~/git/anyscale/ray/python/ray/rllib/algorithms/algorithm.py:1444\u001b[0m, in \u001b[0;36mAlgorithm.load_checkpoint\u001b[0;34m(self, checkpoint_path)\u001b[0m\n\u001b[1;32m   1441\u001b[0m \u001b[38;5;129m@override\u001b[39m(Trainable)\n\u001b[1;32m   1442\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_checkpoint\u001b[39m(\u001b[38;5;28mself\u001b[39m, checkpoint_path: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1443\u001b[0m     extra_data \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;28mopen\u001b[39m(checkpoint_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m-> 1444\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__setstate__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mextra_data\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/git/anyscale/ray/python/ray/rllib/algorithms/algorithm.py:2199\u001b[0m, in \u001b[0;36mAlgorithm.__setstate__\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m   2197\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__setstate__\u001b[39m(\u001b[38;5;28mself\u001b[39m, state: \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m   2198\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mworkers\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mworker\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m state:\n\u001b[0;32m-> 2199\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlocal_worker\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrestore\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mworker\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2200\u001b[0m         remote_state \u001b[38;5;241m=\u001b[39m ray\u001b[38;5;241m.\u001b[39mput(state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mworker\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m   2201\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mworkers\u001b[38;5;241m.\u001b[39mremote_workers():\n",
      "File \u001b[0;32m~/git/anyscale/ray/python/ray/rllib/evaluation/rollout_worker.py:1575\u001b[0m, in \u001b[0;36mRolloutWorker.restore\u001b[0;34m(self, objs)\u001b[0m\n\u001b[1;32m   1567\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_policy(\n\u001b[1;32m   1568\u001b[0m             policy_id\u001b[38;5;241m=\u001b[39mpid,\n\u001b[1;32m   1569\u001b[0m             policy_cls\u001b[38;5;241m=\u001b[39mpol_spec\u001b[38;5;241m.\u001b[39mpolicy_class,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1572\u001b[0m             config\u001b[38;5;241m=\u001b[39mpol_spec\u001b[38;5;241m.\u001b[39mconfig,\n\u001b[1;32m   1573\u001b[0m         )\n\u001b[1;32m   1574\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1575\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpolicy_map\u001b[49m\u001b[43m[\u001b[49m\u001b[43mpid\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_state\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/git/anyscale/ray/python/ray/rllib/policy/torch_mixins.py:113\u001b[0m, in \u001b[0;36mKLCoeffMixin.set_state\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkl_coeff \u001b[38;5;241m=\u001b[39m state\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcurrent_kl_coeff\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkl_coeff\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    112\u001b[0m \u001b[38;5;66;03m# Call super's set_state with rest of the state dict.\u001b[39;00m\n\u001b[0;32m--> 113\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_state\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/git/anyscale/ray/python/ray/rllib/policy/torch_policy_v2.py:914\u001b[0m, in \u001b[0;36mTorchPolicyV2.set_state\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m    912\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(optimizer_vars) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizers)\n\u001b[1;32m    913\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m o, s \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizers, optimizer_vars):\n\u001b[0;32m--> 914\u001b[0m         optim_state_dict \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_to_torch_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    915\u001b[0m         o\u001b[38;5;241m.\u001b[39mload_state_dict(optim_state_dict)\n\u001b[1;32m    916\u001b[0m \u001b[38;5;66;03m# Set exploration's state.\u001b[39;00m\n",
      "File \u001b[0;32m~/git/anyscale/ray/python/ray/rllib/utils/torch_utils.py:178\u001b[0m, in \u001b[0;36mconvert_to_torch_tensor\u001b[0;34m(x, device)\u001b[0m\n\u001b[1;32m    175\u001b[0m         tensor \u001b[38;5;241m=\u001b[39m tensor\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[1;32m    176\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tensor \u001b[38;5;28;01mif\u001b[39;00m device \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m tensor\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m--> 178\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_structure\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmapping\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ray2beta/lib/python3.9/site-packages/tree/__init__.py:430\u001b[0m, in \u001b[0;36mmap_structure\u001b[0;34m(func, *structures, **kwargs)\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m other \u001b[38;5;129;01min\u001b[39;00m structures[\u001b[38;5;241m1\u001b[39m:]:\n\u001b[1;32m    428\u001b[0m   assert_same_structure(structures[\u001b[38;5;241m0\u001b[39m], other, check_types\u001b[38;5;241m=\u001b[39mcheck_types)\n\u001b[1;32m    429\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m unflatten_as(structures[\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m--> 430\u001b[0m                     [func(\u001b[38;5;241m*\u001b[39margs) \u001b[38;5;28;01mfor\u001b[39;00m args \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mmap\u001b[39m(flatten, structures))])\n",
      "File \u001b[0;32m~/miniconda3/envs/ray2beta/lib/python3.9/site-packages/tree/__init__.py:430\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m other \u001b[38;5;129;01min\u001b[39;00m structures[\u001b[38;5;241m1\u001b[39m:]:\n\u001b[1;32m    428\u001b[0m   assert_same_structure(structures[\u001b[38;5;241m0\u001b[39m], other, check_types\u001b[38;5;241m=\u001b[39mcheck_types)\n\u001b[1;32m    429\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m unflatten_as(structures[\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m--> 430\u001b[0m                     [\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m args \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mmap\u001b[39m(flatten, structures))])\n",
      "File \u001b[0;32m~/git/anyscale/ray/python/ray/rllib/utils/torch_utils.py:172\u001b[0m, in \u001b[0;36mconvert_to_torch_tensor.<locals>.mapping\u001b[0;34m(item)\u001b[0m\n\u001b[1;32m    169\u001b[0m         tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(item)\n\u001b[1;32m    170\u001b[0m \u001b[38;5;66;03m# Everything else: Convert to numpy, then wrap as torch tensor.\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 172\u001b[0m     tensor \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;66;03m# Floatify all float64 tensors.\u001b[39;00m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tensor\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m torch\u001b[38;5;241m.\u001b[39mdouble:\n",
      "\u001b[0;31mTypeError\u001b[0m: can't convert np.ndarray of type numpy.object_. The only supported types are: float64, float32, float16, complex64, complex128, int64, int32, int16, int8, uint8, and bool."
     ]
    }
   ],
   "source": [
    "ppo.restore(\"models/FrozenLakeSlippery-256-Ray2/checkpoint-50\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db71b112-0918-4b7c-9275-f6bb38417640",
   "metadata": {},
   "source": [
    "Notes:\n",
    "\n",
    "Apparently, it was trained for 30 iterations, 124k time steps, 1 minute, 17k episodes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370d6ffb-b48b-4209-b7b8-ce0cb4d45e8c",
   "metadata": {},
   "source": [
    "#### Viewing stochastic policies\n",
    "\n",
    "- If we want to see what a policy does, we can use `compute_single action`\n",
    "- But, some RL algorithms, including PPO, learn _stochastic policies_.\n",
    "- We may wish to look at these _action probabilities_.\n",
    "- The code can be viewed on GitHub, but is hidden here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bc24efa0-bc12-4d99-b9c6-88fc9bf10550",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import query_policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7096f91a-7a14-4b9a-905b-603583d46c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"FrozenLake-v1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81533301-9caa-4fcc-a354-45ac8f98dabc",
   "metadata": {},
   "source": [
    "We'll use the trainer we just restored:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9cd397c9-9182-4391-a997-b1e8f23d1c5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.2502399 , 0.2493437 , 0.25035876, 0.25005776], dtype=float32)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_policy(ppo, env, obs=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c43dbb9c-06f8-4e5e-8c7f-5349d39623c4",
   "metadata": {},
   "source": [
    "Arena:\n",
    "\n",
    "```\n",
    "SFFF\n",
    "FHFH\n",
    "FFFH\n",
    "HFFG\n",
    "```\n",
    "\n",
    "Actions: left (0), down (1), right (2), up (3)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e800476-34c2-4fe4-bb1e-7f9c7e77e94a",
   "metadata": {},
   "source": [
    "Notes:\n",
    "    \n",
    "What we see here are the action probabilities. From the top-left, the agent considers moving left down or right, but not up. It's not entirely clear why left is preferred to up.\n",
    "\n",
    "In module 5 we'll see an RL algorithm that acts deterministically.\n",
    "\n",
    "For a continuous action space this would be different."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44268a54-4855-434d-ac21-d2801f46a322",
   "metadata": {},
   "source": [
    "#### Viewing stochastic policies\n",
    "\n",
    "Let's view all the probabilities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d4a0e388-5ec4-489b-a4cd-53531859fe9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HIDDEN\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a8fdedc6-f162-4c92-a674-648f7ae154c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>left</th>\n",
       "      <th>down</th>\n",
       "      <th>right</th>\n",
       "      <th>up</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.361283</td>\n",
       "      <td>0.304118</td>\n",
       "      <td>0.294776</td>\n",
       "      <td>0.039823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.105703</td>\n",
       "      <td>0.295750</td>\n",
       "      <td>0.179304</td>\n",
       "      <td>0.419243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.878681</td>\n",
       "      <td>0.029604</td>\n",
       "      <td>0.040693</td>\n",
       "      <td>0.051021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.436856</td>\n",
       "      <td>0.262808</td>\n",
       "      <td>0.236151</td>\n",
       "      <td>0.064186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.609650</td>\n",
       "      <td>0.186226</td>\n",
       "      <td>0.176718</td>\n",
       "      <td>0.027406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.430741</td>\n",
       "      <td>0.223148</td>\n",
       "      <td>0.239431</td>\n",
       "      <td>0.106680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.021220</td>\n",
       "      <td>0.542077</td>\n",
       "      <td>0.414277</td>\n",
       "      <td>0.022427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.377155</td>\n",
       "      <td>0.222003</td>\n",
       "      <td>0.223822</td>\n",
       "      <td>0.177020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.016745</td>\n",
       "      <td>0.560293</td>\n",
       "      <td>0.378151</td>\n",
       "      <td>0.044812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.007635</td>\n",
       "      <td>0.627997</td>\n",
       "      <td>0.344637</td>\n",
       "      <td>0.019731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.946561</td>\n",
       "      <td>0.017667</td>\n",
       "      <td>0.021163</td>\n",
       "      <td>0.014609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.164004</td>\n",
       "      <td>0.406202</td>\n",
       "      <td>0.349804</td>\n",
       "      <td>0.079989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.255850</td>\n",
       "      <td>0.341471</td>\n",
       "      <td>0.332879</td>\n",
       "      <td>0.069800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.018130</td>\n",
       "      <td>0.351915</td>\n",
       "      <td>0.582430</td>\n",
       "      <td>0.047525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.003570</td>\n",
       "      <td>0.635234</td>\n",
       "      <td>0.344824</td>\n",
       "      <td>0.016371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.325553</td>\n",
       "      <td>0.313347</td>\n",
       "      <td>0.286977</td>\n",
       "      <td>0.074124</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        left      down     right        up\n",
       "0   0.361283  0.304118  0.294776  0.039823\n",
       "1   0.105703  0.295750  0.179304  0.419243\n",
       "2   0.878681  0.029604  0.040693  0.051021\n",
       "3   0.436856  0.262808  0.236151  0.064186\n",
       "4   0.609650  0.186226  0.176718  0.027406\n",
       "5   0.430741  0.223148  0.239431  0.106680\n",
       "6   0.021220  0.542077  0.414277  0.022427\n",
       "7   0.377155  0.222003  0.223822  0.177020\n",
       "8   0.016745  0.560293  0.378151  0.044812\n",
       "9   0.007635  0.627997  0.344637  0.019731\n",
       "10  0.946561  0.017667  0.021163  0.014609\n",
       "11  0.164004  0.406202  0.349804  0.079989\n",
       "12  0.255850  0.341471  0.332879  0.069800\n",
       "13  0.018130  0.351915  0.582430  0.047525\n",
       "14  0.003570  0.635234  0.344824  0.016371\n",
       "15  0.325553  0.313347  0.286977  0.074124"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_probs = {obs : query_policy(ppo, env, obs) for obs in range(16)}\n",
    "pd.DataFrame(action_probs, index=[\"left\", \"down\", \"right\", \"up\"]).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d83f8b3-a489-4da1-b000-402cbf192497",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Viewing stochastic policies\n",
    "\n",
    "We can also view this as an image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8a9a93cc-951c-44e9-b797-d7cce0bf3209",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HIDDEN\n",
    "df = pd.DataFrame(action_probs, index=[\"left\", \"down\", \"right\", \"up\"]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "67a7b13e-82f5-4c51-a3ad-e0b27410aa44",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,4))\n",
    "plt.imshow(df.values.T);\n",
    "plt.yticks(np.arange(4), labels=[\"left\", \"down\", \"up\", \"right\"]);\n",
    "plt.xticks(np.arange(16), labels=np.arange(16));\n",
    "plt.setp(plt.gca().get_xticklabels(), rotation=45, ha=\"right\",\n",
    "         rotation_mode=\"anchor\");\n",
    "plt.xlabel(\"observations\");\n",
    "plt.ylabel(\"actions\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e860de2e-9b73-4968-a99f-07da50e5978c",
   "metadata": {},
   "source": [
    "Notes:\n",
    "    \n",
    "This is transposed to fit on the screen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d9e3b1-6715-4883-995b-963d9f2e5c3b",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Acting stochastically\n",
    "\n",
    "`compute_single_action` will act according to these probabilities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "098512e5-5290-4736-99aa-5663d4c3bc12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.36128262, 0.30411848, 0.29477558, 0.03982319], dtype=float32)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_probs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "700ac122-31cc-4718-98e0-215e58190c17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "counts = np.bincount([trainer.compute_single_action(0) for _ in range(10_000)])\n",
    "plt.bar([0,1,2,3], counts/10_000)\n",
    "plt.xticks([0,1,2,3]);\n",
    "plt.xlabel(\"Action\");\n",
    "plt.ylabel(\"Empirical dist\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab2dc857-33bd-42e4-a002-797cf8beee3f",
   "metadata": {},
   "source": [
    "#### Acting deterministically\n",
    "\n",
    "We can also tell the agent to act deterministically with `explore=False`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "d2c8797d-7eb8-480b-887f-470c46901f9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ppo.compute_single_action(0, explore=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "046bbdf5-ca03-46f9-b6be-2547653d7eff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print([ppo.compute_single_action(0, explore=False) for _ in range(100)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d576256-a969-4b77-a204-2bb8219450cd",
   "metadata": {},
   "source": [
    "Notes:\n",
    "\n",
    "During training, exploration is a fundamental concept in RL. We will discuss it in Module 4!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d205da70-1255-437c-8a99-6ea8a5e8d2a0",
   "metadata": {},
   "source": [
    "#### Let's apply what we learned!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd539d44-aa7c-4958-b448-7759f3adc20e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## RLlib trainer methods\n",
    "<!-- multiple choice -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb0453c-7d3e-4092-b6c7-6757c05056ed",
   "metadata": {},
   "source": [
    "exercise: draw the max prob of the plicy as a measure of sureness"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe3eb48-7201-4b1e-9e10-f88c8524fcdc",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Visualizing the policy\n",
    "<!-- coding exercise -->\n",
    "\n",
    "In the slides we looked at the probability of"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad1fa7c-90b0-47e6-8f57-b2a070bb85fc",
   "metadata": {},
   "source": [
    "could revisit previs Ex but look at probabilities this time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a2dd37-444e-4bfc-a7eb-220271154672",
   "metadata": {},
   "source": [
    "## Cartpole environment\n",
    "<!-- coding exercise -->\n",
    "\n",
    "A famous benchmark environment in RL is the _Cartpole_ environment, in which the agent must balance an [inverted pendulum](https://en.wikipedia.org/wiki/Inverted_pendulum) by applying force on the cart (at the bottom) to keep it stable. More information is available in the gym documentation [here](https://www.gymlibrary.ml/environments/classic_control/cart_pole/).\n",
    "\n",
    "Note: the code below imports the env `MyCartPole`. This is identical to gym's `'CartPole-v1'` except that the rendering method has been overridden with something that can be displayed inside of this interactive course platform. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47b1f3a-66b1-463f-9e59-2b3c903cb377",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION\n",
    "import numpy as np\n",
    "import time\n",
    "from IPython import display\n",
    "\n",
    "from envs import MyCartPole\n",
    "from ray.rllib.algorithms.ppo import PPO, PPOConfig\n",
    "\n",
    "config = (\n",
    "    PPOConfig()\\\n",
    "    .framework(\"torch\")\\\n",
    "    .rollouts(create_env_on_local_worker=True)\\\n",
    "    .debugging(seed=0, log_level=\"ERROR\")\\\n",
    "    .training(model={\"fcnet_hiddens\" : [32,32]})\n",
    ")\n",
    "\n",
    "ppo = config.build(env=MyCartPole);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337c5eba-1698-44d4-9a45-3e38eb6765f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rewards = []\n",
    "for i in range(50):\n",
    "    out = ppo.train()\n",
    "    rewards.append(out[\"episode_reward_mean\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d102289-3f41-4dce-b6ca-a649820450db",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = MyCartPole()\n",
    "env.reset()\n",
    "\n",
    "for i in range(20):\n",
    "    o,r,d,_ = env.step(np.random.rand()<0.5)\n",
    "\n",
    "    env.render()\n",
    "    time.sleep(0.2)\n",
    "\n",
    "display.clear_output(wait=True);\n",
    "\n",
    "# make a plot of prob(push left) vs. angle??"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ray2beta]",
   "language": "python",
   "name": "conda-env-ray2beta-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
