{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90c01ab9-1cd0-47d8-a198-e07e36e2c1fc",
   "metadata": {
    "tags": []
   },
   "source": [
    "## RLlib continued"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e74417a3-63bc-4000-951a-72ab882b689e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HIDDEN\n",
    "import gym\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['font.size'] = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27a0a477-40eb-44e1-b3aa-59e4f6f31fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HIDDEN\n",
    "import ray\n",
    "import logging\n",
    "ray.init(log_to_driver=False, ignore_reinit_error=True, logging_level=logging.ERROR); # logging.FATAL\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08a296a4-e50a-4530-8034-c8bc1e27671c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HIDDEN\n",
    "\n",
    "from ray.rllib.algorithms.ppo import PPO, PPOConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f67da7-14aa-456a-84bb-5813db493143",
   "metadata": {},
   "source": [
    "#### RLlib features\n",
    "\n",
    "- So far we've seen training, evaluation, and \"prediction\" with RLlib.\n",
    "- Next we'll explore a few more features:\n",
    "   - Algorithm configs\n",
    "   - Saving/restoring models\n",
    "   - Interpreting stochastic policies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e07d9e0-cc95-43f0-81b4-2b937070a7f2",
   "metadata": {},
   "source": [
    "#### Algorithm configs\n",
    "\n",
    "Remember this code?\n",
    "\n",
    "```python\n",
    "from ray.rllib.algorithms.ppo import PPO, PPOConfig\n",
    "ppo = PPO(env=\"FrozenLake-v1\", config=ppo_config)\n",
    "```\n",
    "\n",
    "Previously, we hid the `ppo_config`. Now we'll delve into it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6e49ba6-315f-42d5-949a-6ae5d98ae758",
   "metadata": {},
   "outputs": [],
   "source": [
    "ppo_config = PPOConfig()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c0eec80-c3e8-4bf9-8fa5-a913ad32ebaf",
   "metadata": {},
   "source": [
    "The number of options is way too many to read:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae2a8631-271c-4f85-8715-6cf1f95393f5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "125"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ppo_config.to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84d1087e-c1fb-4b1e-abb5-c9d7520c87dd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'extra_python_environs_for_driver': {},\n",
       " 'extra_python_environs_for_worker': {},\n",
       " 'num_gpus': 0,\n",
       " 'num_cpus_per_worker': 1,\n",
       " 'num_gpus_per_worker': 0,\n",
       " '_fake_gpus': False,\n",
       " 'custom_resources_per_worker': {},\n",
       " 'placement_strategy': 'PACK',\n",
       " 'eager_tracing': False,\n",
       " 'eager_max_retraces': 20,\n",
       " 'tf_session_args': {'intra_op_parallelism_threads': 2,\n",
       "  'inter_op_parallelism_threads': 2,\n",
       "  'gpu_options': {'allow_growth': True},\n",
       "  'log_device_placement': False,\n",
       "  'device_count': {'CPU': 1},\n",
       "  'allow_soft_placement': True},\n",
       " 'local_tf_session_args': {'intra_op_parallelism_threads': 8,\n",
       "  'inter_op_parallelism_threads': 8},\n",
       " 'env': None,\n",
       " 'env_config': {},\n",
       " 'observation_space': None,\n",
       " 'action_space': None,\n",
       " 'env_task_fn': None,\n",
       " 'render_env': False,\n",
       " 'clip_rewards': None,\n",
       " 'normalize_actions': True,\n",
       " 'clip_actions': False,\n",
       " 'disable_env_checking': False,\n",
       " 'num_workers': 2,\n",
       " 'num_envs_per_worker': 1,\n",
       " 'sample_collector': ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector,\n",
       " 'sample_async': False,\n",
       " 'rollout_fragment_length': 200,\n",
       " 'batch_mode': 'truncate_episodes',\n",
       " 'remote_worker_envs': False,\n",
       " 'remote_env_batch_wait_ms': 0,\n",
       " 'validate_workers_after_construction': True,\n",
       " 'ignore_worker_failures': False,\n",
       " 'recreate_failed_workers': False,\n",
       " 'restart_failed_sub_environments': False,\n",
       " 'num_consecutive_worker_failures_tolerance': 100,\n",
       " 'horizon': None,\n",
       " 'soft_horizon': False,\n",
       " 'no_done_at_end': False,\n",
       " 'preprocessor_pref': 'deepmind',\n",
       " 'observation_filter': 'NoFilter',\n",
       " 'synchronize_filters': True,\n",
       " 'compress_observations': False,\n",
       " 'gamma': 0.99,\n",
       " 'lr': 5e-05,\n",
       " 'train_batch_size': 4000,\n",
       " 'model': {'_use_default_native_models': False,\n",
       "  '_disable_preprocessor_api': False,\n",
       "  '_disable_action_flattening': False,\n",
       "  'fcnet_hiddens': [256, 256],\n",
       "  'fcnet_activation': 'tanh',\n",
       "  'conv_filters': None,\n",
       "  'conv_activation': 'relu',\n",
       "  'post_fcnet_hiddens': [],\n",
       "  'post_fcnet_activation': 'relu',\n",
       "  'free_log_std': False,\n",
       "  'no_final_linear': False,\n",
       "  'vf_share_layers': False,\n",
       "  'use_lstm': False,\n",
       "  'max_seq_len': 20,\n",
       "  'lstm_cell_size': 256,\n",
       "  'lstm_use_prev_action': False,\n",
       "  'lstm_use_prev_reward': False,\n",
       "  '_time_major': False,\n",
       "  'use_attention': False,\n",
       "  'attention_num_transformer_units': 1,\n",
       "  'attention_dim': 64,\n",
       "  'attention_num_heads': 1,\n",
       "  'attention_head_dim': 32,\n",
       "  'attention_memory_inference': 50,\n",
       "  'attention_memory_training': 50,\n",
       "  'attention_position_wise_mlp_dim': 32,\n",
       "  'attention_init_gru_gate_bias': 2.0,\n",
       "  'attention_use_n_prev_actions': 0,\n",
       "  'attention_use_n_prev_rewards': 0,\n",
       "  'framestack': True,\n",
       "  'dim': 84,\n",
       "  'grayscale': False,\n",
       "  'zero_mean': True,\n",
       "  'custom_model': None,\n",
       "  'custom_model_config': {},\n",
       "  'custom_action_dist': None,\n",
       "  'custom_preprocessor': None,\n",
       "  'lstm_use_prev_action_reward': -1},\n",
       " 'optimizer': {},\n",
       " 'explore': True,\n",
       " 'exploration_config': {'type': 'StochasticSampling'},\n",
       " 'input_config': {},\n",
       " 'actions_in_input_normalized': False,\n",
       " 'off_policy_estimation_methods': {},\n",
       " 'postprocess_inputs': False,\n",
       " 'shuffle_buffer_size': 0,\n",
       " 'output': None,\n",
       " 'output_config': {},\n",
       " 'output_compress_columns': ['obs', 'new_obs'],\n",
       " 'output_max_file_size': 67108864,\n",
       " 'evaluation_interval': None,\n",
       " 'evaluation_duration': 10,\n",
       " 'evaluation_duration_unit': 'episodes',\n",
       " 'evaluation_parallel_to_training': False,\n",
       " 'evaluation_config': {},\n",
       " 'evaluation_num_workers': 0,\n",
       " 'always_attach_evaluation_results': False,\n",
       " 'in_evaluation': False,\n",
       " 'sync_filters_on_rollout_workers_timeout_s': 60.0,\n",
       " 'keep_per_episode_custom_metrics': False,\n",
       " 'metrics_episode_collection_timeout_s': 180,\n",
       " 'metrics_num_episodes_for_smoothing': 100,\n",
       " 'min_time_s_per_iteration': None,\n",
       " 'min_train_timesteps_per_iteration': 0,\n",
       " 'min_sample_timesteps_per_iteration': 0,\n",
       " 'logger_creator': None,\n",
       " 'logger_config': None,\n",
       " 'log_level': 'WARN',\n",
       " 'log_sys_usage': True,\n",
       " 'fake_sampler': False,\n",
       " 'seed': None,\n",
       " '_tf_policy_handles_more_than_one_loss': False,\n",
       " '_disable_preprocessor_api': False,\n",
       " '_disable_action_flattening': False,\n",
       " '_disable_execution_plan_api': True,\n",
       " 'simple_optimizer': -1,\n",
       " 'monitor': -1,\n",
       " 'evaluation_num_episodes': -1,\n",
       " 'metrics_smoothing_episodes': -1,\n",
       " 'timesteps_per_iteration': -1,\n",
       " 'min_iter_time_s': -1,\n",
       " 'collect_metrics_timeout': -1,\n",
       " 'buffer_size': -1,\n",
       " 'prioritized_replay': -1,\n",
       " 'learning_starts': -1,\n",
       " 'replay_batch_size': -1,\n",
       " 'replay_sequence_length': None,\n",
       " 'prioritized_replay_alpha': -1,\n",
       " 'prioritized_replay_beta': -1,\n",
       " 'prioritized_replay_eps': -1,\n",
       " 'min_time_s_per_reporting': -1,\n",
       " 'min_train_timesteps_per_reporting': -1,\n",
       " 'min_sample_timesteps_per_reporting': -1,\n",
       " 'input_evaluation': -1,\n",
       " 'lr_schedule': None,\n",
       " 'use_critic': True,\n",
       " 'use_gae': True,\n",
       " 'kl_coeff': 0.2,\n",
       " 'sgd_minibatch_size': 128,\n",
       " 'num_sgd_iter': 30,\n",
       " 'shuffle_sequences': True,\n",
       " 'vf_loss_coeff': 1.0,\n",
       " 'entropy_coeff': 0.0,\n",
       " 'entropy_coeff_schedule': None,\n",
       " 'clip_param': 0.3,\n",
       " 'vf_clip_param': 10.0,\n",
       " 'grad_clip': None,\n",
       " 'kl_target': 0.01,\n",
       " 'vf_share_layers': -1,\n",
       " 'lambda': 1.0,\n",
       " 'input': 'sampler',\n",
       " 'multiagent': {'policies': {},\n",
       "  'policy_map_capacity': 100,\n",
       "  'policy_map_cache': None,\n",
       "  'policy_mapping_fn': None,\n",
       "  'policies_to_train': None,\n",
       "  'observation_fn': None,\n",
       "  'replay_mode': 'independent',\n",
       "  'count_steps_by': 'env_steps'},\n",
       " 'callbacks': ray.rllib.algorithms.callbacks.DefaultCallbacks,\n",
       " 'create_env_on_driver': False,\n",
       " 'custom_eval_function': None,\n",
       " 'framework': 'tf',\n",
       " 'num_cpus_for_driver': 1}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ppo_config.to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af4f47b-ef9a-4443-9dad-d5bb2e533b3b",
   "metadata": {},
   "source": [
    "#### Algorithm configs\n",
    "\n",
    "- When we instantiate a `PPOConfig()` we get the default config values.\n",
    "- There are a few values that we changed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0308301b-4f37-4218-8360-862b18574c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ppo_config = ppo_config.framework(\"torch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e78fb6f4-36b4-424d-8535-9473934b7e88",
   "metadata": {},
   "source": [
    "⬆️ Changes the framework from tensorflow (default) to pytorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d746f6bf-d5d0-41b6-b717-796d91a45f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "ppo_config = ppo_config.debugging(seed=0, log_level=\"ERROR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ca478e-2c3b-4c47-beba-94014f376469",
   "metadata": {},
   "source": [
    "⬆️ Sets a random seed for reproducibility of the course, reduces the warnings displayed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b8890eef-bbad-41a7-af8e-7fac509eb04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ppo_config = ppo_config.training(model={\"fcnet_hiddens\" : [32, 32]})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b4ecc0b-0d85-4aec-8011-28a2adc309f3",
   "metadata": {},
   "source": [
    "⬆️ Sets the policy neural network to have a smaller-than-default architecture, which helps the course materials run faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "098f8aa8-16b3-455e-9a92-4d92063da388",
   "metadata": {},
   "outputs": [],
   "source": [
    "ppo_config = ppo_config.rollouts(create_env_on_local_worker=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a68b5322-8fb4-4d07-9913-6696aa8905cf",
   "metadata": {},
   "source": [
    "⬆️ This relates to Ray, which we will touch on briefly in Module 5, but skip for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4e215df8-9e3e-4607-a831-b083cd949cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "ppo_config = ppo_config.environment(env_config={\"is_slippery\" : False})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc6380d-b76e-4960-a3c0-9e1618109ebd",
   "metadata": {},
   "source": [
    "⬆️ This is how we set env parameters, in this case specifying the non-slippery Frozen Lake."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "322b9bd0-8426-4648-80c0-479f96f6cddc",
   "metadata": {},
   "source": [
    "Notes:\n",
    "\n",
    "The random seed is only for the algorithm itself, e.g. randomness in the neural network optimization. It doesn't set the random seed for the environment's own randomness. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e834f6c3-0b1f-49dc-8c65-136e8b93fa5f",
   "metadata": {},
   "source": [
    "#### Algorithm configs\n",
    "\n",
    "We can also generate this config in one giant line of Python as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "447b397b-a875-417b-8bc7-ef862229ca64",
   "metadata": {},
   "outputs": [],
   "source": [
    "ppo_config = (\n",
    "    PPOConfig()\\\n",
    "    .framework(\"torch\")\\\n",
    "    .rollouts(create_env_on_local_worker=True)\\\n",
    "    .debugging(seed=0, log_level=\"ERROR\")\\\n",
    "    .training(model={\"fcnet_hiddens\" : [32, 32]})\\\n",
    "    .environment(env_config={\"is_slippery\" : False})\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7254e6af-7f07-4afc-b46d-575214eed645",
   "metadata": {},
   "source": [
    "(The `\\` character just means the line of Python continues below.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8cfa9d1-fbfa-455f-a722-950b634d4d45",
   "metadata": {},
   "source": [
    "Notes:\n",
    "\n",
    "We'll discuss tuning in Module 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "30eb0986-9e52-4656-9819-7c43b6d083a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HIDDEN\n",
    "algo_config = (\n",
    "    PPOConfig()\\\n",
    "    .framework(\"torch\")\\\n",
    "    .rollouts(create_env_on_local_worker=True)\\\n",
    "    .debugging(seed=0, log_level=\"ERROR\")\\\n",
    "    .training(model={\"fcnet_hiddens\" : [32, 32]})\\\n",
    "    .environment(env_config={\"is_slippery\" : False})\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "185074d6-c847-4790-94ba-381030616f56",
   "metadata": {},
   "source": [
    "#### Building an algorithm from the config\n",
    "\n",
    "We previously instantiated our PPO algorithm like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3f8b977e-e59d-4afd-9d82-2010be65ed40",
   "metadata": {},
   "outputs": [],
   "source": [
    "ppo = PPO(env=\"FrozenLake-v1\", config=ppo_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "499bf30c-c42a-40d5-957c-477686ee7ee7",
   "metadata": {},
   "source": [
    "The preferred syntax in the latest release of Ray/RLlib is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "217ddfaf-0332-42a8-8178-23c949a80b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ppo = ppo_config.build(env=\"FrozenLake-v1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e483661-3f65-4f61-8db4-3ac3a650619d",
   "metadata": {},
   "source": [
    "As a third option, you can also specify the environment in the config rather than as an argument to `build`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b2be522c-6b40-4b0d-8cf3-c473b420c325",
   "metadata": {},
   "outputs": [],
   "source": [
    "ppo_config.environment(env=\"FrozenLake-v1\")\n",
    "\n",
    "ppo = ppo_config.build()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef84da1-19ef-4300-8555-7e6e65b3e3b7",
   "metadata": {},
   "source": [
    "The end result is the same whichever way you choose."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e3069d-b826-447f-ad34-24eb1d912c4a",
   "metadata": {},
   "source": [
    "#### Saving models\n",
    "\n",
    "- We may want to save trained agents for future use.\n",
    "- This is also called _checkpointing_, especially when done during a training loop.\n",
    "- In RLlib, this can be done simply with:\n",
    "\n",
    "```python\n",
    "algo.save(path_to_checkpoint)\n",
    "```\n",
    "\n",
    "It can then be later restored with\n",
    "\n",
    "```python\n",
    "algo.restore(path_to_checkpoint)\n",
    "```\n",
    "\n",
    "Just make sure you create the trainer with the same environment and parameters when restoring from a checkpoint."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27092e6c-772e-4940-b140-fa77b8469397",
   "metadata": {},
   "source": [
    "#### Restoring models\n",
    "\n",
    "- Let's restore a PPO algorithm object\n",
    "- We need to set it up with the same config first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "517db53e-410c-441f-8823-53b76a3cf825",
   "metadata": {},
   "outputs": [],
   "source": [
    "ppo_config = (\n",
    "    PPOConfig()\\\n",
    "    .framework(\"torch\")\\\n",
    "    .rollouts(create_env_on_local_worker=True)\\\n",
    "    .debugging(seed=0, log_level=\"ERROR\")\\\n",
    "    .training(model={\"fcnet_hiddens\" : [64,64]})\n",
    "    .environment(env_config={\"is_slippery\" : True})\\\n",
    "    .evaluation(evaluation_config = {\"explore\" : False})\n",
    ")\n",
    "\n",
    "ppo = ppo_config.build(\"FrozenLake-v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2e39804d-b683-404c-9a7a-443569b284d7",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't convert np.ndarray of type numpy.object_. The only supported types are: float64, float32, float16, complex64, complex128, int64, int32, int16, int8, uint8, and bool.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [18]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mppo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrestore\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodels/FrozenLakeSlippery-256-Ray2/checkpoint-50\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/git/anyscale/ray/python/ray/tune/trainable/trainable.py:585\u001b[0m, in \u001b[0;36mTrainable.restore\u001b[0;34m(self, checkpoint_path, checkpoint_node_ip)\u001b[0m\n\u001b[1;32m    583\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mload_checkpoint(checkpoint_dict)\n\u001b[1;32m    584\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 585\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_checkpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheckpoint_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    586\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time_since_restore \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m    587\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timesteps_since_restore \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m~/git/anyscale/ray/python/ray/rllib/algorithms/algorithm.py:1444\u001b[0m, in \u001b[0;36mAlgorithm.load_checkpoint\u001b[0;34m(self, checkpoint_path)\u001b[0m\n\u001b[1;32m   1441\u001b[0m \u001b[38;5;129m@override\u001b[39m(Trainable)\n\u001b[1;32m   1442\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_checkpoint\u001b[39m(\u001b[38;5;28mself\u001b[39m, checkpoint_path: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1443\u001b[0m     extra_data \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;28mopen\u001b[39m(checkpoint_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m-> 1444\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__setstate__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mextra_data\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/git/anyscale/ray/python/ray/rllib/algorithms/algorithm.py:2199\u001b[0m, in \u001b[0;36mAlgorithm.__setstate__\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m   2197\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__setstate__\u001b[39m(\u001b[38;5;28mself\u001b[39m, state: \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m   2198\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mworkers\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mworker\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m state:\n\u001b[0;32m-> 2199\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlocal_worker\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrestore\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mworker\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2200\u001b[0m         remote_state \u001b[38;5;241m=\u001b[39m ray\u001b[38;5;241m.\u001b[39mput(state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mworker\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m   2201\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mworkers\u001b[38;5;241m.\u001b[39mremote_workers():\n",
      "File \u001b[0;32m~/git/anyscale/ray/python/ray/rllib/evaluation/rollout_worker.py:1575\u001b[0m, in \u001b[0;36mRolloutWorker.restore\u001b[0;34m(self, objs)\u001b[0m\n\u001b[1;32m   1567\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_policy(\n\u001b[1;32m   1568\u001b[0m             policy_id\u001b[38;5;241m=\u001b[39mpid,\n\u001b[1;32m   1569\u001b[0m             policy_cls\u001b[38;5;241m=\u001b[39mpol_spec\u001b[38;5;241m.\u001b[39mpolicy_class,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1572\u001b[0m             config\u001b[38;5;241m=\u001b[39mpol_spec\u001b[38;5;241m.\u001b[39mconfig,\n\u001b[1;32m   1573\u001b[0m         )\n\u001b[1;32m   1574\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1575\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpolicy_map\u001b[49m\u001b[43m[\u001b[49m\u001b[43mpid\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_state\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/git/anyscale/ray/python/ray/rllib/policy/torch_mixins.py:113\u001b[0m, in \u001b[0;36mKLCoeffMixin.set_state\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkl_coeff \u001b[38;5;241m=\u001b[39m state\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcurrent_kl_coeff\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkl_coeff\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    112\u001b[0m \u001b[38;5;66;03m# Call super's set_state with rest of the state dict.\u001b[39;00m\n\u001b[0;32m--> 113\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_state\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/git/anyscale/ray/python/ray/rllib/policy/torch_policy_v2.py:914\u001b[0m, in \u001b[0;36mTorchPolicyV2.set_state\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m    912\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(optimizer_vars) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizers)\n\u001b[1;32m    913\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m o, s \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizers, optimizer_vars):\n\u001b[0;32m--> 914\u001b[0m         optim_state_dict \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_to_torch_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    915\u001b[0m         o\u001b[38;5;241m.\u001b[39mload_state_dict(optim_state_dict)\n\u001b[1;32m    916\u001b[0m \u001b[38;5;66;03m# Set exploration's state.\u001b[39;00m\n",
      "File \u001b[0;32m~/git/anyscale/ray/python/ray/rllib/utils/torch_utils.py:178\u001b[0m, in \u001b[0;36mconvert_to_torch_tensor\u001b[0;34m(x, device)\u001b[0m\n\u001b[1;32m    175\u001b[0m         tensor \u001b[38;5;241m=\u001b[39m tensor\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[1;32m    176\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tensor \u001b[38;5;28;01mif\u001b[39;00m device \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m tensor\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m--> 178\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_structure\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmapping\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ray2beta/lib/python3.9/site-packages/tree/__init__.py:430\u001b[0m, in \u001b[0;36mmap_structure\u001b[0;34m(func, *structures, **kwargs)\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m other \u001b[38;5;129;01min\u001b[39;00m structures[\u001b[38;5;241m1\u001b[39m:]:\n\u001b[1;32m    428\u001b[0m   assert_same_structure(structures[\u001b[38;5;241m0\u001b[39m], other, check_types\u001b[38;5;241m=\u001b[39mcheck_types)\n\u001b[1;32m    429\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m unflatten_as(structures[\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m--> 430\u001b[0m                     [func(\u001b[38;5;241m*\u001b[39margs) \u001b[38;5;28;01mfor\u001b[39;00m args \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mmap\u001b[39m(flatten, structures))])\n",
      "File \u001b[0;32m~/miniconda3/envs/ray2beta/lib/python3.9/site-packages/tree/__init__.py:430\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m other \u001b[38;5;129;01min\u001b[39;00m structures[\u001b[38;5;241m1\u001b[39m:]:\n\u001b[1;32m    428\u001b[0m   assert_same_structure(structures[\u001b[38;5;241m0\u001b[39m], other, check_types\u001b[38;5;241m=\u001b[39mcheck_types)\n\u001b[1;32m    429\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m unflatten_as(structures[\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m--> 430\u001b[0m                     [\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m args \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mmap\u001b[39m(flatten, structures))])\n",
      "File \u001b[0;32m~/git/anyscale/ray/python/ray/rllib/utils/torch_utils.py:172\u001b[0m, in \u001b[0;36mconvert_to_torch_tensor.<locals>.mapping\u001b[0;34m(item)\u001b[0m\n\u001b[1;32m    169\u001b[0m         tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(item)\n\u001b[1;32m    170\u001b[0m \u001b[38;5;66;03m# Everything else: Convert to numpy, then wrap as torch tensor.\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 172\u001b[0m     tensor \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;66;03m# Floatify all float64 tensors.\u001b[39;00m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tensor\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m torch\u001b[38;5;241m.\u001b[39mdouble:\n",
      "\u001b[0;31mTypeError\u001b[0m: can't convert np.ndarray of type numpy.object_. The only supported types are: float64, float32, float16, complex64, complex128, int64, int32, int16, int8, uint8, and bool."
     ]
    }
   ],
   "source": [
    "ppo.restore(\"models/FrozenLakeSlippery-256-Ray2/checkpoint-50\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db71b112-0918-4b7c-9275-f6bb38417640",
   "metadata": {},
   "source": [
    "Notes:\n",
    "\n",
    "Apparently, it was trained for 30 iterations, 124k time steps, 1 minute, 17k episodes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370d6ffb-b48b-4209-b7b8-ce0cb4d45e8c",
   "metadata": {},
   "source": [
    "#### Viewing stochastic policies\n",
    "\n",
    "- If we want to see what a policy does, we can use `compute_single action`\n",
    "- But, some RL algorithms, including PPO, learn _stochastic policies_.\n",
    "- We may wish to look at these _action probabilities_.\n",
    "- The code can be viewed on GitHub, but is hidden here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bc24efa0-bc12-4d99-b9c6-88fc9bf10550",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import query_policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7096f91a-7a14-4b9a-905b-603583d46c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"FrozenLake-v1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81533301-9caa-4fcc-a354-45ac8f98dabc",
   "metadata": {},
   "source": [
    "We'll use the trainer we just restored:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9cd397c9-9182-4391-a997-b1e8f23d1c5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.2502399 , 0.2493437 , 0.25035876, 0.25005776], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_policy(ppo, env, obs=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c43dbb9c-06f8-4e5e-8c7f-5349d39623c4",
   "metadata": {},
   "source": [
    "Arena:\n",
    "\n",
    "```\n",
    "SFFF\n",
    "FHFH\n",
    "FFFH\n",
    "HFFG\n",
    "```\n",
    "\n",
    "Actions: left (0), down (1), right (2), up (3)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e800476-34c2-4fe4-bb1e-7f9c7e77e94a",
   "metadata": {},
   "source": [
    "Notes:\n",
    "    \n",
    "What we see here are the action probabilities. From the top-left, the agent considers moving left down or right, but not up. It's not entirely clear why left is preferred to up.\n",
    "\n",
    "In module 5 we'll see an RL algorithm that acts deterministically.\n",
    "\n",
    "For a continuous action space this would be different."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44268a54-4855-434d-ac21-d2801f46a322",
   "metadata": {},
   "source": [
    "#### Viewing stochastic policies\n",
    "\n",
    "Let's view all the probabilities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d4a0e388-5ec4-489b-a4cd-53531859fe9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HIDDEN\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a8fdedc6-f162-4c92-a674-648f7ae154c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>left</th>\n",
       "      <th>down</th>\n",
       "      <th>right</th>\n",
       "      <th>up</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.250240</td>\n",
       "      <td>0.249344</td>\n",
       "      <td>0.250359</td>\n",
       "      <td>0.250058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.249624</td>\n",
       "      <td>0.249341</td>\n",
       "      <td>0.250767</td>\n",
       "      <td>0.250268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.250308</td>\n",
       "      <td>0.249372</td>\n",
       "      <td>0.250365</td>\n",
       "      <td>0.249955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.250228</td>\n",
       "      <td>0.250027</td>\n",
       "      <td>0.249284</td>\n",
       "      <td>0.250460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.250549</td>\n",
       "      <td>0.250105</td>\n",
       "      <td>0.249870</td>\n",
       "      <td>0.249475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.250541</td>\n",
       "      <td>0.250021</td>\n",
       "      <td>0.249565</td>\n",
       "      <td>0.249873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.248910</td>\n",
       "      <td>0.251030</td>\n",
       "      <td>0.249831</td>\n",
       "      <td>0.250229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.250184</td>\n",
       "      <td>0.249560</td>\n",
       "      <td>0.250375</td>\n",
       "      <td>0.249882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.249786</td>\n",
       "      <td>0.251036</td>\n",
       "      <td>0.249219</td>\n",
       "      <td>0.249960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.249306</td>\n",
       "      <td>0.250444</td>\n",
       "      <td>0.250571</td>\n",
       "      <td>0.249679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.250247</td>\n",
       "      <td>0.249437</td>\n",
       "      <td>0.250041</td>\n",
       "      <td>0.250275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.250463</td>\n",
       "      <td>0.251258</td>\n",
       "      <td>0.249044</td>\n",
       "      <td>0.249235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.249745</td>\n",
       "      <td>0.250019</td>\n",
       "      <td>0.249934</td>\n",
       "      <td>0.250301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.250174</td>\n",
       "      <td>0.250088</td>\n",
       "      <td>0.250135</td>\n",
       "      <td>0.249602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.250800</td>\n",
       "      <td>0.249303</td>\n",
       "      <td>0.250129</td>\n",
       "      <td>0.249768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.250479</td>\n",
       "      <td>0.250754</td>\n",
       "      <td>0.249008</td>\n",
       "      <td>0.249759</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        left      down     right        up\n",
       "0   0.250240  0.249344  0.250359  0.250058\n",
       "1   0.249624  0.249341  0.250767  0.250268\n",
       "2   0.250308  0.249372  0.250365  0.249955\n",
       "3   0.250228  0.250027  0.249284  0.250460\n",
       "4   0.250549  0.250105  0.249870  0.249475\n",
       "5   0.250541  0.250021  0.249565  0.249873\n",
       "6   0.248910  0.251030  0.249831  0.250229\n",
       "7   0.250184  0.249560  0.250375  0.249882\n",
       "8   0.249786  0.251036  0.249219  0.249960\n",
       "9   0.249306  0.250444  0.250571  0.249679\n",
       "10  0.250247  0.249437  0.250041  0.250275\n",
       "11  0.250463  0.251258  0.249044  0.249235\n",
       "12  0.249745  0.250019  0.249934  0.250301\n",
       "13  0.250174  0.250088  0.250135  0.249602\n",
       "14  0.250800  0.249303  0.250129  0.249768\n",
       "15  0.250479  0.250754  0.249008  0.249759"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_probs = {obs : query_policy(ppo, env, obs) for obs in range(16)}\n",
    "pd.DataFrame(action_probs, index=[\"left\", \"down\", \"right\", \"up\"]).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d83f8b3-a489-4da1-b000-402cbf192497",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Viewing stochastic policies\n",
    "\n",
    "We can also view this as an image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8a9a93cc-951c-44e9-b797-d7cce0bf3209",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HIDDEN\n",
    "df = pd.DataFrame(action_probs, index=[\"left\", \"down\", \"right\", \"up\"]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "67a7b13e-82f5-4c51-a3ad-e0b27410aa44",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,4))\n",
    "plt.imshow(df.values.T);\n",
    "plt.yticks(np.arange(4), labels=[\"left\", \"down\", \"up\", \"right\"]);\n",
    "plt.xticks(np.arange(16), labels=np.arange(16));\n",
    "plt.setp(plt.gca().get_xticklabels(), rotation=45, ha=\"right\",\n",
    "         rotation_mode=\"anchor\");\n",
    "plt.xlabel(\"observations\");\n",
    "plt.ylabel(\"actions\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e860de2e-9b73-4968-a99f-07da50e5978c",
   "metadata": {},
   "source": [
    "Notes:\n",
    "    \n",
    "This is transposed to fit on the screen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d9e3b1-6715-4883-995b-963d9f2e5c3b",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Acting stochastically\n",
    "\n",
    "`compute_single_action` will act according to these probabilities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "098512e5-5290-4736-99aa-5663d4c3bc12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.2502399 , 0.2493437 , 0.25035876, 0.25005776], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_probs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "700ac122-31cc-4718-98e0-215e58190c17",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trainer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [27]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m counts \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mbincount([trainer\u001b[38;5;241m.\u001b[39mcompute_single_action(\u001b[38;5;241m0\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10_000\u001b[39m)])\n\u001b[1;32m      2\u001b[0m plt\u001b[38;5;241m.\u001b[39mbar([\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m3\u001b[39m], counts\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m10_000\u001b[39m)\n\u001b[1;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mxticks([\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m3\u001b[39m]);\n",
      "Input \u001b[0;32mIn [27]\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0m counts \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mbincount([\u001b[43mtrainer\u001b[49m\u001b[38;5;241m.\u001b[39mcompute_single_action(\u001b[38;5;241m0\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10_000\u001b[39m)])\n\u001b[1;32m      2\u001b[0m plt\u001b[38;5;241m.\u001b[39mbar([\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m3\u001b[39m], counts\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m10_000\u001b[39m)\n\u001b[1;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mxticks([\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m3\u001b[39m]);\n",
      "\u001b[0;31mNameError\u001b[0m: name 'trainer' is not defined"
     ]
    }
   ],
   "source": [
    "counts = np.bincount([ppo.compute_single_action(0) for _ in range(10_000)])\n",
    "plt.bar([0,1,2,3], counts/10_000)\n",
    "plt.xticks([0,1,2,3]);\n",
    "plt.xlabel(\"Action\");\n",
    "plt.ylabel(\"Empirical dist\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab2dc857-33bd-42e4-a002-797cf8beee3f",
   "metadata": {},
   "source": [
    "#### Acting deterministically\n",
    "\n",
    "We can also tell the agent to act deterministically with `explore=False`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d2c8797d-7eb8-480b-887f-470c46901f9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ppo.compute_single_action(0, explore=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "046bbdf5-ca03-46f9-b6be-2547653d7eff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n"
     ]
    }
   ],
   "source": [
    "print([ppo.compute_single_action(0, explore=False) for _ in range(100)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df58d2f-8ad0-4b16-b3e8-058016123bf4",
   "metadata": {},
   "source": [
    "Often this is desirable, but **sometimes the optimal policy is stochastic**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d576256-a969-4b77-a204-2bb8219450cd",
   "metadata": {},
   "source": [
    "Notes:\n",
    "\n",
    "During training, exploration is a fundamental concept in RL. We will discuss it in Module 4!\n",
    "\n",
    "In Module 4 we'll also see an example where the optimal policy is stochastic, so we would definitely not want to set `explore=False` in deployment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d205da70-1255-437c-8a99-6ea8a5e8d2a0",
   "metadata": {},
   "source": [
    "#### Let's apply what we learned!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd539d44-aa7c-4958-b448-7759f3adc20e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## RLlib config syntax\n",
    "<!-- multiple choice -->\n",
    "\n",
    "Which of the following is **NOT** correct RLlib syntax for instantiating a PPO algorithm instance? Assume the following import has already been run:\n",
    "\n",
    "```python\n",
    "from ray.rllib.algorithms.ppo import PPO, PPOConfig\n",
    "```\n",
    "\n",
    "- [ ] PPOConfig().build(env=\"FrozenLake-v1\")\n",
    "- [ ] PPOConfig().environment(env=\"FrozenLake-v1\").build()\n",
    "- [x] PPOConfig(env=\"FrozenLake-v1\").build()\n",
    "- [ ] PPO(env=\"FrozenLake-v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "46809a96-dc1f-4d56-ad40-226c68d70a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # HIDDEN\n",
    "# from ray.rllib.algorithms.ppo import PPO, PPOConfig\n",
    "\n",
    "# PPOConfig().framework(\"torch\").build(env=\"FrozenLake-v1\")\n",
    "# PPOConfig().framework(\"torch\").environment(env=\"FrozenLake-v1\").build()\n",
    "# PPO(env=\"FrozenLake-v1\", config={\"framework\" : \"torch\"})\n",
    "# PPOConfig(env=\"FrozenLake-v1\").framework(\"torch\").build()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce5cbd1-2669-4470-abd7-573ac1b8205a",
   "metadata": {},
   "source": [
    "## Saving/restoring models\n",
    "<!-- multiple choice -->\n",
    "\n",
    "Which of the following is **NOT** a plausible use of saving (\"checkpointing\") models in RLlib?\n",
    "\n",
    "- [x] Checkpointing generates cryptocurrency.\n",
    "- [ ] In a course like this, loading a checkpoint means you don't always have to wait for models to train.\n",
    "- [ ] Saved models can be stored, shared, copied and/or moved for deployment.\n",
    "- [ ] Training can be resumed from a checkpoint in case it fails and needs to be restarted."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb0453c-7d3e-4092-b6c7-6757c05056ed",
   "metadata": {},
   "source": [
    "exercise: draw the max prob of the plicy as a measure of sureness"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe3eb48-7201-4b1e-9e10-f88c8524fcdc",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Visualizing the policy\n",
    "<!-- coding exercise -->\n",
    "\n",
    "In the slides we looked at the probability of"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad1fa7c-90b0-47e6-8f57-b2a070bb85fc",
   "metadata": {},
   "source": [
    "could revisit previs Ex but look at probabilities this time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a2dd37-444e-4bfc-a7eb-220271154672",
   "metadata": {},
   "source": [
    "## Cartpole environment\n",
    "<!-- coding exercise -->\n",
    "\n",
    "A famous benchmark environment in RL is the _Cartpole_ environment, in which the agent must balance an [inverted pendulum](https://en.wikipedia.org/wiki/Inverted_pendulum) by applying force on the cart (at the bottom) to keep it stable. More information is available in the gym documentation [here](https://www.gymlibrary.ml/environments/classic_control/cart_pole/).\n",
    "\n",
    "Note: the code below imports the env `MyCartPole`. This is identical to gym's `'CartPole-v1'` except that the rendering method has been overridden with something that can be displayed inside of this interactive course platform. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c47b1f3a-66b1-463f-9e59-2b3c903cb377",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION\n",
    "import numpy as np\n",
    "import time\n",
    "from IPython import display\n",
    "\n",
    "from envs import MyCartPole\n",
    "from ray.rllib.algorithms.ppo import PPO, PPOConfig\n",
    "\n",
    "config = (\n",
    "    PPOConfig()\\\n",
    "    .framework(\"torch\")\\\n",
    "    .rollouts(create_env_on_local_worker=True)\\\n",
    "    .debugging(seed=0, log_level=\"ERROR\")\\\n",
    "    .training(model={\"fcnet_hiddens\" : [32,32]})\n",
    ")\n",
    "\n",
    "ppo = config.build(env=MyCartPole);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "337c5eba-1698-44d4-9a45-3e38eb6765f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rewards = []\n",
    "for i in range(50):\n",
    "    out = ppo.train()\n",
    "    rewards.append(out[\"episode_reward_mean\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7d102289-3f41-4dce-b6ca-a649820450db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "env = MyCartPole()\n",
    "obs = env.reset()\n",
    "\n",
    "for i in range(20):\n",
    "    \n",
    "    action = ppo.compute_single_action(obs)\n",
    "    \n",
    "    obs, reward, done, _ = env.step(action)\n",
    "\n",
    "    env.render()\n",
    "    time.sleep(0.2)\n",
    "\n",
    "display.clear_output(wait=True);\n",
    "\n",
    "# make a plot of prob(push left) vs. angle??"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2dc421-4a02-45e3-974d-49d30b1dfe67",
   "metadata": {},
   "source": [
    "# TODO\n",
    "\n",
    "need to be able to load a trained model here, which is currently not working. then, split this up into 2 coding exercises, one with the video and one with the plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3a5a7f1a-4fd7-4182-b4f9-2a23fb5618de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from utils import query_policy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "angle_range_deg = np.arange(-15,15,0.1)\n",
    "push_left_probs = 0*angle_range_deg\n",
    "\n",
    "for i, angle_deg in enumerate(angle_range_deg):\n",
    "    angle_rad = angle_deg/180*np.pi\n",
    "    \n",
    "    obs = np.zeros(4)\n",
    "    obs[2] = angle_rad\n",
    "\n",
    "    push_left_probs[i] = query_policy(ppo, env, obs, actions=[0,1])[0]\n",
    "\n",
    "plt.plot(angle_range_deg, push_left_probs);\n",
    "plt.xlabel(\"pole angle (degrees)\")\n",
    "plt.ylabel(\"probability of pushing left\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a14614-d1c5-4319-9559-543ecf432699",
   "metadata": {},
   "source": [
    "#### Interpreting the plot\n",
    "\n",
    "How does the observed pole angle affect the trained agent's probability of pushing left?\n",
    "\n",
    "- [ ] Positive pole angles (leaning right) result in the agent pushing the cart left. | The agent wants to push the cart underneath the top of the pole.\n",
    "- [x] Negative pole angles (leaning left) result in the agent pushing the cart left.\n",
    "- [ ] The agent's probability of pushing left is not significantly affected by the pole angle.\n",
    "- [ ] None of the above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2370b6-7abb-4d23-adad-ada45068d3c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ray2beta]",
   "language": "python",
   "name": "conda-env-ray2beta-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
