{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90c01ab9-1cd0-47d8-a198-e07e36e2c1fc",
   "metadata": {
    "tags": []
   },
   "source": [
    "## RLlib continued"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e74417a3-63bc-4000-951a-72ab882b689e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HIDDEN\n",
    "import gym\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from ray import rllib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f67da7-14aa-456a-84bb-5813db493143",
   "metadata": {},
   "source": [
    "#### RLlib features\n",
    "\n",
    "- So far we've seen training, evaluation, and \"prediction\" with RLlib.\n",
    "- Next we'll explore a few more features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e07d9e0-cc95-43f0-81b4-2b937070a7f2",
   "metadata": {},
   "source": [
    "#### Configuring the trainer\n",
    "\n",
    "Earlier, we saw configs like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43a7bbd3-489c-43e5-93a8-212d2abc31a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_config = {\n",
    "    \"framework\"             : \"torch\",\n",
    "    \"create_env_on_driver\"  : True,\n",
    "    \"seed\"                  : 0,\n",
    "    \"model\"                 : {\"fcnet_hiddens\" : [32, 32]},\n",
    "    \"env_config\"            : {\"is_slippery\" : False}\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8cfa9d1-fbfa-455f-a722-950b634d4d45",
   "metadata": {},
   "source": [
    "- `config={\"framework\" : \"torch\"}`: RLlib works with tensorflow (`\"tf\"` or `\"tf2\"`) and pytorch (`\"torch\"`)\n",
    "- `\"create_env_on_driver\" : True`: This relates to Ray, and we will touch on it briefly, but not much in this course\n",
    "-  `\"seed\" : 0`: This is used for reproducibility of the teaching materials, and is not normally needed\n",
    "- `\"model\" : {\"fcnet_hiddens\" : [32, 32]}`: this tells RLlib to use a smaller-than-default neural network architecture, which helps this slide deck compile/run faster\n",
    "- `\"env_config\" : {\"is_slippery\" : False}`: this selects the non-slippery Frozen Lake\n",
    "  - All environment hyperparameters go in this sub-dictionary\n",
    "  \n",
    "Notes:\n",
    "\n",
    "We'll discuss tuning in Module 5."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "185074d6-c847-4790-94ba-381030616f56",
   "metadata": {},
   "source": [
    "#### Configuring the trainer\n",
    "\n",
    "We can see the full config, but it's way too long to read!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c17cf8e-52dd-40c0-9949-f689b3f38944",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = rllib.agents.ppo.PPOTrainer(env=\"FrozenLake-v1\", \n",
    "                                      config=trainer_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c25e321c-6480-4710-8e4e-dfbf43ee63f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "105"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainer.config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "22355c1a-ba16-4ed4-8cca-501c08ed8eda",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'num_workers': 2,\n",
       " 'num_envs_per_worker': 1,\n",
       " 'create_env_on_driver': True,\n",
       " 'rollout_fragment_length': 200,\n",
       " 'batch_mode': 'truncate_episodes',\n",
       " 'gamma': 0.99,\n",
       " 'lr': 5e-05,\n",
       " 'train_batch_size': 4000,\n",
       " 'model': {'_use_default_native_models': False,\n",
       "  '_disable_preprocessor_api': False,\n",
       "  '_disable_action_flattening': False,\n",
       "  'fcnet_hiddens': [32, 32],\n",
       "  'fcnet_activation': 'tanh',\n",
       "  'conv_filters': None,\n",
       "  'conv_activation': 'relu',\n",
       "  'post_fcnet_hiddens': [],\n",
       "  'post_fcnet_activation': 'relu',\n",
       "  'free_log_std': False,\n",
       "  'no_final_linear': False,\n",
       "  'vf_share_layers': False,\n",
       "  'use_lstm': False,\n",
       "  'max_seq_len': 20,\n",
       "  'lstm_cell_size': 256,\n",
       "  'lstm_use_prev_action': False,\n",
       "  'lstm_use_prev_reward': False,\n",
       "  '_time_major': False,\n",
       "  'use_attention': False,\n",
       "  'attention_num_transformer_units': 1,\n",
       "  'attention_dim': 64,\n",
       "  'attention_num_heads': 1,\n",
       "  'attention_head_dim': 32,\n",
       "  'attention_memory_inference': 50,\n",
       "  'attention_memory_training': 50,\n",
       "  'attention_position_wise_mlp_dim': 32,\n",
       "  'attention_init_gru_gate_bias': 2.0,\n",
       "  'attention_use_n_prev_actions': 0,\n",
       "  'attention_use_n_prev_rewards': 0,\n",
       "  'framestack': True,\n",
       "  'dim': 84,\n",
       "  'grayscale': False,\n",
       "  'zero_mean': True,\n",
       "  'custom_model': None,\n",
       "  'custom_model_config': {},\n",
       "  'custom_action_dist': None,\n",
       "  'custom_preprocessor': None,\n",
       "  'lstm_use_prev_action_reward': -1},\n",
       " 'optimizer': {},\n",
       " 'horizon': None,\n",
       " 'soft_horizon': False,\n",
       " 'no_done_at_end': False,\n",
       " 'env': 'FrozenLake-v1',\n",
       " 'observation_space': None,\n",
       " 'action_space': None,\n",
       " 'env_config': {'is_slippery': False},\n",
       " 'remote_worker_envs': False,\n",
       " 'remote_env_batch_wait_ms': 0,\n",
       " 'env_task_fn': None,\n",
       " 'render_env': False,\n",
       " 'record_env': False,\n",
       " 'clip_rewards': None,\n",
       " 'normalize_actions': True,\n",
       " 'clip_actions': False,\n",
       " 'preprocessor_pref': 'deepmind',\n",
       " 'log_level': 'WARN',\n",
       " 'callbacks': ray.rllib.agents.callbacks.DefaultCallbacks,\n",
       " 'ignore_worker_failures': False,\n",
       " 'log_sys_usage': True,\n",
       " 'fake_sampler': False,\n",
       " 'framework': 'torch',\n",
       " 'eager_tracing': False,\n",
       " 'eager_max_retraces': 20,\n",
       " 'explore': True,\n",
       " 'exploration_config': {'type': 'StochasticSampling'},\n",
       " 'evaluation_interval': None,\n",
       " 'evaluation_duration': 10,\n",
       " 'evaluation_duration_unit': 'episodes',\n",
       " 'evaluation_parallel_to_training': False,\n",
       " 'in_evaluation': False,\n",
       " 'evaluation_config': {'num_workers': 2,\n",
       "  'num_envs_per_worker': 1,\n",
       "  'create_env_on_driver': True,\n",
       "  'rollout_fragment_length': 200,\n",
       "  'batch_mode': 'truncate_episodes',\n",
       "  'gamma': 0.99,\n",
       "  'lr': 5e-05,\n",
       "  'train_batch_size': 4000,\n",
       "  'model': {'_use_default_native_models': False,\n",
       "   '_disable_preprocessor_api': False,\n",
       "   '_disable_action_flattening': False,\n",
       "   'fcnet_hiddens': [32, 32],\n",
       "   'fcnet_activation': 'tanh',\n",
       "   'conv_filters': None,\n",
       "   'conv_activation': 'relu',\n",
       "   'post_fcnet_hiddens': [],\n",
       "   'post_fcnet_activation': 'relu',\n",
       "   'free_log_std': False,\n",
       "   'no_final_linear': False,\n",
       "   'vf_share_layers': False,\n",
       "   'use_lstm': False,\n",
       "   'max_seq_len': 20,\n",
       "   'lstm_cell_size': 256,\n",
       "   'lstm_use_prev_action': False,\n",
       "   'lstm_use_prev_reward': False,\n",
       "   '_time_major': False,\n",
       "   'use_attention': False,\n",
       "   'attention_num_transformer_units': 1,\n",
       "   'attention_dim': 64,\n",
       "   'attention_num_heads': 1,\n",
       "   'attention_head_dim': 32,\n",
       "   'attention_memory_inference': 50,\n",
       "   'attention_memory_training': 50,\n",
       "   'attention_position_wise_mlp_dim': 32,\n",
       "   'attention_init_gru_gate_bias': 2.0,\n",
       "   'attention_use_n_prev_actions': 0,\n",
       "   'attention_use_n_prev_rewards': 0,\n",
       "   'framestack': True,\n",
       "   'dim': 84,\n",
       "   'grayscale': False,\n",
       "   'zero_mean': True,\n",
       "   'custom_model': None,\n",
       "   'custom_model_config': {},\n",
       "   'custom_action_dist': None,\n",
       "   'custom_preprocessor': None,\n",
       "   'lstm_use_prev_action_reward': -1},\n",
       "  'optimizer': {},\n",
       "  'horizon': None,\n",
       "  'soft_horizon': False,\n",
       "  'no_done_at_end': False,\n",
       "  'env': 'FrozenLake-v1',\n",
       "  'observation_space': None,\n",
       "  'action_space': None,\n",
       "  'env_config': {'is_slippery': False},\n",
       "  'remote_worker_envs': False,\n",
       "  'remote_env_batch_wait_ms': 0,\n",
       "  'env_task_fn': None,\n",
       "  'render_env': False,\n",
       "  'record_env': False,\n",
       "  'clip_rewards': None,\n",
       "  'normalize_actions': True,\n",
       "  'clip_actions': False,\n",
       "  'preprocessor_pref': 'deepmind',\n",
       "  'log_level': 'WARN',\n",
       "  'callbacks': ray.rllib.agents.callbacks.DefaultCallbacks,\n",
       "  'ignore_worker_failures': False,\n",
       "  'log_sys_usage': True,\n",
       "  'fake_sampler': False,\n",
       "  'framework': 'torch',\n",
       "  'eager_tracing': False,\n",
       "  'eager_max_retraces': 20,\n",
       "  'explore': True,\n",
       "  'exploration_config': {'type': 'StochasticSampling'},\n",
       "  'evaluation_interval': None,\n",
       "  'evaluation_duration': 10,\n",
       "  'evaluation_duration_unit': 'episodes',\n",
       "  'evaluation_parallel_to_training': False,\n",
       "  'in_evaluation': False,\n",
       "  'evaluation_config': {},\n",
       "  'evaluation_num_workers': 0,\n",
       "  'custom_eval_function': None,\n",
       "  'always_attach_evaluation_results': False,\n",
       "  'sample_async': False,\n",
       "  'sample_collector': ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector,\n",
       "  'observation_filter': 'NoFilter',\n",
       "  'synchronize_filters': True,\n",
       "  'tf_session_args': {'intra_op_parallelism_threads': 2,\n",
       "   'inter_op_parallelism_threads': 2,\n",
       "   'gpu_options': {'allow_growth': True},\n",
       "   'log_device_placement': False,\n",
       "   'device_count': {'CPU': 1},\n",
       "   'allow_soft_placement': True},\n",
       "  'local_tf_session_args': {'intra_op_parallelism_threads': 8,\n",
       "   'inter_op_parallelism_threads': 8},\n",
       "  'compress_observations': False,\n",
       "  'metrics_episode_collection_timeout_s': 180,\n",
       "  'metrics_num_episodes_for_smoothing': 100,\n",
       "  'min_time_s_per_reporting': None,\n",
       "  'min_train_timesteps_per_reporting': None,\n",
       "  'min_sample_timesteps_per_reporting': 0,\n",
       "  'seed': 0,\n",
       "  'extra_python_environs_for_driver': {},\n",
       "  'extra_python_environs_for_worker': {},\n",
       "  'num_gpus': 0,\n",
       "  '_fake_gpus': False,\n",
       "  'num_cpus_per_worker': 1,\n",
       "  'num_gpus_per_worker': 0,\n",
       "  'custom_resources_per_worker': {},\n",
       "  'num_cpus_for_driver': 1,\n",
       "  'placement_strategy': 'PACK',\n",
       "  'input': 'sampler',\n",
       "  'input_config': {},\n",
       "  'actions_in_input_normalized': False,\n",
       "  'input_evaluation': ['is', 'wis'],\n",
       "  'postprocess_inputs': False,\n",
       "  'shuffle_buffer_size': 0,\n",
       "  'output': None,\n",
       "  'output_compress_columns': ['obs', 'new_obs'],\n",
       "  'output_max_file_size': 67108864,\n",
       "  'multiagent': {'policies': {'default_policy': PolicySpec(policy_class=<class 'ray.rllib.agents.ppo.ppo_torch_policy.PPOTorchPolicy'>, observation_space=Discrete(16), action_space=Discrete(4), config={})},\n",
       "   'policy_map_capacity': 100,\n",
       "   'policy_map_cache': None,\n",
       "   'policy_mapping_fn': None,\n",
       "   'policies_to_train': None,\n",
       "   'observation_fn': None,\n",
       "   'replay_mode': 'independent',\n",
       "   'count_steps_by': 'env_steps'},\n",
       "  'logger_config': None,\n",
       "  '_tf_policy_handles_more_than_one_loss': False,\n",
       "  '_disable_preprocessor_api': False,\n",
       "  '_disable_action_flattening': False,\n",
       "  '_disable_execution_plan_api': False,\n",
       "  'simple_optimizer': False,\n",
       "  'monitor': -1,\n",
       "  'evaluation_num_episodes': -1,\n",
       "  'metrics_smoothing_episodes': -1,\n",
       "  'timesteps_per_iteration': 0,\n",
       "  'min_iter_time_s': -1,\n",
       "  'collect_metrics_timeout': -1,\n",
       "  'use_critic': True,\n",
       "  'use_gae': True,\n",
       "  'lambda': 1.0,\n",
       "  'kl_coeff': 0.2,\n",
       "  'sgd_minibatch_size': 128,\n",
       "  'shuffle_sequences': True,\n",
       "  'num_sgd_iter': 30,\n",
       "  'lr_schedule': None,\n",
       "  'vf_loss_coeff': 1.0,\n",
       "  'entropy_coeff': 0.0,\n",
       "  'entropy_coeff_schedule': None,\n",
       "  'clip_param': 0.3,\n",
       "  'vf_clip_param': 10.0,\n",
       "  'grad_clip': None,\n",
       "  'kl_target': 0.01,\n",
       "  'vf_share_layers': -1},\n",
       " 'evaluation_num_workers': 0,\n",
       " 'custom_eval_function': None,\n",
       " 'always_attach_evaluation_results': False,\n",
       " 'sample_async': False,\n",
       " 'sample_collector': ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector,\n",
       " 'observation_filter': 'NoFilter',\n",
       " 'synchronize_filters': True,\n",
       " 'tf_session_args': {'intra_op_parallelism_threads': 2,\n",
       "  'inter_op_parallelism_threads': 2,\n",
       "  'gpu_options': {'allow_growth': True},\n",
       "  'log_device_placement': False,\n",
       "  'device_count': {'CPU': 1},\n",
       "  'allow_soft_placement': True},\n",
       " 'local_tf_session_args': {'intra_op_parallelism_threads': 8,\n",
       "  'inter_op_parallelism_threads': 8},\n",
       " 'compress_observations': False,\n",
       " 'metrics_episode_collection_timeout_s': 180,\n",
       " 'metrics_num_episodes_for_smoothing': 100,\n",
       " 'min_time_s_per_reporting': None,\n",
       " 'min_train_timesteps_per_reporting': None,\n",
       " 'min_sample_timesteps_per_reporting': 0,\n",
       " 'seed': 0,\n",
       " 'extra_python_environs_for_driver': {},\n",
       " 'extra_python_environs_for_worker': {},\n",
       " 'num_gpus': 0,\n",
       " '_fake_gpus': False,\n",
       " 'num_cpus_per_worker': 1,\n",
       " 'num_gpus_per_worker': 0,\n",
       " 'custom_resources_per_worker': {},\n",
       " 'num_cpus_for_driver': 1,\n",
       " 'placement_strategy': 'PACK',\n",
       " 'input': 'sampler',\n",
       " 'input_config': {},\n",
       " 'actions_in_input_normalized': False,\n",
       " 'input_evaluation': ['is', 'wis'],\n",
       " 'postprocess_inputs': False,\n",
       " 'shuffle_buffer_size': 0,\n",
       " 'output': None,\n",
       " 'output_compress_columns': ['obs', 'new_obs'],\n",
       " 'output_max_file_size': 67108864,\n",
       " 'multiagent': {'policies': {'default_policy': PolicySpec(policy_class=<class 'ray.rllib.agents.ppo.ppo_torch_policy.PPOTorchPolicy'>, observation_space=Discrete(16), action_space=Discrete(4), config={})},\n",
       "  'policy_map_capacity': 100,\n",
       "  'policy_map_cache': None,\n",
       "  'policy_mapping_fn': None,\n",
       "  'policies_to_train': None,\n",
       "  'observation_fn': None,\n",
       "  'replay_mode': 'independent',\n",
       "  'count_steps_by': 'env_steps'},\n",
       " 'logger_config': None,\n",
       " '_tf_policy_handles_more_than_one_loss': False,\n",
       " '_disable_preprocessor_api': False,\n",
       " '_disable_action_flattening': False,\n",
       " '_disable_execution_plan_api': False,\n",
       " 'simple_optimizer': False,\n",
       " 'monitor': -1,\n",
       " 'evaluation_num_episodes': -1,\n",
       " 'metrics_smoothing_episodes': -1,\n",
       " 'timesteps_per_iteration': 0,\n",
       " 'min_iter_time_s': -1,\n",
       " 'collect_metrics_timeout': -1,\n",
       " 'use_critic': True,\n",
       " 'use_gae': True,\n",
       " 'lambda': 1.0,\n",
       " 'kl_coeff': 0.2,\n",
       " 'sgd_minibatch_size': 128,\n",
       " 'shuffle_sequences': True,\n",
       " 'num_sgd_iter': 30,\n",
       " 'lr_schedule': None,\n",
       " 'vf_loss_coeff': 1.0,\n",
       " 'entropy_coeff': 0.0,\n",
       " 'entropy_coeff_schedule': None,\n",
       " 'clip_param': 0.3,\n",
       " 'vf_clip_param': 10.0,\n",
       " 'grad_clip': None,\n",
       " 'kl_target': 0.01,\n",
       " 'vf_share_layers': -1}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e3069d-b826-447f-ad34-24eb1d912c4a",
   "metadata": {},
   "source": [
    "#### Saving models\n",
    "\n",
    "- We may want to save trained agents for future use.\n",
    "- This is also called _checkpointing_, especially when done during a training loop.\n",
    "- In RLlib, this can be done simply with:\n",
    "\n",
    "```python\n",
    "trainer.save()\n",
    "```\n",
    "\n",
    "It can then be later restored with\n",
    "\n",
    "```python\n",
    "trainer.restore(path_to_checkpoint)\n",
    "```\n",
    "\n",
    "Just make sure you create the trainer with the same environment and parameters when restoring from a checkpoint."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27092e6c-772e-4940-b140-fa77b8469397",
   "metadata": {},
   "source": [
    "#### Restoring models\n",
    "\n",
    "Let's restore a trainer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e39804d-b683-404c-9a7a-443569b284d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-24 09:04:19,130\tINFO trainable.py:495 -- Restored on 127.0.0.1 from checkpoint: models/FrozenLakeSlippery3232/checkpoint-31\n",
      "2022-07-24 09:04:19,132\tINFO trainable.py:503 -- Current state after restoring: {'_iteration': 31, '_timesteps_total': 124000, '_time_total': 65.40984463691711, '_episodes_total': 17450}\n"
     ]
    }
   ],
   "source": [
    "trainer.restore(\"models/FrozenLakeSlippery3232/checkpoint-31\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db71b112-0918-4b7c-9275-f6bb38417640",
   "metadata": {},
   "source": [
    "Notes:\n",
    "\n",
    "Apparently, it was trained for 30 iterations, 124k time steps, 1 minute, 17k episodes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370d6ffb-b48b-4209-b7b8-ce0cb4d45e8c",
   "metadata": {},
   "source": [
    "#### Viewing stochastic policies\n",
    "\n",
    "- Some RL algorithms, including PPO, learn stochastic policies.\n",
    "- We may wish to look at these action probabilities.\n",
    "- The code can be viewed on GitHub, but is hidden here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc24efa0-bc12-4d99-b9c6-88fc9bf10550",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import query_policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7096f91a-7a14-4b9a-905b-603583d46c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"FrozenLake-v1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81533301-9caa-4fcc-a354-45ac8f98dabc",
   "metadata": {},
   "source": [
    "We'll use the trainer we just restored:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9cd397c9-9182-4391-a997-b1e8f23d1c5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.36128262, 0.30411848, 0.29477558, 0.03982319], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_policy(trainer, env, obs=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c43dbb9c-06f8-4e5e-8c7f-5349d39623c4",
   "metadata": {},
   "source": [
    "Arena:\n",
    "\n",
    "```\n",
    "SFFF\n",
    "FHFH\n",
    "FFFH\n",
    "HFFG\n",
    "```\n",
    "\n",
    "Actions: left (0), down (1), right (2), up (3)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e800476-34c2-4fe4-bb1e-7f9c7e77e94a",
   "metadata": {},
   "source": [
    "Notes:\n",
    "    \n",
    "What we see here are the action probabilities. From the top-left, the agent considers moving left down or right, but not up. It's not entirely clear why left is preferred to up.\n",
    "\n",
    "In module 5 we'll see an RL algorithm that acts deterministically."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44268a54-4855-434d-ac21-d2801f46a322",
   "metadata": {},
   "source": [
    "#### Viewing stochastic policies\n",
    "\n",
    "Let's view all the probabilities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d4a0e388-5ec4-489b-a4cd-53531859fe9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HIDDEN\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a8fdedc6-f162-4c92-a674-648f7ae154c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>left</th>\n",
       "      <th>down</th>\n",
       "      <th>right</th>\n",
       "      <th>up</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.361283</td>\n",
       "      <td>0.304118</td>\n",
       "      <td>0.294776</td>\n",
       "      <td>0.039823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.105703</td>\n",
       "      <td>0.295750</td>\n",
       "      <td>0.179304</td>\n",
       "      <td>0.419243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.878681</td>\n",
       "      <td>0.029604</td>\n",
       "      <td>0.040693</td>\n",
       "      <td>0.051021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.436856</td>\n",
       "      <td>0.262808</td>\n",
       "      <td>0.236151</td>\n",
       "      <td>0.064186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.609650</td>\n",
       "      <td>0.186226</td>\n",
       "      <td>0.176718</td>\n",
       "      <td>0.027406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.430741</td>\n",
       "      <td>0.223148</td>\n",
       "      <td>0.239431</td>\n",
       "      <td>0.106680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.021220</td>\n",
       "      <td>0.542077</td>\n",
       "      <td>0.414277</td>\n",
       "      <td>0.022427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.377155</td>\n",
       "      <td>0.222003</td>\n",
       "      <td>0.223822</td>\n",
       "      <td>0.177020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.016745</td>\n",
       "      <td>0.560293</td>\n",
       "      <td>0.378151</td>\n",
       "      <td>0.044812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.007635</td>\n",
       "      <td>0.627997</td>\n",
       "      <td>0.344637</td>\n",
       "      <td>0.019731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.946561</td>\n",
       "      <td>0.017667</td>\n",
       "      <td>0.021163</td>\n",
       "      <td>0.014609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.164004</td>\n",
       "      <td>0.406202</td>\n",
       "      <td>0.349804</td>\n",
       "      <td>0.079989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.255850</td>\n",
       "      <td>0.341471</td>\n",
       "      <td>0.332879</td>\n",
       "      <td>0.069800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.018130</td>\n",
       "      <td>0.351915</td>\n",
       "      <td>0.582430</td>\n",
       "      <td>0.047525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.003570</td>\n",
       "      <td>0.635234</td>\n",
       "      <td>0.344824</td>\n",
       "      <td>0.016371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.325553</td>\n",
       "      <td>0.313347</td>\n",
       "      <td>0.286977</td>\n",
       "      <td>0.074124</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        left      down     right        up\n",
       "0   0.361283  0.304118  0.294776  0.039823\n",
       "1   0.105703  0.295750  0.179304  0.419243\n",
       "2   0.878681  0.029604  0.040693  0.051021\n",
       "3   0.436856  0.262808  0.236151  0.064186\n",
       "4   0.609650  0.186226  0.176718  0.027406\n",
       "5   0.430741  0.223148  0.239431  0.106680\n",
       "6   0.021220  0.542077  0.414277  0.022427\n",
       "7   0.377155  0.222003  0.223822  0.177020\n",
       "8   0.016745  0.560293  0.378151  0.044812\n",
       "9   0.007635  0.627997  0.344637  0.019731\n",
       "10  0.946561  0.017667  0.021163  0.014609\n",
       "11  0.164004  0.406202  0.349804  0.079989\n",
       "12  0.255850  0.341471  0.332879  0.069800\n",
       "13  0.018130  0.351915  0.582430  0.047525\n",
       "14  0.003570  0.635234  0.344824  0.016371\n",
       "15  0.325553  0.313347  0.286977  0.074124"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_probs = {obs : query_policy(trainer, env, obs) for obs in range(16)}\n",
    "pd.DataFrame(action_probs, index=[\"left\", \"down\", \"right\", \"up\"]).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d83f8b3-a489-4da1-b000-402cbf192497",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Viewing stochastic policies\n",
    "\n",
    "We can also view this as an image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8a9a93cc-951c-44e9-b797-d7cce0bf3209",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HIDDEN\n",
    "df = pd.DataFrame(action_probs, index=[\"left\", \"down\", \"right\", \"up\"]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "67a7b13e-82f5-4c51-a3ad-e0b27410aa44",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(4,8))\n",
    "plt.imshow(df.values);\n",
    "plt.xticks(np.arange(4), labels=[\"left\", \"down\", \"up\", \"right\"]);\n",
    "plt.yticks(np.arange(16), labels=np.arange(16));\n",
    "plt.setp(plt.gca().get_xticklabels(), rotation=45, ha=\"right\",\n",
    "         rotation_mode=\"anchor\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d9e3b1-6715-4883-995b-963d9f2e5c3b",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Acting stochastically\n",
    "\n",
    "`compute_single_action` will act according to these probabilities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "098512e5-5290-4736-99aa-5663d4c3bc12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.36128262, 0.30411848, 0.29477558, 0.03982319], dtype=float32)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_probs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "700ac122-31cc-4718-98e0-215e58190c17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "counts = np.bincount([trainer.compute_single_action(0) for _ in range(10_000)])\n",
    "plt.bar([0,1,2,3], counts/10_000)\n",
    "plt.xticks([0,1,2,3]);\n",
    "plt.xlabel(\"Action\");\n",
    "plt.ylabel(\"Empirical dist\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab2dc857-33bd-42e4-a002-797cf8beee3f",
   "metadata": {},
   "source": [
    "#### Acting deterministically\n",
    "\n",
    "We can also tell the agent to act deterministically with `explore=False`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "d2c8797d-7eb8-480b-887f-470c46901f9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.compute_single_action(0, explore=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "046bbdf5-ca03-46f9-b6be-2547653d7eff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print([trainer.compute_single_action(0, explore=False) for _ in range(100)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d576256-a969-4b77-a204-2bb8219450cd",
   "metadata": {},
   "source": [
    "Notes:\n",
    "\n",
    "During training, exploration is a fundamental concept in RL. We will discuss it in Module 4!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d205da70-1255-437c-8a99-6ea8a5e8d2a0",
   "metadata": {},
   "source": [
    "#### Let's apply what we learned!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd539d44-aa7c-4958-b448-7759f3adc20e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## RLlib trainer methods\n",
    "<!-- multiple choice -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb0453c-7d3e-4092-b6c7-6757c05056ed",
   "metadata": {},
   "source": [
    "exercise: draw the max prob of the plicy as a measure of sureness"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe3eb48-7201-4b1e-9e10-f88c8524fcdc",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Visualizing the policy\n",
    "<!-- coding exercise -->\n",
    "\n",
    "In the slides we looked at the probability of"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad1fa7c-90b0-47e6-8f57-b2a070bb85fc",
   "metadata": {},
   "source": [
    "could revisit previs Ex but look at probabilities this time"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:rl-course-dev-2-clone]",
   "language": "python",
   "name": "conda-env-rl-course-dev-2-clone-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
