{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5aa21ad-6bb9-4990-ab4d-fb9435b0bc00",
   "metadata": {},
   "source": [
    "## Aprendizaje supervisado vs. aprendizaje por refuerzo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "281ff2e0-a58c-46a3-8250-aa0002f2ad9f",
   "metadata": {},
   "source": [
    "#### Actualización del aprendizaje supervisado\n",
    "\n",
    "- El aprendizaje supervisado aprende a predecir y (normalmente un número o una categoría) a partir de x (normalmente un vector de números o una imagen) dado un conjunto de datos.\n",
    "\n",
    "<br><br>\n",
    "\n",
    "➡️ Pulsa la tecla de flecha derecha para avanzar a la siguiente diapositiva (y la tecla de escape para ver todas las diapositivas)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb4df9c-fc80-4571-9f51-8efebc175d24",
   "metadata": {},
   "source": [
    "#### Ejemplos de aprendizaje supervisado\n",
    "\n",
    "- Predicción de los precios de las casas a partir de sus características\n",
    "- Clasificar un correo electrónico como spam o no spam\n",
    "- Identificar si una imagen contiene un perro\n",
    "\n",
    "Idea general: predecir la salida dada la entrada"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e0f26a4-2313-4474-b173-26b32526eecf",
   "metadata": {},
   "source": [
    "#### La \"API\" del aprendizaje supervisado\n",
    "\n",
    "![](img/SL-API.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c2d25f-02fe-495f-9529-7117d2b91f5c",
   "metadata": {},
   "source": [
    "#### La \"API\" del aprendizaje por refuerzo\n",
    "\n",
    "![](img/SL-vs-RL.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f2188e-0756-4fc7-a038-83b1d54fac8f",
   "metadata": {},
   "source": [
    "#### Aprendizaje por refuerzo\n",
    "\n",
    "- Entrada RL: un **entorno** \n",
    "- Salida RL: una **política** que toma decisiones\n",
    "\n",
    "Definiremos los entornos y las políticas más adelante en este módulo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b566b4-2ef9-4545-834f-903a520c855c",
   "metadata": {},
   "source": [
    "\n",
    "#### Ejemplos de aprendizaje por refuerzo\n",
    "\n",
    "- Un coche autodirigido aprendiendo a conducir\n",
    "  - Env: condiciones de la carretera, cómo conduce el coche. Política: el algoritmo de autoconducción\n",
    "- Aprender a jugar a un videojuego\n",
    "  - Env: el juego. Política: la IA del juego\n",
    "- Aprender la \"mejor\" secuencia de películas para recomendar a un usuario\n",
    "  - Env: preferencias/comportamientos del usuario en materia de películas. Política: el sistema de recomendación\n",
    "\n",
    "Idea general: necesitas tomar una secuencia de decisiones y quieres actuar de forma óptima en cada paso.\n",
    "\n",
    "Estas decisiones afectan a las entradas/salidas futuras (a diferencia del SL).\n",
    "\n",
    "Notas:\n",
    "\n",
    "- La entrada del aprendizaje supervisado es un conjunto de datos\n",
    "- La salida es el modelo entrenado que puede hacer predicciones\n",
    "- El propio modelo tiene entradas y salidas ($x$ e $y$)\n",
    "- Ten en cuenta que, de nuevo, la salida es una función que puede utilizarse para calcular/predecir algo.\n",
    "- En la siguiente sección profundizaremos en los entornos y las políticas.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d070eb2b-121b-4925-b30e-80e8d2b1283b",
   "metadata": {},
   "source": [
    "#### ¡Apliquemos lo que hemos aprendido!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6714de6-59d5-428a-90d5-caa45d222203",
   "metadata": {},
   "source": [
    "## Aprendizaje supervisado o aprendizaje por refuerzo\n",
    "<!-- multiple choice -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c20387-a7d2-4697-895a-57e97d4c1013",
   "metadata": {},
   "source": [
    "#### ¿Resolverías este problema con SL o RL?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956a69c9-859d-4a9f-8f49-ca69bdf64876",
   "metadata": {},
   "source": [
    "clasificar las especies a partir de la imagen de un árbol_\n",
    "\n",
    "- [x] SL \n",
    "- [ ] RL | Inténtalo de nuevo -- se trata de una única predicción y no de una secuencia de acciones."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aec3e2f-b3b2-48fb-b466-fc81a2447655",
   "metadata": {},
   "source": [
    "#### ¿Resolverías este problema con SL o RL?\n",
    "\n",
    "crear una IA que juegue al ajedrez_\n",
    "\n",
    "- [ ] SL | Inténtalo de nuevo -- la IA de ajedrez necesita actuar de forma óptima en cada paso de una secuencia.\n",
    "- [x] RL "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c21b1192-8d52-4178-9921-aef09cbd0286",
   "metadata": {},
   "source": [
    "#### ¿Resolverías este problema con SL o RL?\n",
    "\n",
    "predecir si a un usuario le va a gustar o no una película_\n",
    "\n",
    "- [x] SL \n",
    "- [ ] RL | Inténtalo de nuevo -- se trata de una sola predicción y no de una secuencia de acciones.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67cacbff-c6d3-4b5d-9ea7-4d4cd1e3e3a8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# TODO\n",
    "# start the course by showing some really cool results.\n",
    "# not sure yet whether that should be here, or at the end of module 1 (maybe a section 1.4)\n",
    "# let's see...\n",
    "\n",
    "# Also TODO:\n",
    "# Talk about simulations since we can't usually do RL training in a \"real\" environment\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ray200]",
   "language": "python",
   "name": "conda-env-ray200-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
