{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5aa21ad-6bb9-4990-ab4d-fb9435b0bc00",
   "metadata": {},
   "source": [
    "## Recommender env: design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fdd0ce7d-4a5b-4d03-8d93-b176de9e4db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HIDDEN\n",
    "import gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd89af26-eb12-45d8-95b1-14fdd7027deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: adapt images from Sven for this"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0293f36-0ca4-40d4-8c4f-456c07627269",
   "metadata": {},
   "source": [
    "#### Nutzerverhalten simulieren\n",
    "\n",
    "- Simuliere das Nutzerverhalten, wenn du **wiederholt** auf Produktempfehlungen reagierst.\n",
    "- Das wichtigste zu simulierende Verhalten:\n",
    "\n",
    "&gt; Das Empfehlen von \"Junk Food\"-Produkten ist kurzfristig gut, aber auf lange Sicht schlecht.\n",
    "\n",
    "- Das ist allein unsere Entscheidung als Designer der Environment \n",
    "- Vielleicht möchtest du eine andere Art von Nutzerverhalten simulieren/erfassen.\n",
    "  - Oder du kannst aus den Daten zum Nutzerverhalten lernen - dazu später mehr!\n",
    "- Aber das wird unser Beispiel für den Moment sein."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cbb31ad-3891-4d9a-91be-09854ff73c31",
   "metadata": {},
   "source": [
    "#### Schokolade\n",
    "\n",
    "- Wir werden jeden Artikel mit einem \"Süßigkeitsgrad\" modellieren \n",
    "- Artikel mit hohem Süßigkeitsgrad bezeichnen wir als \"Süßigkeiten\".\n",
    "\n",
    "![](img/candy.jpg)\n",
    "\n",
    "- Dabei kann es sich um kurze, alberne Videos oder billigen Schnickschnack im Angebot handeln.\n",
    "- Kurzfristig lieben die Nutzer/innen Süßigkeiten, aber zu viel Schokolade führt langfristig zu Unzufriedenheit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d7aee0e-e60a-419b-bdd0-b0680b5d2f0c",
   "metadata": {},
   "source": [
    "#### Gemüsesorten\n",
    "\n",
    "- Auf der anderen Seite bezeichnen wir süßstoffarme Produkte als \"Gemüse\".\n",
    "\n",
    "![](img/veggies.jpg)\n",
    "\n",
    "- Das können lehrreiche Dokumentationen sein oder langweilige, aber nützliche Dinge usw.\n",
    "- Kurzfristig macht das Gemüse den Nutzern keinen Spaß, aber langfristig steigert es die Zufriedenheit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58280654-1e51-492c-96da-4764c0ceba37",
   "metadata": {},
   "source": [
    "#### Zuckerspiegel\n",
    "\n",
    "- Wir stellen uns vor, dass unsere Nutzer einen **Zuckerspiegel** haben, der angibt, wie viele Süßigkeiten sie in letzter Zeit gegessen haben.\n",
    "- Der Zuckerspiegel des Benutzers (oder die Vorstellung von einem Zuckerspiegel) _ist dem Agenten nicht bekannt_!\n",
    "- Aber im Moment entwerfen wir den Simulator, damit wir alles wissen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ddc3a6-98b4-4a61-a229-4b0ae27c62fd",
   "metadata": {},
   "source": [
    "#### Dynamik des Zuckerspiegels\n",
    "\n",
    "- Wir müssen entscheiden, wie sich der Zuckerspiegel mit dem Verzehr der Artikel verändert.\n",
    "- Ein einfacher Ansatz ist:\n",
    "\n",
    "&gt; Wenn ein Gegenstand verzehrt wird, bewegt sich der Zuckergehalt in Richtung der Süße des Gegenstands.\n",
    "\n",
    "Beispiele:\n",
    "\n",
    "- Wenn dein Zuckerspiegel 0,2 ist und du einen Gegenstand mit der Süße 0,5 konsumierst, steigt dein Zuckerspiegel ⬆️\n",
    "- Wenn dein Zuckerspiegel 0,2 ist und du einen Gegenstand mit der Süße 0,1 konsumierst, sinkt dein Zuckerspiegel ⬇️"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f5fb6ed-8479-40ae-a489-b279f03a61ac",
   "metadata": {},
   "source": [
    "#### Dynamik des Zuckerspiegels\n",
    "\n",
    "- Wie können wir das mathematisch darstellen?\n",
    "- Wir können dies versuchen:\n",
    "\n",
    "&gt; neuer Zuckerspiegel = ⍺ (alter Zuckerspiegel) + (1 - ⍺) (Artikelsüße)\n",
    "\n",
    "- Dabei ist ⍺ eine Zahl zwischen 0 und 1, die bestimmt, wie \"hartnäckig\" der Zuckergehalt ist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce8adf56-8b56-4dc7-bb3d-3a2cebfe6f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HIDDEN \n",
    "# note the slide above and below are partially the same - just want to hide the bottom half at first"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b8ebcf-d522-42e6-8777-a32b516259e4",
   "metadata": {},
   "source": [
    "#### Dynamik des Zuckerspiegels\n",
    "\n",
    "- Wie können wir das mathematisch darstellen?\n",
    "- Wir können dies versuchen:\n",
    "\n",
    "&gt; neuer Zuckerspiegel = ⍺ (alter Zuckerspiegel) + (1 - ⍺) (Artikelsüße)\n",
    "\n",
    "- Dabei ist ⍺ eine Zahl zwischen 0 und 1, die bestimmt, wie \"hartnäckig\" der Zuckergehalt ist.\n",
    "- Wenn zum Beispiel ⍺=1 ist, wird die obige Gleichung zu\n",
    "\n",
    "&gt; neuer Zuckerspiegel = alter Zuckerspiegel\n",
    "\n",
    "und der Zuckerspiegel ändert sich nie. Wenn ⍺=0 ist, haben wir\n",
    "\n",
    "&gt; neuer Zuckerspiegel = Gegenstandssüße\n",
    "\n",
    "was bedeutet, dass ein einziger Gegenstand den Zuckerspiegel des Nutzers vollständig verändern kann.\n",
    "\n",
    "- Für ⍺ zwischen 0 und 1 haben wir eine Kombination aus dem alten Zuckerspiegel und der Item-Süße."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fca4d06-9168-41b9-8ab2-fc1fd34ce0d1",
   "metadata": {},
   "source": [
    "#### Dynamik des Zuckerspiegels\n",
    "\n",
    "Mit dieser Funktion können wir das obige umsetzen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7821a2f-b42f-4c64-a3d7-a02c7658120f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_sugar_level(sugar_level, item_sweetness, alpha=0.9):\n",
    "    return alpha * sugar_level + (1 - alpha) * item_sweetness"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "796a261f-2cf0-48f4-ab95-c8ff4c7800be",
   "metadata": {},
   "source": [
    "Probieren wir es aus, um sicherzustellen, dass das Verhalten sinnvoll ist (mit dem Standardwert ⍺=0,9):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b934fd76-bda0-4e6d-ad2e-17de12d3b4e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.26"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sugar_level = 0.2\n",
    "sugar_level = update_sugar_level(sugar_level, 0.8)\n",
    "sugar_level"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eda542e-c236-4906-bf8f-fa5f7ab5d238",
   "metadata": {},
   "source": [
    "Der Artikel war süß (0,8), so dass der Zuckerspiegel ziemlich in die Höhe ging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e9e6f2a-ee8a-4458-82eb-afb57e858676",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.264"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sugar_level = update_sugar_level(sugar_level, 0.3)\n",
    "sugar_level"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d9bda3-2c8f-44f8-8cf0-4e3a31cfb404",
   "metadata": {},
   "source": [
    "Der Artikel Süße lag etwas über dem Zuckerspiegel, so dass der Zuckerspiegel leicht anstieg."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27253dfb-a220-4d0f-9816-1fb542f1045b",
   "metadata": {},
   "source": [
    "#### Dynamik des Zuckerspiegels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c8c863a1-c37e-4c29-8136-0529501118b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2386"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sugar_level = update_sugar_level(sugar_level, 0.01)\n",
    "sugar_level"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eeb5116-a9ab-49d9-8748-d751662a994b",
   "metadata": {},
   "source": [
    "Der Artikel war nicht süß, also ging der Zuckergehalt runter."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c20efd-9ca1-43be-8529-aacb7244ad4c",
   "metadata": {},
   "source": [
    "#### Wirkung von alpha\n",
    "\n",
    "Wir können sehen, dass sich der Zuckerspiegel mit einem kleineren Alpha viel schneller ändert:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b684f74b-3519-4300-b4f2-5ff68c0199e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1193"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sugar_level = update_sugar_level(sugar_level, 0.0, alpha=0.5)\n",
    "sugar_level"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea5d8350-5daa-4377-9ec4-79819528d0bb",
   "metadata": {},
   "source": [
    "#### Belohnung\n",
    "\n",
    "- Na toll, jetzt haben wir die Dynamik des Zuckerspiegels im Griff!\n",
    "- Das zweite wichtige Teil des Puzzles ist die Belohnung.\n",
    "- Was wir wollen:\n",
    "\n",
    "1. Je süßer der Gegenstand, desto höher die Belohnung (lecker, Süßigkeiten!)\n",
    "2. Ein höherer Zuckergehalt führt zu einer geringeren Belohnung (ach, zu viel Süßes!)\n",
    "\n",
    "Eine einfache Möglichkeit, diese Effekte zu kombinieren, ist, sie miteinander zu multiplizieren:\n",
    "\n",
    "&gt; Belohnung = Süße des Gegenstands * (1 - Zuckergehalt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f6d77a-2458-4a51-91c4-070d074c1978",
   "metadata": {},
   "source": [
    "#### Implementierung von Belohnungen\n",
    "\n",
    "&gt; Belohnung = Gegenstand Süße * (1 - Zuckergehalt)\n",
    "\n",
    "Wir können dies wie folgt kodieren:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "258777c5-b896-4ec4-b999-38c4aadafdbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reward(sugar_level, item_sweetness):\n",
    "    return item_sweetness * (1 - sugar_level)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a1eeea-f027-419c-8f80-756eec6be9ea",
   "metadata": {},
   "source": [
    "Wir werden diese Teile im nächsten Abschnitt verwenden, wenn wir unsere Environment implementieren!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c68cf7-4dc6-4ab4-86c5-93b10fced0ae",
   "metadata": {},
   "source": [
    "#### Beobachtungsraum\n",
    "\n",
    "- Als Nächstes müssen wir die Beobachtungen einrichten \n",
    "- Unsere Beobachtungen sind die _Merkmale der Artikelkandidaten_.\n",
    "- Der Einfachheit halber nehmen wir an, dass es nur 1 Merkmal gibt, nämlich die Süße des Artikels.\n",
    "- Der Agent sieht also eine Reihe von Süßigkeitsstufen und wählt eine davon aus."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb5cadd-bbdc-4a19-931c-522c8902407f",
   "metadata": {},
   "source": [
    "#### Aktionsraum\n",
    "\n",
    "- In diesem Umfeld ist die Aktion das ausgewählte Element, das angesichts der Kandidaten empfohlen wird."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f7ccbd3-57d6-4914-94a0-7fb03fa0b96e",
   "metadata": {},
   "source": [
    "#### Lass uns das Gelernte anwenden!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bebfec4-9043-498b-b3da-bc91700a74bf",
   "metadata": {},
   "source": [
    "## Big-Picture\n",
    "<!-- multiple choice -->\n",
    "\n",
    "Welche der folgenden Aussagen über die simulierte Empfehlungs-RL-Environment, die wir erstellen, ist **NICHT** wahr?\n",
    "\n",
    "- [ ] Die Environment enthält ein stark vereinfachtes Modell des Nutzerverhaltens, aber ein trainierter Agent kann trotzdem nützlich sein, um Empfehlungen zu geben.\n",
    "- [x] Die Environment gibt genau wieder, wie sich reale Nutzer verhalten.\n",
    "- [ ] Die Environment ist ein guter Ausgangspunkt, und wir möchten die Komplexität im Laufe unserer Arbeit vielleicht noch erhöhen.\n",
    "- [Die Environment berücksichtigt die Tatsache, dass die Nutzer/innen auf verschiedene Gegenstände unterschiedlich reagieren und dass diese Reaktionen von ihrer Vergangenheit abhängen können."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe02b60a-f753-4299-9953-2a6109b77f8a",
   "metadata": {},
   "source": [
    "## Empfehlende Belohnungen\n",
    "<!-- multiple choice -->\n",
    "\n",
    "Erinnern Sie sich, dass unsere Belohnungsfunktion lautet\n",
    "\n",
    "&gt; Belohnung = Süße des Artikels * (1 - Zuckergehalt)\n",
    "\n",
    "#### Kurzfristige Zufriedenheit\n",
    "\n",
    "Richtig oder falsch: Zu einem bestimmten Zeitpunkt ist die _unmittelbare_ Belohnung für Süßigkeiten _immer_ größer als für Gemüse.\n",
    "\n",
    "- [Richtig | Die unmittelbare Belohnung ist direkt proportional zur Süße des Gegenstands.\n",
    "- [Falsch | Sieh dir die Formel oben genauer an!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e512009-9deb-4c39-a055-3e82a7acdf14",
   "metadata": {},
   "source": [
    "#### Langfristige Zufriedenheit\n",
    "\n",
    "Richtig oder falsch: Zu einem bestimmten Zeitpunkt ist die _langfristige Gesamtbelohnung_ für die Empfehlung von Gemüse _immer_ größer als für Süßigkeiten.\n",
    "\n",
    "- [Richtig | Es ist kompliziert zu bestimmen, was langfristig das Beste ist - das muss unser Agent lernen!\n",
    "- [x] Falsch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2622b06b-90fc-4fc7-9448-a782be431d63",
   "metadata": {},
   "source": [
    "## Zucker-Crash\n",
    "<!-- coding exercise -->\n",
    "\n",
    "Nehmen wir an, dein Zuckerspiegel beginnt bei 0,5 und du hast bei jedem Schritt nur zwei Produkte zur Auswahl: Mega-Gemüse (Süße = 0) und Mega-Süßigkeiten (Süße = 1). Du gibst 3 Empfehlungen hintereinander ab, wobei Alpha = 0,7 gilt. Nutze das Kodierfenster unten, um mit verschiedenen Optionen zu spielen und die beste Reihenfolge der Empfehlungen im Hinblick auf die _gesamte_ Belohnung zu finden "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d8695dc5-2538-4158-95fa-50a9135b42f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Received reward 0.00000, new sugar level 0.35000\n",
      "  Received reward 0.00000, new sugar level 0.24500\n",
      "  Received reward 0.00000, new sugar level 0.17150\n",
      "Total reward after 5 recommendations: 0.0\n"
     ]
    }
   ],
   "source": [
    "# EXERCISE\n",
    "\n",
    "def update_sugar_level(sugar_level, item_sweetness, alpha=0.9):\n",
    "    return alpha * sugar_level + (1 - alpha) * item_sweetness\n",
    "\n",
    "def reward(sugar_level, item_sweetness):\n",
    "    return item_sweetness * (1 - sugar_level)\n",
    "\n",
    "# MODIFY THIS LIST\n",
    "# But make sure it always contains 3 items, each 0 or 1\n",
    "recommendations = [0, 0, 0]\n",
    "\n",
    "# starting sugar level\n",
    "sugar_level = 0.5\n",
    "\n",
    "total_reward = 0\n",
    "\n",
    "for item_sweetness in recommendations:\n",
    "    \n",
    "    # add reward\n",
    "    immediate_reward = reward(sugar_level, item_sweetness)\n",
    "    total_reward += immediate_reward\n",
    "    \n",
    "    # update sugar level\n",
    "    sugar_level = update_sugar_level(sugar_level, item_sweetness, alpha=0.7)\n",
    "    \n",
    "    print(f\"  Received reward {immediate_reward:.5f}, new sugar level {sugar_level:.5f}\")\n",
    "    \n",
    "print(\"Total reward after 5 recommendations:\", total_reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d2d62233-1f33-47fe-b155-15e12dd9a8ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Received reward 0.00000, new sugar level 0.35000\n",
      "  Received reward 0.65000, new sugar level 0.54500\n",
      "  Received reward 0.45500, new sugar level 0.68150\n",
      "Total reward after 5 recommendations 1.105\n"
     ]
    }
   ],
   "source": [
    "# SOLUTION\n",
    "\n",
    "def update_sugar_level(sugar_level, item_sweetness, alpha=0.9):\n",
    "    return alpha * sugar_level + (1 - alpha) * item_sweetness\n",
    "\n",
    "def reward(sugar_level, item_sweetness):\n",
    "    return item_sweetness * (1 - sugar_level)\n",
    "\n",
    "# MODIFY THIS LIST\n",
    "# But make sure it always contains 3 items, each 0 or 1\n",
    "recommendations = [0,1,1]\n",
    "\n",
    "# starting sugar level\n",
    "sugar_level = 0.5\n",
    "\n",
    "total_reward = 0\n",
    "\n",
    "for item_sweetness in recommendations:\n",
    "    \n",
    "    # add reward\n",
    "    immediate_reward = reward(sugar_level, item_sweetness)\n",
    "    total_reward += immediate_reward\n",
    "    \n",
    "    # update sugar level\n",
    "    sugar_level = update_sugar_level(sugar_level, item_sweetness, alpha=0.7)\n",
    "    \n",
    "    print(f\"  Received reward {immediate_reward:.5f}, new sugar level {sugar_level:.5f}\")\n",
    "    \n",
    "print(\"Total reward after 5 recommendations\", total_reward)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a377412-aefd-4b85-8b94-de3869d0858a",
   "metadata": {},
   "source": [
    "#### Was war die beste Policy in diesem Beispiel?\n",
    "\n",
    "- [x] 1 Gemüse, um den Zuckerspiegel zu senken, dann 2 Süßigkeiten für die süße, süße Belohnung.\n",
    "- [x] Süßigkeiten, dann Gemüse für die Gesundheit, dann wieder Süßigkeiten.\n",
    "- [ ] Gemüse für alle Fälle!\n",
    "- [ ] Süßigkeiten bis zum Schluss!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080aeba6-d6fd-461c-8ab7-c6420f692f93",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ray200]",
   "language": "python",
   "name": "conda-env-ray200-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
