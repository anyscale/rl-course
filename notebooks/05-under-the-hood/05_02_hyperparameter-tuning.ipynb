{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b02cdbb-95e8-451d-87d5-8a3f07088797",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a9a6bb4-1668-4b87-a908-2a41204458f8",
   "metadata": {},
   "source": [
    "#### Ray tune\n",
    "\n",
    "![](img/rllib_and_tune.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "385c99f3-3400-4f54-881d-391fba6c36da",
   "metadata": {},
   "source": [
    "#### Key hypers\n",
    "\n",
    "- `lr`\n",
    "- `train_batch_size`\n",
    "- `sgd_minibatch_size`\n",
    "- `num_sgd_iter`\n",
    "- `entropy_coeff`\n",
    "- model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "493fe311-47cc-479b-99ae-4042f74401f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_config = {\n",
    "    \"num_candidates\" : 2,\n",
    "    \"alpha\"          : 0.5,\n",
    "    \"seed\"           : 42\n",
    "}\n",
    "\n",
    "tune_config = {\n",
    "    \"framework\"             : \"torch\",\n",
    "    \"create_env_on_driver\"  : True,\n",
    "    \"seed\"                  : 0,\n",
    "    \"lr\"                    : 0.001,\n",
    "    \"model\"                 : {\n",
    "        \"fcnet_hiddens\"     : [64, 64]\n",
    "    },\n",
    "    \"env\"                   : BasicRecommender,\n",
    "    \"env_config\"            : env_config\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b327fc30-a3a2-4e47-9ac8-92b4f577d2ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-07-14 09:51:31 (running for 00:00:00.22)<br>Memory usage on this node: 6.8/8.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/8 CPUs, 0/0 GPUs, 0.0/3.05 GiB heap, 0.0/1.53 GiB objects<br>Result logdir: /Users/mike/git/anyscale/rl-course/notebooks/04-application-recommender/PPO<br>Number of trials: 1/1 (1 PENDING)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(PPOTrainer pid=63452)\u001b[0m 2022-07-14 09:51:34,080\tINFO ppo.py:249 -- In multi-agent mode, policies will be optimized sequentially by the multi-GPU optimizer. Consider setting simple_optimizer=True if this doesn't work for you.\n",
      "\u001b[2m\u001b[36m(PPOTrainer pid=63452)\u001b[0m 2022-07-14 09:51:34,090\tINFO trainer.py:779 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-07-14 09:51:36 (running for 00:00:05.46)<br>Memory usage on this node: 6.8/8.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/8 CPUs, 0/0 GPUs, 0.0/3.05 GiB heap, 0.0/1.53 GiB objects<br>Result logdir: /Users/mike/git/anyscale/rl-course/notebooks/04-application-recommender/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial PPO_BasicRecommender_36008_00000 reported episode_reward_max=26.229951468536488,episode_reward_min=24.437207722145967,episode_reward_mean=25.367144631882343,episode_len_mean=100.0,episode_media={},episodes_this_iter=40,policy_reward_min={},policy_reward_max={},policy_reward_mean={},custom_metrics={},sampler_perf={'mean_raw_obs_processing_ms': 0.03270105622161454, 'mean_inference_ms': 0.25230732516966003, 'mean_action_processing_ms': 0.015700894078869987, 'mean_env_wait_ms': 0.014201394919453113, 'mean_env_render_ms': 0.0},off_policy_estimator={},num_healthy_workers=2,timesteps_this_iter=4000,agent_timesteps_total=4000,timers={'sample_time_ms': 3011.171, 'sample_throughput': 1328.387, 'load_time_ms': 6.652, 'load_throughput': 601333.907, 'learn_time_ms': 1587.199, 'learn_throughput': 2520.163, 'update_time_ms': 2.732},info={'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.20000000000000004, 'cur_lr': 0.0010000000000000005, 'total_loss': 25.43452578206216, 'policy_loss': -0.014144874419716577, 'vf_loss': 25.447020125645462, 'vf_explained_var': -0.001425929287428497, 'kl': 0.008252872885188042, 'entropy': 0.6851955661850591, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}}}, 'num_steps_sampled': 4000, 'num_agent_steps_sampled': 4000, 'num_steps_trained': 4000, 'num_steps_trained_this_iter': 4000, 'num_agent_steps_trained': 4000},perf={'cpu_util_percent': 34.114285714285714, 'ram_util_percent': 85.31428571428572} with parameters={'framework': 'torch', 'create_env_on_driver': True, 'seed': 0, 'lr': 0.001, 'model': {'fcnet_hiddens': [64, 64]}, 'env': <class 'envs.BasicRecommender'>, 'env_config': {'num_candidates': 2, 'alpha': 0.5, 'seed': 42}}.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-07-14 09:51:42 (running for 00:00:11.04)<br>Memory usage on this node: 6.8/8.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/8 CPUs, 0/0 GPUs, 0.0/3.05 GiB heap, 0.0/1.53 GiB objects<br>Result logdir: /Users/mike/git/anyscale/rl-course/notebooks/04-application-recommender/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial PPO_BasicRecommender_36008_00000 reported episode_reward_max=26.52690953227332,episode_reward_min=24.093393864945554,episode_reward_mean=25.429153526172882,episode_len_mean=100.0,episode_media={},episodes_this_iter=40,policy_reward_min={},policy_reward_max={},policy_reward_mean={},custom_metrics={},sampler_perf={'mean_raw_obs_processing_ms': 0.036330457471485056, 'mean_inference_ms': 0.2579944025246475, 'mean_action_processing_ms': 0.015710399918824974, 'mean_env_wait_ms': 0.01514268198918096, 'mean_env_render_ms': 0.0},off_policy_estimator={},num_healthy_workers=2,timesteps_this_iter=4000,agent_timesteps_total=16000,timers={'sample_time_ms': 2459.617, 'sample_throughput': 1626.269, 'load_time_ms': 1.859, 'load_throughput': 2151752.725, 'learn_time_ms': 1446.732, 'learn_throughput': 2764.852, 'update_time_ms': 3.082},info={'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.20000000000000004, 'cur_lr': 0.0010000000000000005, 'total_loss': 20.42486534836472, 'policy_loss': -0.012980463006283327, 'vf_loss': 20.436380077690206, 'vf_explained_var': 5.428579545790149e-05, 'kl': 0.007328934054126103, 'entropy': 0.6597061257208547, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}}}, 'num_steps_sampled': 16000, 'num_agent_steps_sampled': 16000, 'num_steps_trained': 16000, 'num_steps_trained_this_iter': 4000, 'num_agent_steps_trained': 16000},perf={'cpu_util_percent': 46.166666666666664, 'ram_util_percent': 86.0} with parameters={'framework': 'torch', 'create_env_on_driver': True, 'seed': 0, 'lr': 0.001, 'model': {'fcnet_hiddens': [64, 64]}, 'env': <class 'envs.BasicRecommender'>, 'env_config': {'num_candidates': 2, 'alpha': 0.5, 'seed': 42}}.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-07-14 09:51:47 (running for 00:00:16.62)<br>Memory usage on this node: 6.8/8.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/8 CPUs, 0/0 GPUs, 0.0/3.05 GiB heap, 0.0/1.53 GiB objects<br>Result logdir: /Users/mike/git/anyscale/rl-course/notebooks/04-application-recommender/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial PPO_BasicRecommender_36008_00000 reported episode_reward_max=26.771151646915843,episode_reward_min=24.011689111219024,episode_reward_mean=25.575060131062806,episode_len_mean=100.0,episode_media={},episodes_this_iter=40,policy_reward_min={},policy_reward_max={},policy_reward_mean={},custom_metrics={},sampler_perf={'mean_raw_obs_processing_ms': 0.0378616620354775, 'mean_inference_ms': 0.263690299528818, 'mean_action_processing_ms': 0.016213090765989046, 'mean_env_wait_ms': 0.015341564616789033, 'mean_env_render_ms': 0.0},off_policy_estimator={},num_healthy_workers=2,timesteps_this_iter=4000,agent_timesteps_total=28000,timers={'sample_time_ms': 2288.985, 'sample_throughput': 1747.5, 'load_time_ms': 1.285, 'load_throughput': 3112573.534, 'learn_time_ms': 1380.818, 'learn_throughput': 2896.834, 'update_time_ms': 2.364},info={'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.10000000000000002, 'cur_lr': 0.0010000000000000005, 'total_loss': 20.654890163995887, 'policy_loss': -0.01704748478988486, 'vf_loss': 20.6707669391427, 'vf_explained_var': 2.0207640945270496e-05, 'kl': 0.011707536025864792, 'entropy': 0.648529960134978, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}}}, 'num_steps_sampled': 28000, 'num_agent_steps_sampled': 28000, 'num_steps_trained': 28000, 'num_steps_trained_this_iter': 4000, 'num_agent_steps_trained': 28000},perf={'cpu_util_percent': 31.599999999999998, 'ram_util_percent': 85.23333333333333} with parameters={'framework': 'torch', 'create_env_on_driver': True, 'seed': 0, 'lr': 0.001, 'model': {'fcnet_hiddens': [64, 64]}, 'env': <class 'envs.BasicRecommender'>, 'env_config': {'num_candidates': 2, 'alpha': 0.5, 'seed': 42}}.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-07-14 09:51:52 (running for 00:00:21.63)<br>Memory usage on this node: 6.8/8.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/8 CPUs, 0/0 GPUs, 0.0/3.05 GiB heap, 0.0/1.53 GiB objects<br>Result logdir: /Users/mike/git/anyscale/rl-course/notebooks/04-application-recommender/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-07-14 09:51:57 (running for 00:00:26.74)<br>Memory usage on this node: 6.8/8.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 3.0/8 CPUs, 0/0 GPUs, 0.0/3.05 GiB heap, 0.0/1.53 GiB objects<br>Result logdir: /Users/mike/git/anyscale/rl-course/notebooks/04-application-recommender/PPO<br>Number of trials: 1/1 (1 RUNNING)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial PPO_BasicRecommender_36008_00000 reported episode_reward_max=26.6548669958362,episode_reward_min=24.056177303270747,episode_reward_mean=25.540941366961775,episode_len_mean=100.0,episode_media={},episodes_this_iter=40,policy_reward_min={},policy_reward_max={},policy_reward_mean={},custom_metrics={},sampler_perf={'mean_raw_obs_processing_ms': 0.036447590817010475, 'mean_inference_ms': 0.25664676157687394, 'mean_action_processing_ms': 0.015811126708607494, 'mean_env_wait_ms': 0.014775917683812385, 'mean_env_render_ms': 0.0},off_policy_estimator={},num_healthy_workers=2,timesteps_this_iter=4000,agent_timesteps_total=40000,timers={'sample_time_ms': 2217.21, 'sample_throughput': 1804.069, 'load_time_ms': 1.0, 'load_throughput': 4000862.307, 'learn_time_ms': 1385.19, 'learn_throughput': 2887.692, 'update_time_ms': 2.919},info={'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.10000000000000002, 'cur_lr': 0.0010000000000000005, 'total_loss': 20.466726658933908, 'policy_loss': -0.015410010112068986, 'vf_loss': 20.48122098368983, 'vf_explained_var': -1.1669948536862609e-05, 'kl': 0.009155829549640001, 'entropy': 0.6179378610144379, 'entropy_coeff': 0.0}, 'model': {}, 'custom_metrics': {}}}, 'num_steps_sampled': 40000, 'num_agent_steps_sampled': 40000, 'num_steps_trained': 40000, 'num_steps_trained_this_iter': 4000, 'num_agent_steps_trained': 40000},perf={'cpu_util_percent': 45.633333333333326, 'ram_util_percent': 85.39999999999999} with parameters={'framework': 'torch', 'create_env_on_driver': True, 'seed': 0, 'lr': 0.001, 'model': {'fcnet_hiddens': [64, 64]}, 'env': <class 'envs.BasicRecommender'>, 'env_config': {'num_candidates': 2, 'alpha': 0.5, 'seed': 42}}. This trial completed.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-07-14 09:51:57 (running for 00:00:26.83)<br>Memory usage on this node: 6.8/8.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/8 CPUs, 0/0 GPUs, 0.0/3.05 GiB heap, 0.0/1.53 GiB objects<br>Result logdir: /Users/mike/git/anyscale/rl-course/notebooks/04-application-recommender/PPO<br>Number of trials: 1/1 (1 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_BasicRecommender_36008_00000</td><td>TERMINATED</td><td>127.0.0.1:63452</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         23.1234</td><td style=\"text-align: right;\">40000</td><td style=\"text-align: right;\"> 25.5409</td><td style=\"text-align: right;\">             26.6549</td><td style=\"text-align: right;\">             24.0562</td><td style=\"text-align: right;\">               100</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(PPOTrainer pid=63452)\u001b[0m 2022-07-14 09:51:57,783\tWARNING deprecation.py:45 -- DeprecationWarning: `clear_buffer` has been deprecated. Use `Filter.reset_buffer()` instead. This will raise an error in the future!\n",
      "2022-07-14 09:51:58,607\tINFO tune.py:639 -- Total run time: 27.73 seconds (26.82 seconds for the tuning loop).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ray.tune.analysis.experiment_analysis.ExperimentAnalysis at 0x126f5e7f0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tune.run(\"PPO\", config = tune_config, stop = {\"training_iteration\": 10}, checkpoint_at_end=True, verbose=2, local_dir=\".\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:rl-course-dev-2]",
   "language": "python",
   "name": "conda-env-rl-course-dev-2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
