{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be76afd1-30c0-4f6a-9107-bf9eef74f904",
   "metadata": {},
   "source": [
    "## Ray"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fea144b-381f-4fcd-ac3d-e9f1d364d660",
   "metadata": {},
   "source": [
    "#### What is Ray?\n",
    "\n",
    "This whole course we've been using the Ray package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41754b57-9c36-48f7-843a-4989c90f357b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray.rllib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4357c3f6-bc60-4eb4-b4be-6aac32900960",
   "metadata": {},
   "source": [
    "![](img/ray-logo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "173eca68-40f8-43ce-9889-a4d3b6f96505",
   "metadata": {},
   "source": [
    "What is Ray? From the [docs](https://docs.ray.io/en/latest/):\n",
    "\n",
    "> Ray is a general-purpose and universal distributed compute framework.\n",
    "\n",
    "Ray is also:\n",
    "\n",
    "- An [active open source project](https://github.com/ray-project/ray) with over 20k stars on GitHub ðŸ¤©\n",
    "- Backed by the unicorn startup [Anyscale](https://www.anyscale.com/), that produced this course ðŸ¦„\n",
    "\n",
    "Notes:\n",
    "\n",
    "But, back to distributed computing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bceac41-d9d5-46e4-8e3a-21d5a914a986",
   "metadata": {},
   "source": [
    "#### What is distributed computing?\n",
    "\n",
    "_Distributed computing_ is computing that involves multiple machines (nodes) distributed across a network.\n",
    "\n",
    "![](img/supercomputer.png)\n",
    "\n",
    "Pros:\n",
    "\n",
    "- Massively improved capabilities\n",
    "\n",
    "Cons/challenges:\n",
    "\n",
    "- Synchronization\n",
    "- Failure\n",
    "- ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d345f4-5b01-49f2-9635-130f4d580f21",
   "metadata": {},
   "source": [
    "#### Ray makes distributed computing easy\n",
    "\n",
    "- The goal of Ray is to make distributed computing easy and accessible.\n",
    "- Ray handles most of the challenges for users.\n",
    "- RLlib, tune and the other sub-packages were built on top of Ray.\n",
    "- This means _RLlib and tune automatically have distributed capabilities._\n",
    "\n",
    "Notes:\n",
    "\n",
    "Surprise! RLlib is easy to use and conveniently implements many state-of-the-art RL algorithms, but it has another benefit that we didn't mention until now: natural distributed computing capabilities. This puts it well ahead of competing packages in ease of distributing the computation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "275fe8fc-292d-4622-b7c9-5e6d0c0f4022",
   "metadata": {},
   "source": [
    "#### RLlib, distributed\n",
    "\n",
    "- In this course we set up algorithm configs many times.\n",
    "- But there are some parameters we haven't used before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a1e8fe8-c52d-4cf6-a846-75f6ca83e381",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray.rllib.algorithms.ppo import PPOConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68ff95da-eee7-45eb-9694-ac4fd5420c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "ppo_config = (\n",
    "    PPOConfig()\\\n",
    "    .framework(\"torch\")\\\n",
    "    .rollouts(num_rollout_workers=4, num_envs_per_worker=2)\\\n",
    "    .resources(num_gpus=0)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e10ccc-cc94-41a3-bcda-66de6cf68fcc",
   "metadata": {},
   "source": [
    "You can read more about specifying resources [here](https://docs.ray.io/en/master/rllib/rllib-training.html#specifying-resources) and about scaling [here](https://docs.ray.io/en/master/rllib/rllib-training.html#scaling-guide)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec03fa7b-c78f-446d-9be7-deac2c895ce2",
   "metadata": {},
   "source": [
    "But... what is a \"rollout worker\"?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ebdf4e-e1c0-41c9-b923-1a3917106f9e",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Rollout workers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d5ea641-4738-4220-8adc-78d5a65141e0",
   "metadata": {},
   "source": [
    "- Rollout workers collect data from the environment (simulator) in parallel.\n",
    "- For most simulator environments, one can replicate the environment in a cluster.\n",
    "- Therefore, you can collect data much faster and avoid bottlenecking the training.\n",
    "- Whatever cluster Ray is connected to on the backend, `num_rollout_workers=4` works seamlessly.\n",
    "\n",
    "Notes:\n",
    "\n",
    "In supervised learning, when you're waiting you know you're probably waiting for the model to train. In RL, the bottleneck could be the data collection or the model updates. Being able to parallelize rollouts alleviates the data collection bottleneck. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac61bd0-31ac-47e7-a51b-6ff1b92cb753",
   "metadata": {},
   "source": [
    "#### Driver\n",
    "\n",
    "In all our configs we've had\n",
    "\n",
    "```python\n",
    "create_env_on_driver = True\n",
    "```\n",
    "\n",
    "What this means is that we put the env on the same \"driver\" process that's running the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "340e0f0a-7954-44b1-ad30-a146f3ba89b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "76648d6e-5b58-4241-aeb3-84d4dc6c661f",
   "metadata": {},
   "source": [
    "#### Let's apply what we learned!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d0b93e-69ad-4338-b937-62bb19fc506b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## MCQ\n",
    "<!-- multiple choice -->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd7a1f3a-18b5-4d99-ad1f-409bf87b59ad",
   "metadata": {},
   "source": [
    "## Coding\n",
    "<!-- coding exercise -->\n",
    "\n",
    "Have them do something simple with Ray core, or with RLlib where we can see the processes somehow - or just see that it's faster, though it might not be depending on how the cluster is set up...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2405893d-2dc6-4a91-8d22-bb4db1450b3b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ray2beta]",
   "language": "python",
   "name": "conda-env-ray2beta-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
