{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5aa21ad-6bb9-4990-ab4d-fb9435b0bc00",
   "metadata": {},
   "source": [
    "## Supervised learning vs. reinforcement learning\n",
    "<!-- video shot=\"/uTwaFTVJG6g\" start=\"00:30\" end=\"03:47\" -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "281ff2e0-a58c-46a3-8250-aa0002f2ad9f",
   "metadata": {},
   "source": [
    "#### Supervised learning refresher\n",
    "\n",
    "- Supervised learning learns to predict y (most commonly a number or category) from x (most commonly a vector of numbers or an image) given a dataset.\n",
    "\n",
    "<br><br>\n",
    "\n",
    "➡️ Press the right arrow key to advance to the next slide (and the escape key to see all slides)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb4df9c-fc80-4571-9f51-8efebc175d24",
   "metadata": {},
   "source": [
    "#### Supervised learning examples\n",
    "\n",
    "- Predicting house prices given house features\n",
    "- Classifying an email as spam or not spam\n",
    "- Identifying whether an image contains a dog\n",
    "\n",
    "General idea: predict the output given the input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e0f26a4-2313-4474-b173-26b32526eecf",
   "metadata": {},
   "source": [
    "#### The \"API\" of supervised learning\n",
    "\n",
    "![](img/SL-API.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c2d25f-02fe-495f-9529-7117d2b91f5c",
   "metadata": {},
   "source": [
    "#### The \"API\" of reinforcement learning\n",
    "\n",
    "![](img/SL-vs-RL.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f2188e-0756-4fc7-a038-83b1d54fac8f",
   "metadata": {},
   "source": [
    "#### Reinforcement learning\n",
    "\n",
    "- RL input: an **environment** \n",
    "- RL output: a **policy** that makes decisions\n",
    "\n",
    "We will define environments and policies later in this module!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b566b4-2ef9-4545-834f-903a520c855c",
   "metadata": {},
   "source": [
    "#### Reinforcement learning examples\n",
    "\n",
    "- A self-driving car learning to drive\n",
    "  - Env: road conditions, how the car drives. Policy: the self-driving algorithm\n",
    "- Learning to play a video game\n",
    "  - Env: the game. Policy: the game AI\n",
    "- Learning the \"best\" sequence of movies to recommend to a user\n",
    "  - Env: user movie preferences/behaviors. Policy: the recommender system\n",
    "\n",
    "General idea: you need to make a sequence of decisions and want to act optimally at each step.\n",
    "\n",
    "These decisions affect future inputs/outputs (unlike SL).\n",
    "\n",
    "Notes:\n",
    "\n",
    "- The input to supervised learning is a dataset\n",
    "- The output is the trained model that can make predictions\n",
    "- The model itself has inputs and outputs ($x$ and $y$)\n",
    "- Note that, again, the output is a function which can be used to compute/predict something.\n",
    "- In the next section we'll delve into environments and policies.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d070eb2b-121b-4925-b30e-80e8d2b1283b",
   "metadata": {},
   "source": [
    "#### Let's apply what we learned!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6714de6-59d5-428a-90d5-caa45d222203",
   "metadata": {},
   "source": [
    "## Supervised learning or reinforcement learning\n",
    "<!-- multiple choice -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c20387-a7d2-4697-895a-57e97d4c1013",
   "metadata": {},
   "source": [
    "#### Would you solve this problem with SL or RL?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956a69c9-859d-4a9f-8f49-ca69bdf64876",
   "metadata": {},
   "source": [
    "_Classifying the species based on an image of a tree_\n",
    "\n",
    "- [x] SL \n",
    "- [ ] RL | Try again -- this is a single prediction rather than a sequence of actions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aec3e2f-b3b2-48fb-b466-fc81a2447655",
   "metadata": {},
   "source": [
    "#### Would you solve this problem with SL or RL?\n",
    "\n",
    "_Creating an AI that plays chess_\n",
    "\n",
    "- [ ] SL | Try again -- the chess AI needs to act optimally at each step in a sequence.\n",
    "- [x] RL "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c21b1192-8d52-4178-9921-aef09cbd0286",
   "metadata": {},
   "source": [
    "#### Would you solve this problem with SL or RL?\n",
    "\n",
    "_Predicting whether or not a user will like a movie_\n",
    "\n",
    "- [x] SL \n",
    "- [ ] RL | Try again -- this is a single prediction rather than a sequence of actions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67cacbff-c6d3-4b5d-9ea7-4d4cd1e3e3a8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# TODO\n",
    "# start the course by showing some really cool results.\n",
    "# not sure yet whether that should be here, or at the end of module 1 (maybe a section 1.4)\n",
    "# let's see...\n",
    "\n",
    "# Also TODO:\n",
    "# Talk about simulations since we can't usually do RL training in a \"real\" environment\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ray200]",
   "language": "python",
   "name": "conda-env-ray200-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
