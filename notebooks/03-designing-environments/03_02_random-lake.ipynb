{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e23df55-837b-4ec9-86ad-3b60c6a7f00d",
   "metadata": {},
   "source": [
    "## Random Lake Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ffbd783-053c-47c6-afb4-72724590ee1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HIDDEN\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9081d4b5-47ed-48ed-abe0-1ef2f7c23847",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HIDDEN\n",
    "import ray\n",
    "import logging\n",
    "ray.init(log_to_driver=False, ignore_reinit_error=True, logging_level=logging.ERROR); # logging.FATAL\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d94457f-7893-4f58-8714-dc8feafc3c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HIDDEN\n",
    "\n",
    "from ray.rllib.algorithms.ppo import PPOConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b40b252-c6b3-46bf-af14-61620bc95a2c",
   "metadata": {},
   "source": [
    "#### Learning a policy\n",
    "\n",
    "- Let's train an agent to complete the Frozen Pond using RLlib.\n",
    "- This is similar to our Frozen Lake agent from Module 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bca1aaf-cd30-44a6-b192-87ea6ad3be39",
   "metadata": {},
   "source": [
    "#### Quick aside: default config\n",
    "\n",
    "- For brevity, we'll introduce the following default algorithm config settings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9c34cd0-1f80-441c-9550-bfe238f54ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "lake_default_config = (\n",
    "    PPOConfig()\\\n",
    "    .framework(\"torch\")\\\n",
    "    .rollouts(create_env_on_local_worker=True, horizon=100)\\\n",
    "    .debugging(seed=0, log_level=\"ERROR\")\\\n",
    "    .training(model={\"fcnet_hiddens\" : [32, 32]})\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a15abde2-a45f-45bf-a33f-2e5c02f001d9",
   "metadata": {},
   "source": [
    "So, if you see `lake_default_config`, this is what it contains!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b96688-5597-4709-bd71-552dfec70920",
   "metadata": {},
   "source": [
    "#### Learning a policy\n",
    "\n",
    "- Back to it: let's train an agent to complete the Frozen Pond using RLlib.\n",
    "- This is similar to our Frozen Lake agent from Module 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63d101fe-ebcf-43bb-859f-d07d3afc2093",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gym.wrappers import TimeLimit\n",
    "from envs import FrozenPond # defined in previous slides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c31ea0c-5e7b-46ff-b312-c1b846d7b2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "ppo = lake_default_config.build(env=FrozenPond)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "548763bc-2399-4ac8-9936-2dba7b183467",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_info = ppo.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ee6979-e728-454d-bf34-35d1688c748f",
   "metadata": {},
   "source": [
    "#### Learning a policy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd7f6f10-c910-47e8-995c-aac0c33855a8",
   "metadata": {},
   "source": [
    "We see that the agent only reaches the goal in ~2% of evaluation episodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc2c0986-b123-49b2-b021-9cc0a8ea0383",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.021897810218978103"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ppo.evaluate()[\"evaluation\"][\"episode_reward_mean\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db523173-21d9-42a4-ab33-51d6f23a4d38",
   "metadata": {},
   "source": [
    "We can improve the agent by training for more iterations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d709ff68-c2dd-4cf8-acf2-1ed728b44569",
   "metadata": {},
   "source": [
    "#### Learning a policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b06c345a-3490-4ec8-8ef2-5b311f7db938",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(8):\n",
    "    ppo.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cdc6777d-e77d-4dbc-a9c1-5dbf75c06d5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9612903225806452"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ppo.evaluate()[\"evaluation\"][\"episode_reward_mean\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f416155b-486e-4e4f-958f-103d119cc829",
   "metadata": {},
   "source": [
    "With another 8 training iterations, we increased the success rate to more than 96%. Nice."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e482d6-850a-4608-932a-ffec45bf52d5",
   "metadata": {},
   "source": [
    "#### Beyond the simple environment\n",
    "\n",
    "We just trained an agent to learn this fixed Frozen Pond:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b9ac3f06-a899-407c-82fe-217d48222aea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßëüßäüßäüßä\n",
      "üßäüï≥üßäüï≥\n",
      "üßäüßäüßäüï≥\n",
      "üï≥üßäüßä‚õ≥Ô∏è\n"
     ]
    }
   ],
   "source": [
    "pond = FrozenPond()\n",
    "pond.reset()\n",
    "pond.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c23b95-7b31-40c8-819f-eb8f6a3872f8",
   "metadata": {},
   "source": [
    "But this is quite an easy problem:\n",
    "\n",
    "- Small state space\n",
    "- Small action space\n",
    "- No stochasticity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eaa3bd3-4291-4efd-b961-7fe41b71d463",
   "metadata": {},
   "source": [
    "#### Random lake\n",
    "\n",
    "- Let's make the problem harder by looking at a _random_ frozen lake\n",
    "- That is, the hole locations change every episode.\n",
    "- We'll do this by reimplementing the `reset` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4fad2e84-ce76-4c93-a373-74ea955e2a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomLake(FrozenPond):\n",
    "    def reset(self):\n",
    "        self.player = (0, 0) # the player starts at the top-left\n",
    "        self.goal = (3, 3)   # goal is at the bottom-right\n",
    "        \n",
    "        self.holes = np.random.rand(4, 4) < 0.2\n",
    "        self.holes[self.player] = 0  # no hole at start location\n",
    "        self.holes[self.goal] = 0    # no hole at goal location\n",
    "        \n",
    "        return 0 # the observation corresponding to (0,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04592876-bd6b-49be-9d0a-41b1ceb68ce0",
   "metadata": {},
   "source": [
    "Now, each square (except the start and end locations) is a hole with probability 20%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c86702-111e-48c0-9519-1a539e734187",
   "metadata": {},
   "source": [
    "#### Random lake"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef26c29d-0573-40f9-8cd9-a3aaa6daf073",
   "metadata": {},
   "source": [
    "Here's one random lake:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "85da7b48-9d04-454a-8f72-d56a127396ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HIDDEN\n",
    "np.random.seed(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f73a2c5a-6a5b-4718-bc8d-e975315b19da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßëüï≥üßäüßä\n",
      "üßäüßäüßäüßä\n",
      "üßäüßäüßäüßä\n",
      "üï≥üßäüï≥‚õ≥Ô∏è\n"
     ]
    }
   ],
   "source": [
    "lake = RandomLake()\n",
    "lake.reset()\n",
    "lake.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60bb00bd-b507-4a7a-a92c-b4ee2936c59e",
   "metadata": {},
   "source": [
    "Here's another:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8f209f4a-d520-4386-875b-f0f412d6d8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HIDDEN\n",
    "np.random.seed(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "25acfc89-2815-4830-8a1b-ccf71d17397d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßëüßäüßäüßä\n",
      "üßäüßäüï≥üßä\n",
      "üï≥üßäüï≥üßä\n",
      "üßäüßäüßä‚õ≥Ô∏è\n"
     ]
    }
   ],
   "source": [
    "lake.reset()\n",
    "lake.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c991ca-3b07-4b47-ad56-82b44810d241",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Impossible games"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd66e4fd-252d-4528-922f-0f523d03a462",
   "metadata": {},
   "source": [
    "And here's one more:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1923d74a-bd44-47c3-9097-3b243135382c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HIDDEN\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "15ebefd7-e7f3-4a59-b7df-6d15c976a6dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßëüßäüï≥üßä\n",
      "üï≥üï≥üï≥üßä\n",
      "üßäüßäüßäüßä\n",
      "üßäüßäüï≥‚õ≥Ô∏è\n"
     ]
    }
   ],
   "source": [
    "lake.reset()\n",
    "lake.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abcf6d47-0d42-40ed-9c7d-832c08413bcd",
   "metadata": {},
   "source": [
    "- This time, there is no way to the goal! \n",
    "- This is a situation where the maximum episode length would really come in handle.\n",
    "  - We saw this earlier with the gym `TimeLimit` wrapper.\n",
    "- With these impossible lakes, we should no longer be aiming for a 100% win rate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4749279-b545-4967-ace4-37eb29196908",
   "metadata": {},
   "source": [
    "#### Learning the random lake\n",
    "\n",
    "- We've had success with RLlib so far, achieving a decent win rate on the original Frozen Lake.\n",
    "- Let's try the random lake:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "76357ccd-be6b-4bae-ac47-bb4c800593d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ppo = lake_default_config.build(env=RandomLake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ff308b05-0541-4e33-a1cc-0090c3e4bc9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_info = ppo.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1170e96f-990d-42de-8651-faab7236e6c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15337423312883436"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ppo.evaluate()[\"evaluation\"][\"episode_reward_mean\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b542ce1-34e8-4b6d-a0c3-0afdb87e0f94",
   "metadata": {},
   "source": [
    "This looks good for only one training iteration."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f2aa884-f762-4d1c-a25b-172eecacd542",
   "metadata": {},
   "source": [
    "#### Learning the random lake\n",
    "\n",
    "Let's try more iterations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e8d867db-3015-4e68-815a-c9cb002f4dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(4):\n",
    "    train_info = ppo.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2b5d3b1d-6dc2-4c5e-bef3-2b8953aec8ce",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.35331230283911674"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ppo.evaluate()[\"evaluation\"][\"episode_reward_mean\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d0e946-a17d-4104-975c-35f1cc0566ab",
   "metadata": {},
   "source": [
    "Yikes. Another 4 iterations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "648157bf-a4dc-4454-bb0a-ae2f5a85d258",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(4):\n",
    "    train_info = ppo.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "48bdad7e-c523-4126-9a7d-1ddb6938a85e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.328537170263789"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ppo.evaluate()[\"evaluation\"][\"episode_reward_mean\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e44ad0-a041-4d5b-9af2-9b35487c98a7",
   "metadata": {},
   "source": [
    "It looks like we're hitting a plateau here and falling into the lake most of the time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8a491d4-9bd2-4ea5-b11f-8b9d33390910",
   "metadata": {},
   "source": [
    "#### Comparing environments\n",
    "\n",
    "Let's compare the learning curves of the two environments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cdee8959-a7e8-4f79-9911-8dde89e5b01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_algo = lake_default_config.build(env=FrozenPond)\n",
    "rando_algo = lake_default_config.build(env=RandomLake)\n",
    "fixed_rewards = []\n",
    "rando_rewards = []\n",
    "\n",
    "for i in range(8):\n",
    "    fixed_rewards.append(fixed_algo.train()['episode_reward_mean'])\n",
    "    rando_rewards.append(rando_algo.train()['episode_reward_mean'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a49aa2-f60f-4983-97c1-0116bc92e9f1",
   "metadata": {},
   "source": [
    "#### Comparing environments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ab537d27-06e4-477d-8127-8405dd0fc550",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HIDDEN\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['font.size'] = 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "07ed6a6a-7f7d-48cc-883e-bc3d20cc83ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(fixed_rewards, label=\"fixed\")\n",
    "plt.plot(rando_rewards, label=\"random\")\n",
    "plt.xlabel(\"training iteration\")\n",
    "plt.ylabel(\"success rate\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0610637c-8765-4b3e-b620-c9b11247f7b6",
   "metadata": {},
   "source": [
    "This confirms our idea that the random lake environment is much harder to solve."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cea2749-2dc6-4e5f-a01b-b751350ed6ba",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Random lake challenges\n",
    "\n",
    "- So, why is the random lake so hard?\n",
    "- Recall what we're learning: a policy, which maps observations to actions.\n",
    "- Here, our observations are the location in the lake, and the action is the movement direction.\n",
    "- So, say the observation is 3, meaning you're standing at the top-right. What action should you take?\n",
    "- Answer: it depends on where the holes are!\n",
    "- We're asking our agent to avoid holes _without being able to see_.\n",
    "- In the next section we'll address this issue."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8191ed69-c91c-4b3c-a9d7-6779f728e855",
   "metadata": {},
   "source": [
    "#### Let's apply what we learned!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "428bcdc3-79ee-4845-9db9-113f69d1f30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HIDDEN\n",
    "ppo.stop()\n",
    "ray.shutdown()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f29e54-1e2c-4137-8130-f60c16328740",
   "metadata": {},
   "source": [
    "## Number of holes\n",
    "<!-- multiple choice -->\n",
    "\n",
    "Our Random Lake environment is set up so that each square (except the start and goal) has a 20% probability of being a hole. \n",
    "\n",
    "#### Average episode reward\n",
    "\n",
    "What do you think would happen to the average episode **reward** if we increased this number to 50%?\n",
    "\n",
    "- [ ] The average episode reward would increase.\n",
    "- [x] The average episode reward would decrease."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e32eab-df7d-4235-a4f1-d9b07391eeb4",
   "metadata": {},
   "source": [
    "#### Average episode length\n",
    "\n",
    "What do you think would happen to the average episode **length** if we increased this number to 50%?\n",
    "\n",
    "- [ ] The average episode length would increase.\n",
    "- [x] The average episode length would decrease."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e18f28-e0f5-4abb-a1f7-ab25bb7943a0",
   "metadata": {},
   "source": [
    "## Where is the randomness?\n",
    "<!-- multiple choice -->\n",
    "\n",
    "In our implementation of `RandomLake`, we put the random hole creation in the `reset` method:\n",
    "\n",
    "```python\n",
    "self.holes = np.random.rand(4, 4) < 0.2\n",
    "```\n",
    "\n",
    "What would have happened if we put this in the constructor instead?\n",
    "\n",
    "- [ ] It would behave the same as the current implementation.\n",
    "- [ ] It would revert back to the non-random Frozen Pond from the previous module.\n",
    "- [x] The holes would be randomized each time an environment is created, but all episodes would have the same random holes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c8cacad-97f4-41ec-8337-652600549571",
   "metadata": {},
   "source": [
    "## Step counter\n",
    "<!-- multiple choice -->\n",
    "\n",
    "Let's say we wanted to implement a step counter in our environment _manually_, not using gym's `TimeLimit` wrapper or RLlib's `\"horizon\"` parameter for training. As a reminder, we would like the episodes to end after 50 steps even if you haven't reached the goal or fallen into a hole. \n",
    "\n",
    "#### Initializing the counter variable\n",
    "\n",
    "First, we would need to created a new counter variable, say `self.stepcount`, and initialize it to zero with `self.stepcount = 0`. In which method would we include this code?\n",
    "\n",
    "- [ ] constructor\n",
    "- [x] `reset`\n",
    "- [ ] `step`\n",
    "- [ ] `done` (called by `step`)\n",
    "- [ ] `render`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75761b99-6b65-473a-be27-a8f44800702f",
   "metadata": {},
   "source": [
    "#### Incrementing the counter\n",
    "\n",
    "Next, we would need to increment this counter after each step, say with `self.stepcount += 1`. In which method would we include this code?\n",
    "\n",
    "- [ ] constructor\n",
    "- [ ] `reset`\n",
    "- [x] `step`\n",
    "- [ ] `done` (called by `step`)\n",
    "- [ ] `render`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a8bb09-d9e7-4d15-bd10-e540070e12b3",
   "metadata": {},
   "source": [
    "#### Ending the episode\n",
    "\n",
    "Finally, we would need to make sure the episode ends if the `self.stepcount >= 50`. Which method should we modify?\n",
    "\n",
    "- [ ] constructor\n",
    "- [ ] `reset`\n",
    "- [ ] `step`\n",
    "- [x] `done` (called by `step`)\n",
    "- [ ] `render`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "410b77fb-51cf-4706-a835-afd1b9f68ace",
   "metadata": {},
   "source": [
    "## Step counter: implementation\n",
    "<!-- coding exercise -->\n",
    "\n",
    "Below is the code of the Random Lake (minus rendering). Following the logic from the previous exercise, implement a step counter so that the max episode length is 50 steps. Then, test it out with the provided code, which repeatedly moves left (thus not moving at all)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c7fdf181-408e-4b32-9f8f-2e8630fddc97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 False\n",
      "2 False\n",
      "3 False\n",
      "4 False\n",
      "5 False\n",
      "6 False\n",
      "7 False\n",
      "8 False\n",
      "9 False\n",
      "10 False\n",
      "11 False\n",
      "12 False\n",
      "13 False\n",
      "14 False\n",
      "15 False\n",
      "16 False\n",
      "17 False\n",
      "18 False\n",
      "19 False\n",
      "20 False\n",
      "21 False\n",
      "22 False\n",
      "23 False\n",
      "24 False\n",
      "25 False\n",
      "26 False\n",
      "27 False\n",
      "28 False\n",
      "29 False\n",
      "30 False\n",
      "31 False\n",
      "32 False\n",
      "33 False\n",
      "34 False\n",
      "35 False\n",
      "36 False\n",
      "37 False\n",
      "38 False\n",
      "39 False\n",
      "40 False\n",
      "41 False\n",
      "42 False\n",
      "43 False\n",
      "44 False\n",
      "45 False\n",
      "46 False\n",
      "47 False\n",
      "48 False\n",
      "49 False\n",
      "50 False\n",
      "51 False\n",
      "52 False\n",
      "53 False\n",
      "54 False\n",
      "55 False\n"
     ]
    }
   ],
   "source": [
    "# EXERCISE\n",
    "\n",
    "import gym\n",
    "\n",
    "class RandomLake(gym.Env):\n",
    "    def __init__(self, env_config=None):\n",
    "        self.observation_space = gym.spaces.Discrete(16)\n",
    "        self.action_space = gym.spaces.Discrete(4)      \n",
    "        \n",
    "    def reset(self):\n",
    "        self.player = (0, 0) # the player starts at the top-left\n",
    "        self.goal = (3, 3)   # goal is at the bottom-right\n",
    "        \n",
    "        self.holes = np.random.rand(4, 4) < 0.2\n",
    "        self.holes[self.player] = 0  # no hole at start location\n",
    "        self.holes[self.goal] = 0    # no hole at goal location\n",
    "        \n",
    "        self.stepcount = 0\n",
    "        \n",
    "        return self.observation()\n",
    "    \n",
    "    def observation(self):\n",
    "        return 4*self.player[0] + self.player[1]\n",
    "    \n",
    "    def reward(self):\n",
    "        return int(self.player == self.goal)\n",
    "    \n",
    "    def done(self):\n",
    "        is_done = self.player == self.goal or self.holes[self.player] == 1 \n",
    "        return is_done\n",
    "    \n",
    "    def is_valid_loc(self, location):\n",
    "        return 0 <= location[0] <= 3 and 0 <= location[1] <= 3\n",
    "\n",
    "    def step(self, action):\n",
    "        # Compute the new player location\n",
    "        if action == 0:   # left\n",
    "            new_loc = (self.player[0], self.player[1]-1)\n",
    "        elif action == 1: # down\n",
    "            new_loc = (self.player[0]+1, self.player[1])\n",
    "        elif action == 2: # right\n",
    "            new_loc = (self.player[0], self.player[1]+1)\n",
    "        elif action == 3: # up\n",
    "            new_loc = (self.player[0]-1, self.player[1])\n",
    "        else:\n",
    "            raise ValueError(\"Action must be in {0,1,2,3}\")\n",
    "        \n",
    "        # Update the player location only if you stayed in bounds\n",
    "        if self.is_valid_loc(new_loc):\n",
    "            self.player = new_loc\n",
    "            \n",
    "        self.stepcount += 1\n",
    "        \n",
    "        return self.observation(), self.reward(), self.done(), {}\n",
    "    \n",
    "lake = RandomLake()\n",
    "obs = lake.reset()\n",
    "\n",
    "done = False\n",
    "for i in range(55):\n",
    "    obs, rewards, done, _ = lake.step(0)\n",
    "    print(i+1, done)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2fbbf52b-78d2-4a3c-9d50-bb7a6d4b3cb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 False\n",
      "2 False\n",
      "3 False\n",
      "4 False\n",
      "5 False\n",
      "6 False\n",
      "7 False\n",
      "8 False\n",
      "9 False\n",
      "10 False\n",
      "11 False\n",
      "12 False\n",
      "13 False\n",
      "14 False\n",
      "15 False\n",
      "16 False\n",
      "17 False\n",
      "18 False\n",
      "19 False\n",
      "20 False\n",
      "21 False\n",
      "22 False\n",
      "23 False\n",
      "24 False\n",
      "25 False\n",
      "26 False\n",
      "27 False\n",
      "28 False\n",
      "29 False\n",
      "30 False\n",
      "31 False\n",
      "32 False\n",
      "33 False\n",
      "34 False\n",
      "35 False\n",
      "36 False\n",
      "37 False\n",
      "38 False\n",
      "39 False\n",
      "40 False\n",
      "41 False\n",
      "42 False\n",
      "43 False\n",
      "44 False\n",
      "45 False\n",
      "46 False\n",
      "47 False\n",
      "48 False\n",
      "49 False\n",
      "50 True\n",
      "51 True\n",
      "52 True\n",
      "53 True\n",
      "54 True\n",
      "55 True\n"
     ]
    }
   ],
   "source": [
    "# SOLUTION\n",
    "\n",
    "import gym\n",
    "\n",
    "class RandomLake(gym.Env):\n",
    "    def __init__(self, env_config=None):\n",
    "        self.observation_space = gym.spaces.Discrete(16)\n",
    "        self.action_space = gym.spaces.Discrete(4)      \n",
    "        \n",
    "    def reset(self):\n",
    "        self.player = (0, 0) # the player starts at the top-left\n",
    "        self.goal = (3, 3)   # goal is at the bottom-right\n",
    "        \n",
    "        self.holes = np.random.rand(4, 4) < 0.2\n",
    "        self.holes[self.player] = 0  # no hole at start location\n",
    "        self.holes[self.goal] = 0    # no hole at goal location\n",
    "        \n",
    "        self.stepcount = 0\n",
    "        \n",
    "        return self.observation()\n",
    "    \n",
    "    def observation(self):\n",
    "        return 4*self.player[0] + self.player[1]\n",
    "    \n",
    "    def reward(self):\n",
    "        return int(self.player == self.goal)\n",
    "    \n",
    "    def done(self):\n",
    "        is_done = self.player == self.goal or self.holes[self.player] == 1 or self.stepcount >= 50\n",
    "        return is_done\n",
    "    \n",
    "    def is_valid_loc(self, location):\n",
    "        return 0 <= location[0] <= 3 and 0 <= location[1] <= 3\n",
    "\n",
    "    def step(self, action):\n",
    "        # Compute the new player location\n",
    "        if action == 0:   # left\n",
    "            new_loc = (self.player[0], self.player[1]-1)\n",
    "        elif action == 1: # down\n",
    "            new_loc = (self.player[0]+1, self.player[1])\n",
    "        elif action == 2: # right\n",
    "            new_loc = (self.player[0], self.player[1]+1)\n",
    "        elif action == 3: # up\n",
    "            new_loc = (self.player[0]-1, self.player[1])\n",
    "        else:\n",
    "            raise ValueError(\"Action must be in {0,1,2,3}\")\n",
    "        \n",
    "        # Update the player location only if you stayed in bounds\n",
    "        if self.is_valid_loc(new_loc):\n",
    "            self.player = new_loc\n",
    "            \n",
    "        self.stepcount += 1\n",
    "        \n",
    "        return self.observation(), self.reward(), self.done(), {}\n",
    "    \n",
    "lake = RandomLake()\n",
    "obs = lake.reset()\n",
    "\n",
    "done = False\n",
    "for i in range(55):\n",
    "    obs, rewards, done, _ = lake.step(0)\n",
    "    print(i+1, done)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7732e833-1c55-496e-88d6-74f5baf00837",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ray2beta]",
   "language": "python",
   "name": "conda-env-ray2beta-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
