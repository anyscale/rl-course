{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e23df55-837b-4ec9-86ad-3b60c6a7f00d",
   "metadata": {},
   "source": [
    "## Random Lake Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ffbd783-053c-47c6-afb4-72724590ee1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HIDDEN\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['font.size'] = 14"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b40b252-c6b3-46bf-af14-61620bc95a2c",
   "metadata": {},
   "source": [
    "#### Learning a policy\n",
    "\n",
    "- Let's train an agent to complete the Frozen Pond using RLlib.\n",
    "- This is similar to our Frozen Lake agent from Module 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bca1aaf-cd30-44a6-b192-87ea6ad3be39",
   "metadata": {},
   "source": [
    "#### Quick aside: default config\n",
    "\n",
    "- For brevity, we'll introduce the following default trainer config settings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9c34cd0-1f80-441c-9550-bfe238f54ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "lake_default_config = {\n",
    "    \"framework\"             : \"torch\",\n",
    "    \"create_env_on_driver\"  : True,\n",
    "    \"seed\"                  : 0,\n",
    "    \"horizon\"               : 100,\n",
    "    \"model\"                 : {\"fcnet_hiddens\" : [32, 32]}}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a15abde2-a45f-45bf-a33f-2e5c02f001d9",
   "metadata": {},
   "source": [
    "So, if you see `lake_default_config`, this is what it contains!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b96688-5597-4709-bd71-552dfec70920",
   "metadata": {},
   "source": [
    "#### Learning a policy\n",
    "\n",
    "- Back to it: let's train an agent to complete the Frozen Pond using RLlib.\n",
    "- This is similar to our Frozen Lake agent from Module 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "63d101fe-ebcf-43bb-859f-d07d3afc2093",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray.rllib.agents.ppo import PPOTrainer\n",
    "from gym.wrappers import TimeLimit\n",
    "from envs import FrozenPond # defined in previous slides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6c31ea0c-5e7b-46ff-b312-c1b846d7b2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = PPOTrainer(lake_default_config, env=FrozenPond)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "548763bc-2399-4ac8-9936-2dba7b183467",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_info = trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ee6979-e728-454d-bf34-35d1688c748f",
   "metadata": {},
   "source": [
    "#### Learning a policy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd7f6f10-c910-47e8-995c-aac0c33855a8",
   "metadata": {},
   "source": [
    "We see that the agent only reaches the goal in ~2% of evaluation episodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fc2c0986-b123-49b2-b021-9cc0a8ea0383",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.021897810218978103"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()[\"evaluation\"][\"episode_reward_mean\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db523173-21d9-42a4-ab33-51d6f23a4d38",
   "metadata": {},
   "source": [
    "We can improve the agent by training for more iterations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d709ff68-c2dd-4cf8-acf2-1ed728b44569",
   "metadata": {},
   "source": [
    "#### Learning a policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b06c345a-3490-4ec8-8ef2-5b311f7db938",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(8):\n",
    "    trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cdc6777d-e77d-4dbc-a9c1-5dbf75c06d5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9612903225806452"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()[\"evaluation\"][\"episode_reward_mean\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f416155b-486e-4e4f-958f-103d119cc829",
   "metadata": {},
   "source": [
    "With another 8 training iterations, we increased the success rate to more than 96%. Nice."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e482d6-850a-4608-932a-ffec45bf52d5",
   "metadata": {},
   "source": [
    "#### Beyond the simple environment\n",
    "\n",
    "We just trained an agent to learn this fixed Frozen Pond:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b9ac3f06-a899-407c-82fe-217d48222aea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P...\n",
      ".O.O\n",
      "...O\n",
      "O..G\n"
     ]
    }
   ],
   "source": [
    "pond = FrozenPond()\n",
    "pond.reset()\n",
    "pond.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c23b95-7b31-40c8-819f-eb8f6a3872f8",
   "metadata": {},
   "source": [
    "But this is quite an easy problem:\n",
    "\n",
    "- Small state space\n",
    "- Small action space\n",
    "- No stochasticity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eaa3bd3-4291-4efd-b961-7fe41b71d463",
   "metadata": {},
   "source": [
    "#### Random lake\n",
    "\n",
    "- Let's make the problem harder by looking at a _random_ frozen lake\n",
    "- That is, the hole locations change every episode.\n",
    "- We'll do this by reimplementing the `reset` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4fad2e84-ce76-4c93-a373-74ea955e2a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomLake(FrozenPond):\n",
    "    def reset(self):\n",
    "        self.player = (0, 0) # the player starts at the top-left\n",
    "        self.goal = (3, 3)   # goal is at the bottom-right\n",
    "        \n",
    "        self.holes = np.random.rand(4, 4) < 0.2\n",
    "        self.holes[self.player] = 0  # no hole at start location\n",
    "        self.holes[self.goal] = 0    # no hole at goal location\n",
    "        \n",
    "        return 0 # the observation corresponding to (0,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04592876-bd6b-49be-9d0a-41b1ceb68ce0",
   "metadata": {},
   "source": [
    "Now, each square (except the start and end locations) is a hole with probability 20%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c86702-111e-48c0-9519-1a539e734187",
   "metadata": {},
   "source": [
    "#### Random lake"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef26c29d-0573-40f9-8cd9-a3aaa6daf073",
   "metadata": {},
   "source": [
    "Here's one random lake:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "85da7b48-9d04-454a-8f72-d56a127396ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HIDDEN\n",
    "np.random.seed(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f73a2c5a-6a5b-4718-bc8d-e975315b19da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PO..\n",
      "....\n",
      "....\n",
      "O.OG\n"
     ]
    }
   ],
   "source": [
    "lake = RandomLake()\n",
    "lake.reset()\n",
    "lake.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60bb00bd-b507-4a7a-a92c-b4ee2936c59e",
   "metadata": {},
   "source": [
    "Here's another:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8f209f4a-d520-4386-875b-f0f412d6d8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HIDDEN\n",
    "np.random.seed(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "25acfc89-2815-4830-8a1b-ccf71d17397d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P...\n",
      "..O.\n",
      "O.O.\n",
      "...G\n"
     ]
    }
   ],
   "source": [
    "lake.reset()\n",
    "lake.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c991ca-3b07-4b47-ad56-82b44810d241",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Impossible games"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd66e4fd-252d-4528-922f-0f523d03a462",
   "metadata": {},
   "source": [
    "And here's one more:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1923d74a-bd44-47c3-9097-3b243135382c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HIDDEN\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "15ebefd7-e7f3-4a59-b7df-6d15c976a6dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P.O.\n",
      "OOO.\n",
      "....\n",
      "..OG\n"
     ]
    }
   ],
   "source": [
    "lake.reset()\n",
    "lake.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abcf6d47-0d42-40ed-9c7d-832c08413bcd",
   "metadata": {},
   "source": [
    "- This time, there is no way to the goal! \n",
    "- This is a situation where the maximum episode length would really come in handle.\n",
    "  - We saw this earlier with the gym `TimeLimit` wrapper.\n",
    "- With these impossible lakes, we should no longer be aiming for a 100% win rate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4749279-b545-4967-ace4-37eb29196908",
   "metadata": {},
   "source": [
    "#### Learning the random lake\n",
    "\n",
    "- We've had success with RLlib so far, achieving a decent win rate on the original Frozen Lake.\n",
    "- Let's try the random lake:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "76357ccd-be6b-4bae-ac47-bb4c800593d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = PPOTrainer(lake_default_config, env=RandomLake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ff308b05-0541-4e33-a1cc-0090c3e4bc9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_info = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1170e96f-990d-42de-8651-faab7236e6c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15337423312883436"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()[\"evaluation\"][\"episode_reward_mean\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b542ce1-34e8-4b6d-a0c3-0afdb87e0f94",
   "metadata": {},
   "source": [
    "This looks good for only one training iteration."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f2aa884-f762-4d1c-a25b-172eecacd542",
   "metadata": {},
   "source": [
    "#### Learning the random lake\n",
    "\n",
    "Let's try more iterations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e8d867db-3015-4e68-815a-c9cb002f4dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(4):\n",
    "    train_info = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2b5d3b1d-6dc2-4c5e-bef3-2b8953aec8ce",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.35331230283911674"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()[\"evaluation\"][\"episode_reward_mean\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d0e946-a17d-4104-975c-35f1cc0566ab",
   "metadata": {},
   "source": [
    "Yikes. Another 4 iterations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "648157bf-a4dc-4454-bb0a-ae2f5a85d258",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(4):\n",
    "    train_info = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "48bdad7e-c523-4126-9a7d-1ddb6938a85e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.328537170263789"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()[\"evaluation\"][\"episode_reward_mean\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8a491d4-9bd2-4ea5-b11f-8b9d33390910",
   "metadata": {},
   "source": [
    "#### Comparing environments\n",
    "\n",
    "- It looks like we're hitting a plateau here and falling into the lake most of the time.\n",
    "- Let's compare the learning curves of the two environments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cdee8959-a7e8-4f79-9911-8dde89e5b01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_trainer = PPOTrainer(lake_default_config, env=FrozenPond)\n",
    "rando_trainer = PPOTrainer(lake_default_config, env=RandomLake)\n",
    "fixed_rewards = []\n",
    "rando_rewards = []\n",
    "\n",
    "for i in range(8):\n",
    "    fixed_rewards.append(fixed_trainer.train()['episode_reward_mean'])\n",
    "    rando_rewards.append(rando_trainer.train()['episode_reward_mean'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a49aa2-f60f-4983-97c1-0116bc92e9f1",
   "metadata": {},
   "source": [
    "#### Comparing environments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "07ed6a6a-7f7d-48cc-883e-bc3d20cc83ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(fixed_rewards, label=\"fixed\")\n",
    "plt.plot(rando_rewards, label=\"random\")\n",
    "plt.xlabel(\"training iteration\")\n",
    "plt.ylabel(\"success rate\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0610637c-8765-4b3e-b620-c9b11247f7b6",
   "metadata": {},
   "source": [
    "This confirms our idea that the random lake environment is much harder to solve."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cea2749-2dc6-4e5f-a01b-b751350ed6ba",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Random lake challenges\n",
    "\n",
    "- So, why is the random lake so hard?\n",
    "- Recall what we're learning: a policy, which maps observations to actions.\n",
    "- Here, our observations are the location in the lake, and the action is the movement direction.\n",
    "- So, say the observation is 3, meaning you're standing at the top-right. What action should you take?\n",
    "- Answer: it depends on where the holes are!\n",
    "- We're asking our agent to avoid holes _without being able to see_.\n",
    "- In the next section we'll address this issue."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8191ed69-c91c-4b3c-a9d7-6779f728e855",
   "metadata": {},
   "source": [
    "#### Let's apply what we learned!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f29e54-1e2c-4137-8130-f60c16328740",
   "metadata": {},
   "source": [
    "## Number of holes\n",
    "<!-- multiple choice -->\n",
    "\n",
    "Our Random Lake environment is set up so that each square (except the start and goal) has a 20% probability of being a hole. \n",
    "\n",
    "#### Average episode reward\n",
    "\n",
    "What do you think would happen to the average episode **reward** if we increased this number to 50%?\n",
    "\n",
    "- [ ] The average episode reward would increase.\n",
    "- [x] The average episode reward would decrease."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e32eab-df7d-4235-a4f1-d9b07391eeb4",
   "metadata": {},
   "source": [
    "#### Average episode length\n",
    "\n",
    "What do you think would happen to the average episode **length** if we increased this number to 50%?\n",
    "\n",
    "- [ ] The average episode length would increase.\n",
    "- [x] The average episode length would decrease."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e18f28-e0f5-4abb-a1f7-ab25bb7943a0",
   "metadata": {},
   "source": [
    "## Where is the randomness?\n",
    "<!-- multiple choice -->\n",
    "\n",
    "In our implementation of `RandomLake`, we put the random hole creation in the `reset` method:\n",
    "\n",
    "```python\n",
    "self.holes = np.random.rand(4, 4) < 0.2\n",
    "```\n",
    "\n",
    "What would have happened if we put this in the constructor instead?\n",
    "\n",
    "- [ ] It would behave the same as the current implementation.\n",
    "- [ ] It would revert back to the non-random Frozen Pond from the previous module.\n",
    "- [x] The holes would be randomized each time an environment is created, but all episodes would have the same random holes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c8cacad-97f4-41ec-8337-652600549571",
   "metadata": {},
   "source": [
    "## Step counter\n",
    "<!-- multiple choice -->\n",
    "\n",
    "Let's say we wanted to implement a step counter in our environment _manually_, not using gym's `TimeLimit` wrapper or RLlib's `\"horizon\"` parameter for training. As a reminder, we would like the episodes to end after 50 steps even if you haven't reached the goal or fallen into a hole. \n",
    "\n",
    "#### Initializing the counter variable\n",
    "\n",
    "First, we would need to created a new counter variable, say `self.stepcount`, and initialize it to zero with `self.stepcount = 0`. In which method would we include this code?\n",
    "\n",
    "- [ ] constructor\n",
    "- [x] `reset`\n",
    "- [ ] `step`\n",
    "- [ ] `done` (called by `step`)\n",
    "- [ ] `render`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75761b99-6b65-473a-be27-a8f44800702f",
   "metadata": {},
   "source": [
    "#### Incrementing the counter\n",
    "\n",
    "Next, we would need to increment this counter after each step, say with `self.stepcount += 1`. In which method would we include this code?\n",
    "\n",
    "- [ ] constructor\n",
    "- [ ] `reset`\n",
    "- [x] `step`\n",
    "- [ ] `done` (called by `step`)\n",
    "- [ ] `render`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a8bb09-d9e7-4d15-bd10-e540070e12b3",
   "metadata": {},
   "source": [
    "#### Ending the episode\n",
    "\n",
    "Finally, we would need to make sure the episode ends if the `self.stepcount >= 50`. Which method should we modify?\n",
    "\n",
    "- [ ] constructor\n",
    "- [ ] `reset`\n",
    "- [ ] `step`\n",
    "- [x] `done` (called by `step`)\n",
    "- [ ] `render`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "410b77fb-51cf-4706-a835-afd1b9f68ace",
   "metadata": {},
   "source": [
    "## Step counter: implementation\n",
    "<!-- coding exercise -->\n",
    "\n",
    "Below is the code of the Random Lake (minus rendering). Following the logic from the previous exercise, implement a step counter so that the max episode length is 50 steps. Then, test it out with the provided code, which repeatedly moves left (thus not moving at all)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7fdf181-408e-4b32-9f8f-2e8630fddc97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXERCISE\n",
    "\n",
    "import gym\n",
    "\n",
    "class RandomLake(gym.Env):\n",
    "    def __init__(self, env_config=None):\n",
    "        self.observation_space = gym.spaces.Discrete(16)\n",
    "        self.action_space = gym.spaces.Discrete(4)      \n",
    "        \n",
    "    def reset(self):\n",
    "        self.player = (0, 0) # the player starts at the top-left\n",
    "        self.goal = (3, 3)   # goal is at the bottom-right\n",
    "        \n",
    "        self.holes = np.random.rand(4, 4) < 0.2\n",
    "        self.holes[self.player] = 0  # no hole at start location\n",
    "        self.holes[self.goal] = 0    # no hole at goal location\n",
    "        \n",
    "        return self.observation()\n",
    "    \n",
    "    def observation(self):\n",
    "        return 4*self.player[0] + self.player[1]\n",
    "    \n",
    "    def reward(self):\n",
    "        return int(self.player == self.goal)\n",
    "    \n",
    "    def done(self):\n",
    "        is_done = self.player == self.goal or self.holes[self.player] == 1 \n",
    "        return is_done\n",
    "    \n",
    "    def is_valid_loc(self, location):\n",
    "        return 0 <= location[0] <= 3 and 0 <= location[1] <= 3\n",
    "\n",
    "    def step(self, action):\n",
    "        # Compute the new player location\n",
    "        if action == 0:   # left\n",
    "            new_loc = (self.player[0], self.player[1]-1)\n",
    "        elif action == 1: # down\n",
    "            new_loc = (self.player[0]+1, self.player[1])\n",
    "        elif action == 2: # right\n",
    "            new_loc = (self.player[0], self.player[1]+1)\n",
    "        elif action == 3: # up\n",
    "            new_loc = (self.player[0]-1, self.player[1])\n",
    "        else:\n",
    "            raise ValueError(\"Action must be in {0,1,2,3}\")\n",
    "        \n",
    "        # Update the player location only if you stayed in bounds\n",
    "        if self.is_valid_loc(new_loc):\n",
    "            self.player = new_loc\n",
    "            \n",
    "        self.stepcount += 1\n",
    "        \n",
    "        return self.observation(), self.reward(), self.done(), {}\n",
    "    \n",
    "lake = RandomLake()\n",
    "obs = lake.reset()\n",
    "\n",
    "done = False\n",
    "for i in range(55):\n",
    "    obs, rewards, done, _ = lake.step(0)\n",
    "    print(i+1, done)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fbbf52b-78d2-4a3c-9d50-bb7a6d4b3cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION\n",
    "\n",
    "import gym\n",
    "\n",
    "class RandomLake(gym.Env):\n",
    "    def __init__(self, env_config=None):\n",
    "        self.observation_space = gym.spaces.Discrete(16)\n",
    "        self.action_space = gym.spaces.Discrete(4)      \n",
    "        \n",
    "    def reset(self):\n",
    "        self.player = (0, 0) # the player starts at the top-left\n",
    "        self.goal = (3, 3)   # goal is at the bottom-right\n",
    "        \n",
    "        self.holes = np.random.rand(4, 4) < 0.2\n",
    "        self.holes[self.player] = 0  # no hole at start location\n",
    "        self.holes[self.goal] = 0    # no hole at goal location\n",
    "        \n",
    "        self.stepcount = 0\n",
    "        \n",
    "        return self.observation()\n",
    "    \n",
    "    def observation(self):\n",
    "        return 4*self.player[0] + self.player[1]\n",
    "    \n",
    "    def reward(self):\n",
    "        return int(self.player == self.goal)\n",
    "    \n",
    "    def done(self):\n",
    "        is_done = self.player == self.goal or self.holes[self.player] == 1 or self.stepcount >= 50\n",
    "        return is_done\n",
    "    \n",
    "    def is_valid_loc(self, location):\n",
    "        return 0 <= location[0] <= 3 and 0 <= location[1] <= 3\n",
    "\n",
    "    def step(self, action):\n",
    "        # Compute the new player location\n",
    "        if action == 0:   # left\n",
    "            new_loc = (self.player[0], self.player[1]-1)\n",
    "        elif action == 1: # down\n",
    "            new_loc = (self.player[0]+1, self.player[1])\n",
    "        elif action == 2: # right\n",
    "            new_loc = (self.player[0], self.player[1]+1)\n",
    "        elif action == 3: # up\n",
    "            new_loc = (self.player[0]-1, self.player[1])\n",
    "        else:\n",
    "            raise ValueError(\"Action must be in {0,1,2,3}\")\n",
    "        \n",
    "        # Update the player location only if you stayed in bounds\n",
    "        if self.is_valid_loc(new_loc):\n",
    "            self.player = new_loc\n",
    "            \n",
    "        self.stepcount += 1\n",
    "        \n",
    "        return self.observation(), self.reward(), self.done(), {}\n",
    "    \n",
    "lake = RandomLake()\n",
    "obs = lake.reset()\n",
    "\n",
    "done = False\n",
    "for i in range(55):\n",
    "    obs, rewards, done, _ = lake.step(0)\n",
    "    print(i+1, done)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:rl-course]",
   "language": "python",
   "name": "conda-env-rl-course-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
