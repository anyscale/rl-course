{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e23df55-837b-4ec9-86ad-3b60c6a7f00d",
   "metadata": {},
   "source": [
    "## Random Lake Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ffbd783-053c-47c6-afb4-72724590ee1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HIDDEN\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['font.size'] = 14"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b96688-5597-4709-bd71-552dfec70920",
   "metadata": {},
   "source": [
    "#### Learning a policy\n",
    "\n",
    "- Let's train an agent to complete the Frozen Pond using RLlib.\n",
    "- This is similar to our Frozen Lake agent from Module 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63d101fe-ebcf-43bb-859f-d07d3afc2093",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray.rllib.agents.ppo import PPOTrainer\n",
    "from envs import FrozenPond # defined in previous slides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c31ea0c-5e7b-46ff-b312-c1b846d7b2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = PPOTrainer({\"framework\" : \"torch\", \"create_env_on_driver\" : True, \"seed\" : 0}, \n",
    "                     env=FrozenPond)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "548763bc-2399-4ac8-9936-2dba7b183467",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_info = trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ee6979-e728-454d-bf34-35d1688c748f",
   "metadata": {},
   "source": [
    "#### Learning a policy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd7f6f10-c910-47e8-995c-aac0c33855a8",
   "metadata": {},
   "source": [
    "We see that the agent only reaches the goal in 7% of evaluation episodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc2c0986-b123-49b2-b021-9cc0a8ea0383",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05829596412556054"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()[\"evaluation\"][\"episode_reward_mean\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db523173-21d9-42a4-ab33-51d6f23a4d38",
   "metadata": {},
   "source": [
    "We can improve the agent by training for more iterations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d709ff68-c2dd-4cf8-acf2-1ed728b44569",
   "metadata": {},
   "source": [
    "#### Learning the Maze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b06c345a-3490-4ec8-8ef2-5b311f7db938",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(4):\n",
    "    train_info = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cdc6777d-e77d-4dbc-a9c1-5dbf75c06d5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8181818181818182"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()[\"evaluation\"][\"episode_reward_mean\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f416155b-486e-4e4f-958f-103d119cc829",
   "metadata": {},
   "source": [
    "With another 4 training iterations, we increased the success rate to more than 80%. Nice."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e482d6-850a-4608-932a-ffec45bf52d5",
   "metadata": {},
   "source": [
    "#### Beyond the simple lake\n",
    "\n",
    "We can train an agent to learn this fixed Frozen Pond:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b9ac3f06-a899-407c-82fe-217d48222aea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P...\n",
      ".O.O\n",
      "...O\n",
      "O..G\n"
     ]
    }
   ],
   "source": [
    "pond = FrozenPond()\n",
    "pond.reset()\n",
    "pond.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c23b95-7b31-40c8-819f-eb8f6a3872f8",
   "metadata": {},
   "source": [
    "But this is quite an easy problem:\n",
    "\n",
    "- Small state space\n",
    "- Small action space\n",
    "- No stochasticity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eaa3bd3-4291-4efd-b961-7fe41b71d463",
   "metadata": {},
   "source": [
    "#### Random lake\n",
    "\n",
    "- Let's make the problem harder by looking at a _random_ frozen lake\n",
    "- That is, the hole locations change every episode.\n",
    "- We'll do this by reimplementing the `reset` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4fad2e84-ce76-4c93-a373-74ea955e2a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomLake(FrozenPond):\n",
    "    def reset(self):\n",
    "        self.player = (0, 0) # the player starts at the top-left\n",
    "        self.goal = (3, 3)   # goal is at the bottom-right\n",
    "        \n",
    "        self.holes = np.random.rand(4, 4) < 0.2\n",
    "        self.holes[self.player] = 0  # no hole at start location\n",
    "        self.holes[self.goal] = 0    # no hole at goal location\n",
    "        \n",
    "        return 0 # the observation corresponding to (0,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04592876-bd6b-49be-9d0a-41b1ceb68ce0",
   "metadata": {},
   "source": [
    "Now, each square (except the start and end locations) is a hole with probability 20%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c86702-111e-48c0-9519-1a539e734187",
   "metadata": {},
   "source": [
    "#### Random lake"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef26c29d-0573-40f9-8cd9-a3aaa6daf073",
   "metadata": {},
   "source": [
    "Here's one random lake:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "85da7b48-9d04-454a-8f72-d56a127396ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HIDDEN\n",
    "np.random.seed(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f73a2c5a-6a5b-4718-bc8d-e975315b19da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PO..\n",
      "....\n",
      "....\n",
      "O.OG\n"
     ]
    }
   ],
   "source": [
    "lake = RandomLake()\n",
    "lake.reset()\n",
    "lake.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60bb00bd-b507-4a7a-a92c-b4ee2936c59e",
   "metadata": {},
   "source": [
    "Here's another:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8f209f4a-d520-4386-875b-f0f412d6d8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HIDDEN\n",
    "np.random.seed(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "25acfc89-2815-4830-8a1b-ccf71d17397d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P...\n",
      "..O.\n",
      "O.O.\n",
      "...G\n"
     ]
    }
   ],
   "source": [
    "lake.reset()\n",
    "lake.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c991ca-3b07-4b47-ad56-82b44810d241",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Impossible games"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd66e4fd-252d-4528-922f-0f523d03a462",
   "metadata": {},
   "source": [
    "And here's one more:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1923d74a-bd44-47c3-9097-3b243135382c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HIDDEN\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "15ebefd7-e7f3-4a59-b7df-6d15c976a6dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P.O.\n",
      "OOO.\n",
      "....\n",
      "..OG\n"
     ]
    }
   ],
   "source": [
    "lake.reset()\n",
    "lake.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abcf6d47-0d42-40ed-9c7d-832c08413bcd",
   "metadata": {},
   "source": [
    "- This time, there is no way to the goal! \n",
    "- We may want to do something about this, for example a maximum episode length.\n",
    "- For now we won't worry about it - but we shouldn't be aiming to win every time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4749279-b545-4967-ace4-37eb29196908",
   "metadata": {},
   "source": [
    "#### Learning the random lake"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc3e64a-f6ad-4c86-9f69-df8b7addc5ea",
   "metadata": {},
   "source": [
    "- We've had success with RLlib so far, achieving a decent win rate on the original Frozen Lake.\n",
    "- Let's try the random lake:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "76357ccd-be6b-4bae-ac47-bb4c800593d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = PPOTrainer({\"framework\" : \"torch\", \"create_env_on_driver\" : True, \"seed\" : 0}, \n",
    "                     env=RandomLake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ff308b05-0541-4e33-a1cc-0090c3e4bc9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_info = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1170e96f-990d-42de-8651-faab7236e6c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1642512077294686"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()[\"evaluation\"][\"episode_reward_mean\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b542ce1-34e8-4b6d-a0c3-0afdb87e0f94",
   "metadata": {},
   "source": [
    "- At 16%, this is looking good! \n",
    "- With the Frozen Lake we only got 7% after one training iteration."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f2aa884-f762-4d1c-a25b-172eecacd542",
   "metadata": {},
   "source": [
    "#### Learning the random lake"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34121616-3826-426d-ac5d-8e01940a0c88",
   "metadata": {},
   "source": [
    "Let's try more iterations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e8d867db-3015-4e68-815a-c9cb002f4dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(4):\n",
    "    train_info = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2b5d3b1d-6dc2-4c5e-bef3-2b8953aec8ce",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.30994152046783624"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()[\"evaluation\"][\"episode_reward_mean\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d0e946-a17d-4104-975c-35f1cc0566ab",
   "metadata": {},
   "source": [
    "Yikes. Another 4 iterations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "648157bf-a4dc-4454-bb0a-ae2f5a85d258",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(4):\n",
    "    train_info = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "48bdad7e-c523-4126-9a7d-1ddb6938a85e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.32041343669250644"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()[\"evaluation\"][\"episode_reward_mean\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8a491d4-9bd2-4ea5-b11f-8b9d33390910",
   "metadata": {},
   "source": [
    "#### Comparing environments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff71581-143c-4bcd-9bb5-8b4e9b8bcdde",
   "metadata": {},
   "source": [
    "- It looks like we're hitting a plateau here and falling into the lake most of the time.\n",
    "- Let's compare the learning curves of the two environments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cdee8959-a7e8-4f79-9911-8dde89e5b01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_trainer = PPOTrainer({\"framework\" : \"torch\", \"create_env_on_driver\" : True, \"seed\" : 0}, \n",
    "                            env=FrozenPond)\n",
    "rando_trainer = PPOTrainer({\"framework\" : \"torch\", \"create_env_on_driver\" : True, \"seed\" : 0}, \n",
    "                            env=RandomLake)\n",
    "fixed_rewards = []\n",
    "rando_rewards = []\n",
    "\n",
    "for i in range(8):\n",
    "    fixed_rewards.append(fixed_trainer.train()['episode_reward_mean'])\n",
    "    rando_rewards.append(rando_trainer.train()['episode_reward_mean'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a49aa2-f60f-4983-97c1-0116bc92e9f1",
   "metadata": {},
   "source": [
    "#### Comparing environments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "07ed6a6a-7f7d-48cc-883e-bc3d20cc83ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(fixed_rewards, label=\"fixed\")\n",
    "plt.plot(rando_rewards, label=\"random\")\n",
    "plt.xlabel(\"training iteration\")\n",
    "plt.ylabel(\"success rate\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0610637c-8765-4b3e-b620-c9b11247f7b6",
   "metadata": {},
   "source": [
    "This confirms our idea that the random lake environment is much harder to solve."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cea2749-2dc6-4e5f-a01b-b751350ed6ba",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Random lake challenges\n",
    "\n",
    "- So, why is the random lake so hard?\n",
    "- Recall what we're learning: a policy, which maps observations to actions.\n",
    "- Here, our observations are the location in the lake, and the action is the movement direction.\n",
    "- So, say the observation is 3, meaning you're standing at the top-right. What action should you take?\n",
    "- Answer: it depends on where the holes are!\n",
    "- We're asking our agent to avoid holes _without being able to see_.\n",
    "- In the next section we'll address this issue."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8191ed69-c91c-4b3c-a9d7-6779f728e855",
   "metadata": {},
   "source": [
    "#### Let's apply what we learned!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f29e54-1e2c-4137-8130-f60c16328740",
   "metadata": {},
   "source": [
    "## Number of holes\n",
    "<!-- multiple choice -->\n",
    "\n",
    "Our Random Lake environment is set up so that each square (except the start and goal) has a 20% probability of being a hole. \n",
    "\n",
    "#### Average episode reward\n",
    "\n",
    "What do you think would happen to the average episode **reward** if we increased this number to 50%?\n",
    "\n",
    "- [ ] The average episode reward would increase.\n",
    "- [x] The average episode reward would decrease."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e32eab-df7d-4235-a4f1-d9b07391eeb4",
   "metadata": {},
   "source": [
    "#### Average episode length\n",
    "\n",
    "What do you think would happen to the average episode **length** if we increased this number to 50%?\n",
    "\n",
    "- [ ] The average episode length would increase.\n",
    "- [x] The average episode length would decrease."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e18f28-e0f5-4abb-a1f7-ab25bb7943a0",
   "metadata": {},
   "source": [
    "## Where is the randomness?\n",
    "<!-- multiple choice -->\n",
    "\n",
    "In our implementation of `RandomLake`, we put the random hole creation in the `reset` method:\n",
    "\n",
    "```python\n",
    "self.holes = np.random.rand(4, 4) < 0.2\n",
    "```\n",
    "\n",
    "What would have happened if we put this in the constructor instead?\n",
    "\n",
    "- [ ] It would behave the same as the current implementation.\n",
    "- [ ] It would revert back to the non-random Frozen Pond from the previous module.\n",
    "- [x] The holes would be randomized each time an environment is created, but all episodes would have the same random holes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c8cacad-97f4-41ec-8337-652600549571",
   "metadata": {},
   "source": [
    "## Step counter\n",
    "<!-- multiple choice -->\n",
    "\n",
    "We saw that some of the random lakes are impossible because the path to the goal is blocked by holes. Let's say we wanted to implement a step counter in our environment, where the episode ends after 50 steps even if you haven't reached the goal or fallen into a hole. \n",
    "\n",
    "#### Initializing the counter variable\n",
    "\n",
    "First, we would need to created a new counter variable, say `self.stepcount`, and initialize it to zero with `self.stepcount = 0`. In which method would we include this code?\n",
    "\n",
    "- [ ] constructor\n",
    "- [x] `reset`\n",
    "- [ ] `step`\n",
    "- [ ] `done` (called by `step`)\n",
    "- [ ] `render`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75761b99-6b65-473a-be27-a8f44800702f",
   "metadata": {},
   "source": [
    "#### Incrementing the counter\n",
    "\n",
    "Next, we would need to increment this counter after each step, say with `self.stepcount += 1`. In which method would we include this code?\n",
    "\n",
    "- [ ] constructor\n",
    "- [ ] `reset`\n",
    "- [x] `step`\n",
    "- [ ] `done` (called by `step`)\n",
    "- [ ] `render`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a8bb09-d9e7-4d15-bd10-e540070e12b3",
   "metadata": {},
   "source": [
    "#### Ending the episode\n",
    "\n",
    "Finally, we would need to make sure the episode ends if the `self.stepcount >= 50`. Which method should we modify?\n",
    "\n",
    "- [ ] constructor\n",
    "- [ ] `reset`\n",
    "- [ ] `step`\n",
    "- [x] `done` (called by `step`)\n",
    "- [ ] `render`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "410b77fb-51cf-4706-a835-afd1b9f68ace",
   "metadata": {},
   "source": [
    "## Step counter: implementation\n",
    "<!-- coding exercise -->\n",
    "\n",
    "Below is the code of the Random Lake (minus rendering). Following the logic from the previous exercise, implement a step counter so that the max episode length is 50 steps. Then, test it out with the provided code, which repeatedly moves left (thus not moving at all)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c7fdf181-408e-4b32-9f8f-2e8630fddc97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 False\n",
      "2 False\n",
      "3 False\n",
      "4 False\n",
      "5 False\n",
      "6 False\n",
      "7 False\n",
      "8 False\n",
      "9 False\n",
      "10 False\n",
      "11 False\n",
      "12 False\n",
      "13 False\n",
      "14 False\n",
      "15 False\n",
      "16 False\n",
      "17 False\n",
      "18 False\n",
      "19 False\n",
      "20 False\n",
      "21 False\n",
      "22 False\n",
      "23 False\n",
      "24 False\n",
      "25 False\n",
      "26 False\n",
      "27 False\n",
      "28 False\n",
      "29 False\n",
      "30 False\n",
      "31 False\n",
      "32 False\n",
      "33 False\n",
      "34 False\n",
      "35 False\n",
      "36 False\n",
      "37 False\n",
      "38 False\n",
      "39 False\n",
      "40 False\n",
      "41 False\n",
      "42 False\n",
      "43 False\n",
      "44 False\n",
      "45 False\n",
      "46 False\n",
      "47 False\n",
      "48 False\n",
      "49 False\n",
      "50 True\n",
      "51 True\n",
      "52 True\n",
      "53 True\n",
      "54 True\n",
      "55 True\n"
     ]
    }
   ],
   "source": [
    "# EXERCISE\n",
    "\n",
    "import gym\n",
    "\n",
    "class RandomLake(gym.Env):\n",
    "    def __init__(self, env_config=None):\n",
    "        self.observation_space = gym.spaces.Discrete(16)\n",
    "        self.action_space = gym.spaces.Discrete(4)      \n",
    "        \n",
    "    def reset(self):\n",
    "        self.player = (0, 0) # the player starts at the top-left\n",
    "        self.goal = (3, 3)   # goal is at the bottom-right\n",
    "        \n",
    "        self.holes = np.random.rand(4, 4) < 0.2\n",
    "        self.holes[self.player] = 0  # no hole at start location\n",
    "        self.holes[self.goal] = 0    # no hole at goal location\n",
    "        \n",
    "        return self.observation()\n",
    "    \n",
    "    def observation(self):\n",
    "        return 4*self.player[0] + self.player[1]\n",
    "    \n",
    "    def reward(self):\n",
    "        return int(self.player == self.goal)\n",
    "    \n",
    "    def done(self):\n",
    "        is_done = self.player == self.goal or self.holes[self.player] == 1 \n",
    "        return is_done\n",
    "    \n",
    "    def is_valid_loc(self, location):\n",
    "        return 0 <= location[0] <= 3 and 0 <= location[1] <= 3\n",
    "\n",
    "    def step(self, action):\n",
    "        # Compute the new player location\n",
    "        if action == 0:   # left\n",
    "            new_loc = (self.player[0], self.player[1]-1)\n",
    "        elif action == 1: # down\n",
    "            new_loc = (self.player[0]+1, self.player[1])\n",
    "        elif action == 2: # right\n",
    "            new_loc = (self.player[0], self.player[1]+1)\n",
    "        elif action == 3: # up\n",
    "            new_loc = (self.player[0]-1, self.player[1])\n",
    "        else:\n",
    "            raise ValueError(\"Action must be in {0,1,2,3}\")\n",
    "        \n",
    "        # Update the player location only if you stayed in bounds\n",
    "        if self.is_valid_loc(new_loc):\n",
    "            self.player = new_loc\n",
    "            \n",
    "        self.stepcount += 1\n",
    "        \n",
    "        return self.observation(), self.reward(), self.done(), {}\n",
    "    \n",
    "lake = RandomLake()\n",
    "obs = lake.reset()\n",
    "\n",
    "done = False\n",
    "for i in range(55):\n",
    "    obs, rewards, done, _ = lake.step(0)\n",
    "    print(i+1, done)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fbbf52b-78d2-4a3c-9d50-bb7a6d4b3cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION\n",
    "\n",
    "import gym\n",
    "\n",
    "class RandomLake(gym.Env):\n",
    "    def __init__(self, env_config=None):\n",
    "        self.observation_space = gym.spaces.Discrete(16)\n",
    "        self.action_space = gym.spaces.Discrete(4)      \n",
    "        \n",
    "    def reset(self):\n",
    "        self.player = (0, 0) # the player starts at the top-left\n",
    "        self.goal = (3, 3)   # goal is at the bottom-right\n",
    "        \n",
    "        self.holes = np.random.rand(4, 4) < 0.2\n",
    "        self.holes[self.player] = 0  # no hole at start location\n",
    "        self.holes[self.goal] = 0    # no hole at goal location\n",
    "        \n",
    "        self.stepcount = 0\n",
    "        \n",
    "        return self.observation()\n",
    "    \n",
    "    def observation(self):\n",
    "        return 4*self.player[0] + self.player[1]\n",
    "    \n",
    "    def reward(self):\n",
    "        return int(self.player == self.goal)\n",
    "    \n",
    "    def done(self):\n",
    "        is_done = self.player == self.goal or self.holes[self.player] == 1 or self.stepcount >= 50\n",
    "        return is_done\n",
    "    \n",
    "    def is_valid_loc(self, location):\n",
    "        return 0 <= location[0] <= 3 and 0 <= location[1] <= 3\n",
    "\n",
    "    def step(self, action):\n",
    "        # Compute the new player location\n",
    "        if action == 0:   # left\n",
    "            new_loc = (self.player[0], self.player[1]-1)\n",
    "        elif action == 1: # down\n",
    "            new_loc = (self.player[0]+1, self.player[1])\n",
    "        elif action == 2: # right\n",
    "            new_loc = (self.player[0], self.player[1]+1)\n",
    "        elif action == 3: # up\n",
    "            new_loc = (self.player[0]-1, self.player[1])\n",
    "        else:\n",
    "            raise ValueError(\"Action must be in {0,1,2,3}\")\n",
    "        \n",
    "        # Update the player location only if you stayed in bounds\n",
    "        if self.is_valid_loc(new_loc):\n",
    "            self.player = new_loc\n",
    "            \n",
    "        self.stepcount += 1\n",
    "        \n",
    "        return self.observation(), self.reward(), self.done(), {}\n",
    "    \n",
    "lake = RandomLake()\n",
    "obs = lake.reset()\n",
    "\n",
    "done = False\n",
    "for i in range(55):\n",
    "    obs, rewards, done, _ = lake.step(0)\n",
    "    print(i+1, done)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:rl-course]",
   "language": "python",
   "name": "conda-env-rl-course-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
