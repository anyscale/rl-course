{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e23df55-837b-4ec9-86ad-3b60c6a7f00d",
   "metadata": {},
   "source": [
    "## Random Lake Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ffbd783-053c-47c6-afb4-72724590ee1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HIDDEN\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['font.size'] = 14"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b96688-5597-4709-bd71-552dfec70920",
   "metadata": {},
   "source": [
    "#### Learning a policy\n",
    "\n",
    "- Let's train an agent to complete the Frozen Pond using RLlib.\n",
    "- This is similar to our Frozen Lake agent from Module 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63d101fe-ebcf-43bb-859f-d07d3afc2093",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray.rllib.agents.ppo import PPOTrainer\n",
    "from gym.wrappers import TimeLimit\n",
    "from envs import FrozenPond # defined in previous slides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c31ea0c-5e7b-46ff-b312-c1b846d7b2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = PPOTrainer({\"framework\" : \"torch\", \"create_env_on_driver\" : True, \"seed\" : 0, \"horizon\" : 100}, \n",
    "                     env=FrozenPond)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "548763bc-2399-4ac8-9936-2dba7b183467",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_info = trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ee6979-e728-454d-bf34-35d1688c748f",
   "metadata": {},
   "source": [
    "#### Learning a policy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd7f6f10-c910-47e8-995c-aac0c33855a8",
   "metadata": {},
   "source": [
    "We see that the agent only reaches the goal in ~6% of evaluation episodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc2c0986-b123-49b2-b021-9cc0a8ea0383",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05829596412556054"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()[\"evaluation\"][\"episode_reward_mean\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db523173-21d9-42a4-ab33-51d6f23a4d38",
   "metadata": {},
   "source": [
    "We can improve the agent by training for more iterations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d709ff68-c2dd-4cf8-acf2-1ed728b44569",
   "metadata": {},
   "source": [
    "#### Learning the Maze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b06c345a-3490-4ec8-8ef2-5b311f7db938",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(4):\n",
    "    train_info = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cdc6777d-e77d-4dbc-a9c1-5dbf75c06d5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8181818181818182"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()[\"evaluation\"][\"episode_reward_mean\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f416155b-486e-4e4f-958f-103d119cc829",
   "metadata": {},
   "source": [
    "With another 4 training iterations, we increased the success rate to more than 80%. Nice."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e482d6-850a-4608-932a-ffec45bf52d5",
   "metadata": {},
   "source": [
    "#### Beyond the simple lake\n",
    "\n",
    "We can train an agent to learn this fixed Frozen Pond:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b9ac3f06-a899-407c-82fe-217d48222aea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P...\n",
      ".O.O\n",
      "...O\n",
      "O..G\n"
     ]
    }
   ],
   "source": [
    "pond = FrozenPond()\n",
    "pond.reset()\n",
    "pond.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c23b95-7b31-40c8-819f-eb8f6a3872f8",
   "metadata": {},
   "source": [
    "But this is quite an easy problem:\n",
    "\n",
    "- Small state space\n",
    "- Small action space\n",
    "- No stochasticity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eaa3bd3-4291-4efd-b961-7fe41b71d463",
   "metadata": {},
   "source": [
    "#### Random lake\n",
    "\n",
    "- Let's make the problem harder by looking at a _random_ frozen lake\n",
    "- That is, the hole locations change every episode.\n",
    "- We'll do this by reimplementing the `reset` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4fad2e84-ce76-4c93-a373-74ea955e2a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomLake(FrozenPond):\n",
    "    def reset(self):\n",
    "        self.player = (0, 0) # the player starts at the top-left\n",
    "        self.goal = (3, 3)   # goal is at the bottom-right\n",
    "        \n",
    "        self.holes = np.random.rand(4, 4) < 0.2\n",
    "        self.holes[self.player] = 0  # no hole at start location\n",
    "        self.holes[self.goal] = 0    # no hole at goal location\n",
    "        \n",
    "        return 0 # the observation corresponding to (0,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04592876-bd6b-49be-9d0a-41b1ceb68ce0",
   "metadata": {},
   "source": [
    "Now, each square (except the start and end locations) is a hole with probability 20%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c86702-111e-48c0-9519-1a539e734187",
   "metadata": {},
   "source": [
    "#### Random lake"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef26c29d-0573-40f9-8cd9-a3aaa6daf073",
   "metadata": {},
   "source": [
    "Here's one random lake:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "85da7b48-9d04-454a-8f72-d56a127396ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HIDDEN\n",
    "np.random.seed(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f73a2c5a-6a5b-4718-bc8d-e975315b19da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PO..\n",
      "....\n",
      "....\n",
      "O.OG\n"
     ]
    }
   ],
   "source": [
    "lake = RandomLake()\n",
    "lake.reset()\n",
    "lake.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60bb00bd-b507-4a7a-a92c-b4ee2936c59e",
   "metadata": {},
   "source": [
    "Here's another:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8f209f4a-d520-4386-875b-f0f412d6d8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HIDDEN\n",
    "np.random.seed(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "25acfc89-2815-4830-8a1b-ccf71d17397d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P...\n",
      "..O.\n",
      "O.O.\n",
      "...G\n"
     ]
    }
   ],
   "source": [
    "lake.reset()\n",
    "lake.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c991ca-3b07-4b47-ad56-82b44810d241",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Impossible games"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd66e4fd-252d-4528-922f-0f523d03a462",
   "metadata": {},
   "source": [
    "And here's one more:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1923d74a-bd44-47c3-9097-3b243135382c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HIDDEN\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "15ebefd7-e7f3-4a59-b7df-6d15c976a6dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P.O.\n",
      "OOO.\n",
      "....\n",
      "..OG\n"
     ]
    }
   ],
   "source": [
    "lake.reset()\n",
    "lake.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abcf6d47-0d42-40ed-9c7d-832c08413bcd",
   "metadata": {},
   "source": [
    "- This time, there is no way to the goal! \n",
    "- This is a situation where the maximum episode length would really come in handle.\n",
    "  - We saw this earlier with the gym `TimeLimit` wrapper.\n",
    "- With these impossible lakes, we should no longer be aiming for a 100% win rate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4749279-b545-4967-ace4-37eb29196908",
   "metadata": {},
   "source": [
    "#### Learning the random lake"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc3e64a-f6ad-4c86-9f69-df8b7addc5ea",
   "metadata": {},
   "source": [
    "- We've had success with RLlib so far, achieving a decent win rate on the original Frozen Lake.\n",
    "- Let's try the random lake:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "76357ccd-be6b-4bae-ac47-bb4c800593d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = PPOTrainer({\"framework\" : \"torch\", \"create_env_on_driver\" : True, \"seed\" : 0, \"horizon\" : 100}, \n",
    "                     env=RandomLake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ff308b05-0541-4e33-a1cc-0090c3e4bc9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_info = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1170e96f-990d-42de-8651-faab7236e6c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19680851063829788"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()[\"evaluation\"][\"episode_reward_mean\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b542ce1-34e8-4b6d-a0c3-0afdb87e0f94",
   "metadata": {},
   "source": [
    "This looks good for only one training iteration."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f2aa884-f762-4d1c-a25b-172eecacd542",
   "metadata": {},
   "source": [
    "#### Learning the random lake"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34121616-3826-426d-ac5d-8e01940a0c88",
   "metadata": {},
   "source": [
    "Let's try more iterations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e8d867db-3015-4e68-815a-c9cb002f4dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(4):\n",
    "    train_info = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2b5d3b1d-6dc2-4c5e-bef3-2b8953aec8ce",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2672413793103448"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()[\"evaluation\"][\"episode_reward_mean\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d0e946-a17d-4104-975c-35f1cc0566ab",
   "metadata": {},
   "source": [
    "Yikes. Another 4 iterations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "648157bf-a4dc-4454-bb0a-ae2f5a85d258",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(4):\n",
    "    train_info = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "48bdad7e-c523-4126-9a7d-1ddb6938a85e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2872340425531915"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()[\"evaluation\"][\"episode_reward_mean\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8a491d4-9bd2-4ea5-b11f-8b9d33390910",
   "metadata": {},
   "source": [
    "#### Comparing environments\n",
    "\n",
    "- It looks like we're hitting a plateau here and falling into the lake most of the time.\n",
    "- Let's compare the learning curves of the two environments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cdee8959-a7e8-4f79-9911-8dde89e5b01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_trainer = PPOTrainer({\"framework\" : \"torch\", \"create_env_on_driver\" : True, \"seed\" : 0, \n",
    "                            \"horizon\" : 100}, env=FrozenPond)\n",
    "rando_trainer = PPOTrainer({\"framework\" : \"torch\", \"create_env_on_driver\" : True, \"seed\" : 0, \n",
    "                            \"horizon\" : 100}, env=RandomLake)\n",
    "fixed_rewards = []\n",
    "rando_rewards = []\n",
    "\n",
    "for i in range(8):\n",
    "    fixed_rewards.append(fixed_trainer.train()['episode_reward_mean'])\n",
    "    rando_rewards.append(rando_trainer.train()['episode_reward_mean'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a49aa2-f60f-4983-97c1-0116bc92e9f1",
   "metadata": {},
   "source": [
    "#### Comparing environments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "07ed6a6a-7f7d-48cc-883e-bc3d20cc83ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(fixed_rewards, label=\"fixed\")\n",
    "plt.plot(rando_rewards, label=\"random\")\n",
    "plt.xlabel(\"training iteration\")\n",
    "plt.ylabel(\"success rate\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0610637c-8765-4b3e-b620-c9b11247f7b6",
   "metadata": {},
   "source": [
    "This confirms our idea that the random lake environment is much harder to solve."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cea2749-2dc6-4e5f-a01b-b751350ed6ba",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Random lake challenges\n",
    "\n",
    "- So, why is the random lake so hard?\n",
    "- Recall what we're learning: a policy, which maps observations to actions.\n",
    "- Here, our observations are the location in the lake, and the action is the movement direction.\n",
    "- So, say the observation is 3, meaning you're standing at the top-right. What action should you take?\n",
    "- Answer: it depends on where the holes are!\n",
    "- We're asking our agent to avoid holes _without being able to see_.\n",
    "- In the next section we'll address this issue."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8191ed69-c91c-4b3c-a9d7-6779f728e855",
   "metadata": {},
   "source": [
    "#### Let's apply what we learned!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f29e54-1e2c-4137-8130-f60c16328740",
   "metadata": {},
   "source": [
    "## Number of holes\n",
    "<!-- multiple choice -->\n",
    "\n",
    "Our Random Lake environment is set up so that each square (except the start and goal) has a 20% probability of being a hole. \n",
    "\n",
    "#### Average episode reward\n",
    "\n",
    "What do you think would happen to the average episode **reward** if we increased this number to 50%?\n",
    "\n",
    "- [ ] The average episode reward would increase.\n",
    "- [x] The average episode reward would decrease."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e32eab-df7d-4235-a4f1-d9b07391eeb4",
   "metadata": {},
   "source": [
    "#### Average episode length\n",
    "\n",
    "What do you think would happen to the average episode **length** if we increased this number to 50%?\n",
    "\n",
    "- [ ] The average episode length would increase.\n",
    "- [x] The average episode length would decrease."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e18f28-e0f5-4abb-a1f7-ab25bb7943a0",
   "metadata": {},
   "source": [
    "## Where is the randomness?\n",
    "<!-- multiple choice -->\n",
    "\n",
    "In our implementation of `RandomLake`, we put the random hole creation in the `reset` method:\n",
    "\n",
    "```python\n",
    "self.holes = np.random.rand(4, 4) < 0.2\n",
    "```\n",
    "\n",
    "What would have happened if we put this in the constructor instead?\n",
    "\n",
    "- [ ] It would behave the same as the current implementation.\n",
    "- [ ] It would revert back to the non-random Frozen Pond from the previous module.\n",
    "- [x] The holes would be randomized each time an environment is created, but all episodes would have the same random holes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c8cacad-97f4-41ec-8337-652600549571",
   "metadata": {},
   "source": [
    "## Step counter\n",
    "<!-- multiple choice -->\n",
    "\n",
    "Let's say we wanted to implement a step counter in our environment _manually_, not using gym's `TimeLimit` wrapper or RLlib's `\"horizon\"` parameter for training. As a reminder, we would like the episodes to end after 50 steps even if you haven't reached the goal or fallen into a hole. \n",
    "\n",
    "#### Initializing the counter variable\n",
    "\n",
    "First, we would need to created a new counter variable, say `self.stepcount`, and initialize it to zero with `self.stepcount = 0`. In which method would we include this code?\n",
    "\n",
    "- [ ] constructor\n",
    "- [x] `reset`\n",
    "- [ ] `step`\n",
    "- [ ] `done` (called by `step`)\n",
    "- [ ] `render`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75761b99-6b65-473a-be27-a8f44800702f",
   "metadata": {},
   "source": [
    "#### Incrementing the counter\n",
    "\n",
    "Next, we would need to increment this counter after each step, say with `self.stepcount += 1`. In which method would we include this code?\n",
    "\n",
    "- [ ] constructor\n",
    "- [ ] `reset`\n",
    "- [x] `step`\n",
    "- [ ] `done` (called by `step`)\n",
    "- [ ] `render`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a8bb09-d9e7-4d15-bd10-e540070e12b3",
   "metadata": {},
   "source": [
    "#### Ending the episode\n",
    "\n",
    "Finally, we would need to make sure the episode ends if the `self.stepcount >= 50`. Which method should we modify?\n",
    "\n",
    "- [ ] constructor\n",
    "- [ ] `reset`\n",
    "- [ ] `step`\n",
    "- [x] `done` (called by `step`)\n",
    "- [ ] `render`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "410b77fb-51cf-4706-a835-afd1b9f68ace",
   "metadata": {},
   "source": [
    "## Step counter: implementation\n",
    "<!-- coding exercise -->\n",
    "\n",
    "Below is the code of the Random Lake (minus rendering). Following the logic from the previous exercise, implement a step counter so that the max episode length is 50 steps. Then, test it out with the provided code, which repeatedly moves left (thus not moving at all)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7fdf181-408e-4b32-9f8f-2e8630fddc97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXERCISE\n",
    "\n",
    "import gym\n",
    "\n",
    "class RandomLake(gym.Env):\n",
    "    def __init__(self, env_config=None):\n",
    "        self.observation_space = gym.spaces.Discrete(16)\n",
    "        self.action_space = gym.spaces.Discrete(4)      \n",
    "        \n",
    "    def reset(self):\n",
    "        self.player = (0, 0) # the player starts at the top-left\n",
    "        self.goal = (3, 3)   # goal is at the bottom-right\n",
    "        \n",
    "        self.holes = np.random.rand(4, 4) < 0.2\n",
    "        self.holes[self.player] = 0  # no hole at start location\n",
    "        self.holes[self.goal] = 0    # no hole at goal location\n",
    "        \n",
    "        return self.observation()\n",
    "    \n",
    "    def observation(self):\n",
    "        return 4*self.player[0] + self.player[1]\n",
    "    \n",
    "    def reward(self):\n",
    "        return int(self.player == self.goal)\n",
    "    \n",
    "    def done(self):\n",
    "        is_done = self.player == self.goal or self.holes[self.player] == 1 \n",
    "        return is_done\n",
    "    \n",
    "    def is_valid_loc(self, location):\n",
    "        return 0 <= location[0] <= 3 and 0 <= location[1] <= 3\n",
    "\n",
    "    def step(self, action):\n",
    "        # Compute the new player location\n",
    "        if action == 0:   # left\n",
    "            new_loc = (self.player[0], self.player[1]-1)\n",
    "        elif action == 1: # down\n",
    "            new_loc = (self.player[0]+1, self.player[1])\n",
    "        elif action == 2: # right\n",
    "            new_loc = (self.player[0], self.player[1]+1)\n",
    "        elif action == 3: # up\n",
    "            new_loc = (self.player[0]-1, self.player[1])\n",
    "        else:\n",
    "            raise ValueError(\"Action must be in {0,1,2,3}\")\n",
    "        \n",
    "        # Update the player location only if you stayed in bounds\n",
    "        if self.is_valid_loc(new_loc):\n",
    "            self.player = new_loc\n",
    "            \n",
    "        self.stepcount += 1\n",
    "        \n",
    "        return self.observation(), self.reward(), self.done(), {}\n",
    "    \n",
    "lake = RandomLake()\n",
    "obs = lake.reset()\n",
    "\n",
    "done = False\n",
    "for i in range(55):\n",
    "    obs, rewards, done, _ = lake.step(0)\n",
    "    print(i+1, done)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fbbf52b-78d2-4a3c-9d50-bb7a6d4b3cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION\n",
    "\n",
    "import gym\n",
    "\n",
    "class RandomLake(gym.Env):\n",
    "    def __init__(self, env_config=None):\n",
    "        self.observation_space = gym.spaces.Discrete(16)\n",
    "        self.action_space = gym.spaces.Discrete(4)      \n",
    "        \n",
    "    def reset(self):\n",
    "        self.player = (0, 0) # the player starts at the top-left\n",
    "        self.goal = (3, 3)   # goal is at the bottom-right\n",
    "        \n",
    "        self.holes = np.random.rand(4, 4) < 0.2\n",
    "        self.holes[self.player] = 0  # no hole at start location\n",
    "        self.holes[self.goal] = 0    # no hole at goal location\n",
    "        \n",
    "        self.stepcount = 0\n",
    "        \n",
    "        return self.observation()\n",
    "    \n",
    "    def observation(self):\n",
    "        return 4*self.player[0] + self.player[1]\n",
    "    \n",
    "    def reward(self):\n",
    "        return int(self.player == self.goal)\n",
    "    \n",
    "    def done(self):\n",
    "        is_done = self.player == self.goal or self.holes[self.player] == 1 or self.stepcount >= 50\n",
    "        return is_done\n",
    "    \n",
    "    def is_valid_loc(self, location):\n",
    "        return 0 <= location[0] <= 3 and 0 <= location[1] <= 3\n",
    "\n",
    "    def step(self, action):\n",
    "        # Compute the new player location\n",
    "        if action == 0:   # left\n",
    "            new_loc = (self.player[0], self.player[1]-1)\n",
    "        elif action == 1: # down\n",
    "            new_loc = (self.player[0]+1, self.player[1])\n",
    "        elif action == 2: # right\n",
    "            new_loc = (self.player[0], self.player[1]+1)\n",
    "        elif action == 3: # up\n",
    "            new_loc = (self.player[0]-1, self.player[1])\n",
    "        else:\n",
    "            raise ValueError(\"Action must be in {0,1,2,3}\")\n",
    "        \n",
    "        # Update the player location only if you stayed in bounds\n",
    "        if self.is_valid_loc(new_loc):\n",
    "            self.player = new_loc\n",
    "            \n",
    "        self.stepcount += 1\n",
    "        \n",
    "        return self.observation(), self.reward(), self.done(), {}\n",
    "    \n",
    "lake = RandomLake()\n",
    "obs = lake.reset()\n",
    "\n",
    "done = False\n",
    "for i in range(55):\n",
    "    obs, rewards, done, _ = lake.step(0)\n",
    "    print(i+1, done)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:rl-course]",
   "language": "python",
   "name": "conda-env-rl-course-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
