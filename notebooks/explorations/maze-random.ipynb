{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf336e3e-20b0-4095-af4e-880907ceac4a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## The problem\n",
    "\n",
    "- Walking around in a 2D maze, with walls put in random locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bfbaf003-567b-415b-a4ce-2cd8c94fe1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "from gym.spaces import Discrete\n",
    "import numpy as np\n",
    "import ray\n",
    "from ray.rllib.agents.dqn import DQNTrainer\n",
    "from ray.rllib.agents.ppo import PPOTrainer\n",
    "from ray.rllib.models.preprocessors import get_preprocessor \n",
    "from tqdm.notebook import trange, tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81e0db0d-bc87-4c99-8e13-4dffe6f24e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4cdcef1b-9377-4a6d-8b3f-41552167e6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "action_names = {\n",
    "    0 : \"up\",\n",
    "    1 : \"down\",\n",
    "    2 : \"left\",\n",
    "    3 : \"right\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0890080-6686-4876-b100-07bc48b87b57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'node_ip_address': '127.0.0.1',\n",
       " 'raylet_ip_address': '127.0.0.1',\n",
       " 'redis_address': '127.0.0.1:19977',\n",
       " 'object_store_address': '/tmp/ray/session_2022-04-06_08-26-56_591862_42480/sockets/plasma_store',\n",
       " 'raylet_socket_name': '/tmp/ray/session_2022-04-06_08-26-56_591862_42480/sockets/raylet',\n",
       " 'webui_url': None,\n",
       " 'session_dir': '/tmp/ray/session_2022-04-06_08-26-56_591862_42480',\n",
       " 'metrics_export_port': 63347,\n",
       " 'gcs_address': '127.0.0.1:60696',\n",
       " 'node_id': '996cd8db552b7b0a6bd80b3143c2ecbc062143494a015071c86ec797'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ray.init(ignore_reinit_error=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ed4f7a9-fc7c-47b4-9d8f-a40b91f9b61f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomMazeEnvironment(gym.Env): \n",
    "    def __init__(self, env_config):\n",
    "        self.ylen = env_config.get(\"ylen\", 5)\n",
    "        self.xlen = env_config.get(\"xlen\", 5)\n",
    "        \n",
    "        self.action_space = gym.spaces.Discrete(4)\n",
    "        \n",
    "        # show entire state, not just nearby the player\n",
    "        # self.observation_space = gym.spaces.Dict({\n",
    "        #     \"player\" : gym.spaces.Discrete(self.ylen*self.xlen),\n",
    "        #     \"walls\" : gym.spaces.MultiBinary(self.ylen*self.xlen)\n",
    "        # })\n",
    "        # self.observation_space = gym.spaces.MultiBinary([2, self.ylen, self.xlen])\n",
    "\n",
    "        # see https://docs.ray.io/en/latest/rllib/rllib-models.html\n",
    "        # looks like they mainly just preprocess discrete/multidiscrete and atari?\n",
    "        # what about box?? hmm. i guess those go without preproc?\n",
    "        \n",
    "        self.observation_space = gym.spaces.MultiDiscrete([2,2,2,2])\n",
    "        # self.observation_space = gym.spaces.Tuple([Discrete(2), Discrete(2), Discrete(2), Discrete(2)])\n",
    "        # self.observation_space = gym.spaces.MultiBinary(4)\n",
    "        \n",
    "        self.seed = env_config.get(\"random_seed\", None)\n",
    "    \n",
    "    def reset(self, seed=None):\n",
    "        # print(\"RESET\")\n",
    "        self.player = (0, 0)\n",
    "        self.exit = (self.ylen-1, self.xlen-1)\n",
    "        \n",
    "        if self.seed is not None: # fixed seed every time, not random maze\n",
    "            np.random.seed(self.seed)\n",
    "        \n",
    "        self.walls = np.random.rand(self.ylen, self.xlen) < 0.2\n",
    "        self.walls[self.player] = 0\n",
    "        self.walls[self.exit] = 0\n",
    "        \n",
    "        self.num_steps = 0\n",
    "        return self.get_observation()\n",
    "    \n",
    "    def get_observation(self): # SWAPPED FROM THE ABOVE ONE\n",
    "        # make the observation into the entire state??\n",
    "        # playerstate = self.player[1] + self.xlen*self.player[0]\n",
    "        # obsdict = {\n",
    "        #     \"player\" : playerstate,\n",
    "        #     \"walls\" : self.wallsstate\n",
    "        # }\n",
    "        # return obsdict\n",
    "        \n",
    "        # playerstate = 0*self.walls\n",
    "        # playerstate[self.player] = 1\n",
    "        # return np.concatenate((playerstate[None], \n",
    "        #                        self.walls[None]), axis=0).astype(int)\n",
    "        i, j = self.player\n",
    "\n",
    "        obs = []\n",
    "        obs.append(1 if i==0           else self.walls[i-1,j]) # up\n",
    "        obs.append(1 if i==self.ylen-1 else self.walls[i+1,j]) # down\n",
    "        obs.append(1 if j==0           else self.walls[i,j-1]) # left\n",
    "        obs.append(1 if j==self.xlen-1 else self.walls[i,j+1]) # right\n",
    "        return np.array(obs, dtype=int)\n",
    "        # 3x3 context, 8 observations\n",
    "        # wallsexit = self.walls.copy()\n",
    "        # wallspad = np.pad(wallsexit, 1, constant_values=1) # pad with 1 to simulate walls all around\n",
    "        # nearby = wallspad[self.player[0]:self.player[0]+3, self.player[1]:self.player[1]+3]\n",
    "        # nearbyflat = nearby.flatten()\n",
    "        # minus_middle = np.concatenate((nearbyflat[:4], nearbyflat[5:]))\n",
    "        # return minus_middle\n",
    "        # NW N NE W E SW S SE\n",
    "    \n",
    "    def step(self, action):\n",
    "        self.num_steps += 1\n",
    "        \n",
    "        if action == 0: # move up\n",
    "            new_loc = (self.player[0]-1, self.player[1])\n",
    "            \n",
    "        elif action == 1: # move down\n",
    "            new_loc = (self.player[0]+1, self.player[1])\n",
    "                \n",
    "        elif action == 2: # move left\n",
    "            new_loc = (self.player[0], self.player[1]-1)\n",
    "  \n",
    "        elif action == 3: # move right\n",
    "            new_loc = (self.player[0], self.player[1]+1)\n",
    "                \n",
    "        else:\n",
    "            raise Exception(\"Action must be {0,1,2,3}\")\n",
    "            \n",
    "        # update state if you are able to move\n",
    "        move_success = False\n",
    "        if 0 <= new_loc[0] < self.ylen and 0 <= new_loc[1] < self.xlen and not self.walls[new_loc]:\n",
    "            self.player = new_loc\n",
    "            move_success = True\n",
    "                \n",
    "        info = {\"player pos\" : self.player}\n",
    "        \n",
    "        # reward\n",
    "        distance = np.abs(self.player[0]-self.exit[0]) + np.abs(self.player[1]-self.exit[1])\n",
    "        reward = -distance\n",
    "        \n",
    "        # penalize walking into walls\n",
    "        if not move_success:\n",
    "            reward -= 5\n",
    "        \n",
    "        return self.get_observation(), reward, self.is_done(), info\n",
    "\n",
    "    \n",
    "    def is_done(self):\n",
    "        return self.player == self.exit or self.num_steps >= 500\n",
    "\n",
    "    def render(self):\n",
    "        for i in range(self.xlen):\n",
    "            for j in range(self.ylen):\n",
    "                if (i,j) == self.exit:\n",
    "                    print(\"E\", end=\"\")\n",
    "                elif (i,j) == self.player:\n",
    "                    print(\"P\", end=\"\")\n",
    "                elif self.walls[i,j]:\n",
    "                    print(\"X\", end=\"\")\n",
    "                else:\n",
    "                    print(\".\", end=\"\")\n",
    "                # print(\"O\", end=\"\")\n",
    "            print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8cbac29c-fa8b-45a4-9081-7768ff025f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "rme = RandomMazeEnvironment({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0053ea09-352e-4f07-86f0-f79d4a7cf216",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 0])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rme.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7bdfef18-af55-4a80-8f80-5acc736028de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P...X\n",
      ".....\n",
      ".....\n",
      ".X...\n",
      "....E\n"
     ]
    }
   ],
   "source": [
    "rme.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b9ba80d-57a5-4bfe-867f-ed488665d16c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1, 0, 1, 0]), -13, False, {'player pos': (0, 0)})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rme.step(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "10a5c9b7-7fe4-4ba9-98b1-1ecaaba50ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer_config_2 = copy.copy(trainer_config)\n",
    "# trainer_config_2[\"model\"] = {\"fcnet_hiddens\" : [64, 64]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "87345888-8305-4eeb-95e2-a1f7d5bdb8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_config_rme = {\n",
    "    # \"num_workers\": 0,\n",
    "    \"model\": {\n",
    "        \"fcnet_hiddens\": [64, 64],\n",
    "        \"fcnet_activation\": \"relu\",\n",
    "    },\n",
    "    \"evaluation_num_workers\": 1,\n",
    "    # \"create_env_on_driver\" : True,\n",
    "    \"log_level\" : \"ERROR\",\n",
    "    \"framework\" : \"torch\"\n",
    "    # \"_disable_preprocessor_api\" : True\n",
    "    # \"vf_loss_coef\" : 1/20_000 # make this small if the value function loss is big, only if vf_share_layers\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7c761db6-efcb-4efe-9745-eda1d144e11d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-06 08:27:03,599\tWARNING trainer.py:2279 -- You have specified 1 evaluation workers, but your `evaluation_interval` is None! Therefore, evaluation will not occur automatically with each call to `Trainer.train()`. Instead, you will have to call `Trainer.evaluate()` manually in order to trigger an evaluation run.\n",
      "2022-04-06 08:27:03,603\tINFO ppo.py:249 -- In multi-agent mode, policies will be optimized sequentially by the multi-GPU optimizer. Consider setting simple_optimizer=True if this doesn't work for you.\n",
      "2022-04-06 08:27:03,603\tINFO trainer.py:790 -- Current log_level is ERROR. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n"
     ]
    }
   ],
   "source": [
    "trainer = PPOTrainer(trainer_config_rme, env=RandomMazeEnvironment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3906f3cb-5fd3-407b-83af-32cc34f950f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.config[\"train_batch_size\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a95ce2-a4c1-4981-a5ad-219c459944f6",
   "metadata": {},
   "source": [
    "This is measure in individual time steps, per worker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d695d0a2-7a98-4723-bc5d-3a858f93d859",
   "metadata": {},
   "outputs": [],
   "source": [
    "rewards = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e2a7dde1-6392-48ab-b131-8a957d4283bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "for iteration in range(10):\n",
    "    print(iteration)\n",
    "    out = trainer.train();\n",
    "    rewards.append(out['episode_reward_mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "27a8103b-3bcf-48fa-9f55-9729fc0241bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(rewards);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "09fbfb57-e202-4280-8081-1679048df783",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(out[\"hist_stats\"][\"episode_reward\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cea043e-9dc7-4e80-94cd-764ab2deb153",
   "metadata": {},
   "source": [
    "^ number of episodes in one call to `trainer.train()`\n",
    "\n",
    "Keeping the last 100 in memory for a moving average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "94a09a1d-3ad9-45e6-b5e4-b5a46465c83f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'evaluation': {'episode_reward_max': -37.0,\n",
       "  'episode_reward_min': -2158.0,\n",
       "  'episode_reward_mean': -564.2,\n",
       "  'episode_len_mean': 104.5,\n",
       "  'episode_media': {},\n",
       "  'episodes_this_iter': 10,\n",
       "  'policy_reward_min': {},\n",
       "  'policy_reward_max': {},\n",
       "  'policy_reward_mean': {},\n",
       "  'custom_metrics': {},\n",
       "  'hist_stats': {'episode_reward': [-37.0,\n",
       "    -76.0,\n",
       "    -1667.0,\n",
       "    -85.0,\n",
       "    -767.0,\n",
       "    -50.0,\n",
       "    -73.0,\n",
       "    -2158.0,\n",
       "    -569.0,\n",
       "    -160.0],\n",
       "   'episode_lengths': [10, 19, 235, 16, 108, 12, 25, 500, 94, 26]},\n",
       "  'sampler_perf': {'mean_raw_obs_processing_ms': 0.09988644382921733,\n",
       "   'mean_inference_ms': 0.3292458007258165,\n",
       "   'mean_action_processing_ms': 0.019995705803311344,\n",
       "   'mean_env_wait_ms': 0.02004653500325365,\n",
       "   'mean_env_render_ms': 0.0},\n",
       "  'off_policy_estimator': {},\n",
       "  'timesteps_this_iter': 0}}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "18ca07c4-22cc-4b83-9acd-2b420e751e4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P.X.X\n",
      "X..XX\n",
      "...X.\n",
      ".....\n",
      "X...E\n"
     ]
    }
   ],
   "source": [
    "rme = RandomMazeEnvironment({})\n",
    "obs = rme.reset() \n",
    "rme.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1f5e7c49-db20-442e-b054-a358362d0050",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..X.X\n",
      "X..XX\n",
      "...X.\n",
      ".....\n",
      "X...E\n",
      "\n",
      "action: down\n",
      "reward: 0\n",
      "done: True\n",
      "obs: [0 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "action = trainer.compute_single_action(input_dict={\"obs\": obs})#, explore=False)\n",
    "res = rme.step(action)\n",
    "obs = res[0]\n",
    "rme.render()\n",
    "\n",
    "print(\"\\naction:\", action_names[action])\n",
    "print(\"reward:\", res[1])\n",
    "print(\"done:\", res[2])\n",
    "print(\"obs:\", obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a0146852-4768-419d-a3fb-966ae7d17978",
   "metadata": {},
   "outputs": [],
   "source": [
    "policy = trainer.get_policy()\n",
    "model = policy.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "50c3e584-f28c-4b50-8ff2-e7752568aab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_output = model({\"obs\": torch.from_numpy(obs)})[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3d1b1569-a125-4380-962f-6d6c988bc64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6033a529-8087-48a9-8336-a29b3adf917b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FullyConnectedNetwork(\n",
      "  (_logits): SlimFC(\n",
      "    (_model): Sequential(\n",
      "      (0): Linear(in_features=64, out_features=4, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (_hidden_layers): Sequential(\n",
      "    (0): SlimFC(\n",
      "      (_model): Sequential(\n",
      "        (0): Linear(in_features=8, out_features=64, bias=True)\n",
      "        (1): ReLU()\n",
      "      )\n",
      "    )\n",
      "    (1): SlimFC(\n",
      "      (_model): Sequential(\n",
      "        (0): Linear(in_features=64, out_features=64, bias=True)\n",
      "        (1): ReLU()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (_value_branch_separate): Sequential(\n",
      "    (0): SlimFC(\n",
      "      (_model): Sequential(\n",
      "        (0): Linear(in_features=8, out_features=64, bias=True)\n",
      "        (1): ReLU()\n",
      "      )\n",
      "    )\n",
      "    (1): SlimFC(\n",
      "      (_model): Sequential(\n",
      "        (0): Linear(in_features=64, out_features=64, bias=True)\n",
      "        (1): ReLU()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (_value_branch): SlimFC(\n",
      "    (_model): Sequential(\n",
      "      (0): Linear(in_features=64, out_features=1, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "725d0186-654d-4ae3-b804-6f58d869a403",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(trainer.get_policy().get_weights().values())[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "79294b81-830a-4e21-a556-c9d5ab2a8982",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'FullyConnectedNetwork' object has no attribute 'get_q_value_distributions'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/f5/138zmtfd159g5x_f1t80qr440000gp/T/ipykernel_42480/777473342.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mq_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_q_value_distributions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/rllib/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1175\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1177\u001b[0;31m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0m\u001b[1;32m   1178\u001b[0m             type(self).__name__, name))\n\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'FullyConnectedNetwork' object has no attribute 'get_q_value_distributions'"
     ]
    }
   ],
   "source": [
    "q_values = model.get_q_value_distributions(model_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672dfcfa-252e-4074-a0f9-084e9d41990f",
   "metadata": {},
   "outputs": [],
   "source": [
    "q_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d2626e7-0ccc-4901-9b1c-444ef16834e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda28df1-1e40-47c4-a8c1-f32ff54d388d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist = policy.dist_class(model_output, model) \n",
    "dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080e58fe-c5d6-4b61-b186-8058840e3051",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c2c0b3-183d-41bb-bce3-89e25caa6625",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist.dist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2be3ba1-aa3b-478e-855b-d300ec19be32",
   "metadata": {},
   "source": [
    "## Questions for Sven\n",
    "\n",
    "- How many episodes are actually getting run during training/evaluation? Only 10?\n",
    "  - It's complicated for training, but the batch size is measured in time steps (rather than episodes) so it also depends on episode length\n",
    "- `compute_action` vs `compute_single_action` \n",
    "  - Use `compute_single_action`\n",
    "- Can we go through the results of `print(model)` and understand why it looks the way it does?\n",
    "  - for Pytorch specifically, the layers are shown alphabetically and not in order (it only gets linked up in the call to `forward`)\n",
    "- How to get q values from `ComplexInputNetwork`?\n",
    "  - Don't use `ComplexInputNetwork`, avoid at all costs\n",
    "- What happens if you don't call `ray.init()` - the code still seems to run?\n",
    "- Is it fine to call `ray.init(ignore_reinit_error=True)` repeatedly?\n",
    "  - Yes\n",
    "- Why does `episode_reward_mean` not get better with more iterations? Is it because we've reaching the \"ceiling\" given the environment/model?\n",
    "  - Wasn't working at all with `MultiBinary`\n",
    "- What would be your next step to improve performance here? Ideas...\n",
    "  - Reward crafting\n",
    "  - Observation crafting\n",
    "  - Model/algo tuning / ray tune\n",
    "  - More iterations (how do you decide this? look for a plateau? results are generally quite noisy, I guess due to the randomness in the env)\n",
    "  - ...?\n",
    "- Higher-level question: in my google doc I have a list of envs for the tuned examples - which ones would be good for the course? can they be rendered?\n",
    "- Can I reuse recsim material from Sven's tutorial in the course? (And if so, do we think it's a good idea)\n",
    "- Ok to do the whole course with the Python API instead of the CLI?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "682312f9-ba07-4a99-ad73-96d56bc1fdd2",
   "metadata": {},
   "source": [
    "Things that seem to have magically fixed themselves:\n",
    "\n",
    "- Why does it say episode lengths are always 500 when it clearly seems to work (below)?\n",
    "- When I do `dist.sample()`, why do I get numbers larger than 3?\n",
    "- And, why is `model_output` size 64 instead of 4?\n",
    "\n",
    "I wonder why this was happening before... could it have been with `DQN`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805d5e8d-2de0-40ad-a9e4-55a865b1db60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f6dc77-a789-4cd2-9f86-95c3920c639c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e8d72d-55bc-4954-b429-5b4bcb566407",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e4cbb7-ca08-4fe7-98c8-832331434c7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bf563cb9-e516-49d4-b022-910c49d1e696",
   "metadata": {},
   "source": [
    "Idea: give the agent an action that says \"give up\", take a reward hit, but move on.\n",
    "So basically, see if they can figure out if it's unsolvable."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:rllib]",
   "language": "python",
   "name": "conda-env-rllib-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
