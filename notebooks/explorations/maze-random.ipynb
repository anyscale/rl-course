{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf336e3e-20b0-4095-af4e-880907ceac4a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## The problem\n",
    "\n",
    "- Walking around in a 2D maze, with walls put in random locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bfbaf003-567b-415b-a4ce-2cd8c94fe1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "from gym.spaces import Discrete\n",
    "import numpy as np\n",
    "import ray\n",
    "from ray.rllib.agents.dqn import DQNTrainer\n",
    "from ray.rllib.agents.ppo import PPOTrainer\n",
    "from ray.rllib.models.preprocessors import get_preprocessor \n",
    "from tqdm.notebook import trange, tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81e0db0d-bc87-4c99-8e13-4dffe6f24e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4cdcef1b-9377-4a6d-8b3f-41552167e6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "action_names = {\n",
    "    0 : \"up\",\n",
    "    1 : \"down\",\n",
    "    2 : \"left\",\n",
    "    3 : \"right\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0890080-6686-4876-b100-07bc48b87b57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'node_ip_address': '127.0.0.1',\n",
       " 'raylet_ip_address': '127.0.0.1',\n",
       " 'redis_address': '127.0.0.1:6379',\n",
       " 'object_store_address': '/tmp/ray/session_2022-04-06_09-04-04_840336_4389/sockets/plasma_store',\n",
       " 'raylet_socket_name': '/tmp/ray/session_2022-04-06_09-04-04_840336_4389/sockets/raylet',\n",
       " 'webui_url': None,\n",
       " 'session_dir': '/tmp/ray/session_2022-04-06_09-04-04_840336_4389',\n",
       " 'metrics_export_port': 59213,\n",
       " 'gcs_address': '127.0.0.1:50362',\n",
       " 'node_id': '3c52a81ed92603aa6c94712326bb7601b53ead07df5e86ce7ed0cdeb'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ray.init(ignore_reinit_error=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ed4f7a9-fc7c-47b4-9d8f-a40b91f9b61f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomMazeEnvironment(gym.Env): \n",
    "    def __init__(self, env_config):\n",
    "        self.ylen = env_config.get(\"ylen\", 5)\n",
    "        self.xlen = env_config.get(\"xlen\", 5)\n",
    "        \n",
    "        self.action_space = gym.spaces.Discrete(4)\n",
    "        \n",
    "        # show entire state, not just nearby the player\n",
    "        # self.observation_space = gym.spaces.Dict({\n",
    "        #     \"player\" : gym.spaces.Discrete(self.ylen*self.xlen),\n",
    "        #     \"walls\" : gym.spaces.MultiBinary(self.ylen*self.xlen)\n",
    "        # })\n",
    "        # self.observation_space = gym.spaces.MultiBinary([2, self.ylen, self.xlen])\n",
    "\n",
    "        # see https://docs.ray.io/en/latest/rllib/rllib-models.html\n",
    "        # looks like they mainly just preprocess discrete/multidiscrete and atari?\n",
    "        # what about box?? hmm. i guess those go without preproc?\n",
    "        \n",
    "        self.observation_space = gym.spaces.MultiDiscrete([2,2,2,2])\n",
    "        # self.observation_space = gym.spaces.Tuple([Discrete(2), Discrete(2), Discrete(2), Discrete(2)])\n",
    "        # self.observation_space = gym.spaces.MultiBinary(4)\n",
    "        \n",
    "        self.seed = env_config.get(\"random_seed\", None)\n",
    "    \n",
    "    def reset(self, seed=None):\n",
    "        # print(\"RESET\")\n",
    "        self.player = (0, 0)\n",
    "        self.exit = (self.ylen-1, self.xlen-1)\n",
    "        \n",
    "        if self.seed is not None: # fixed seed every time, not random maze\n",
    "            np.random.seed(self.seed)\n",
    "        \n",
    "        self.walls = np.random.rand(self.ylen, self.xlen) < 0.2\n",
    "        self.walls[self.player] = 0\n",
    "        self.walls[self.exit] = 0\n",
    "        \n",
    "        self.num_steps = 0\n",
    "        return self.get_observation()\n",
    "    \n",
    "    def get_observation(self): # SWAPPED FROM THE ABOVE ONE\n",
    "        # make the observation into the entire state??\n",
    "        # playerstate = self.player[1] + self.xlen*self.player[0]\n",
    "        # obsdict = {\n",
    "        #     \"player\" : playerstate,\n",
    "        #     \"walls\" : self.wallsstate\n",
    "        # }\n",
    "        # return obsdict\n",
    "        \n",
    "        # playerstate = 0*self.walls\n",
    "        # playerstate[self.player] = 1\n",
    "        # return np.concatenate((playerstate[None], \n",
    "        #                        self.walls[None]), axis=0).astype(int)\n",
    "        i, j = self.player\n",
    "\n",
    "        obs = []\n",
    "        obs.append(1 if i==0           else self.walls[i-1,j]) # up\n",
    "        obs.append(1 if i==self.ylen-1 else self.walls[i+1,j]) # down\n",
    "        obs.append(1 if j==0           else self.walls[i,j-1]) # left\n",
    "        obs.append(1 if j==self.xlen-1 else self.walls[i,j+1]) # right\n",
    "        return np.array(obs, dtype=int)\n",
    "        # 3x3 context, 8 observations\n",
    "        # wallsexit = self.walls.copy()\n",
    "        # wallspad = np.pad(wallsexit, 1, constant_values=1) # pad with 1 to simulate walls all around\n",
    "        # nearby = wallspad[self.player[0]:self.player[0]+3, self.player[1]:self.player[1]+3]\n",
    "        # nearbyflat = nearby.flatten()\n",
    "        # minus_middle = np.concatenate((nearbyflat[:4], nearbyflat[5:]))\n",
    "        # return minus_middle\n",
    "        # NW N NE W E SW S SE\n",
    "    \n",
    "    def step(self, action):\n",
    "        self.num_steps += 1\n",
    "        \n",
    "        if action == 0: # move up\n",
    "            new_loc = (self.player[0]-1, self.player[1])\n",
    "            \n",
    "        elif action == 1: # move down\n",
    "            new_loc = (self.player[0]+1, self.player[1])\n",
    "                \n",
    "        elif action == 2: # move left\n",
    "            new_loc = (self.player[0], self.player[1]-1)\n",
    "  \n",
    "        elif action == 3: # move right\n",
    "            new_loc = (self.player[0], self.player[1]+1)\n",
    "                \n",
    "        else:\n",
    "            raise Exception(\"Action must be {0,1,2,3}\")\n",
    "            \n",
    "        # update state if you are able to move\n",
    "        move_success = False\n",
    "        if 0 <= new_loc[0] < self.ylen and 0 <= new_loc[1] < self.xlen and not self.walls[new_loc]:\n",
    "            self.player = new_loc\n",
    "            move_success = True\n",
    "                \n",
    "        info = {\"player pos\" : self.player}\n",
    "        \n",
    "        # reward\n",
    "        distance = np.abs(self.player[0]-self.exit[0]) + np.abs(self.player[1]-self.exit[1])\n",
    "        reward = -distance\n",
    "        \n",
    "        # penalize walking into walls\n",
    "        if not move_success:\n",
    "            reward -= 5\n",
    "        \n",
    "        return self.get_observation(), reward, self.is_done(), info\n",
    "\n",
    "    \n",
    "    def is_done(self):\n",
    "        return self.player == self.exit or self.num_steps >= 500\n",
    "\n",
    "    def render(self):\n",
    "        for i in range(self.xlen):\n",
    "            for j in range(self.ylen):\n",
    "                if (i,j) == self.exit:\n",
    "                    print(\"E\", end=\"\")\n",
    "                elif (i,j) == self.player:\n",
    "                    print(\"P\", end=\"\")\n",
    "                elif self.walls[i,j]:\n",
    "                    print(\"X\", end=\"\")\n",
    "                else:\n",
    "                    print(\".\", end=\"\")\n",
    "                # print(\"O\", end=\"\")\n",
    "            print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8cbac29c-fa8b-45a4-9081-7768ff025f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "rme = RandomMazeEnvironment({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0053ea09-352e-4f07-86f0-f79d4a7cf216",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 0])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rme.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7bdfef18-af55-4a80-8f80-5acc736028de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P..X.\n",
      "X....\n",
      "...X.\n",
      ".....\n",
      "X...E\n"
     ]
    }
   ],
   "source": [
    "rme.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b9ba80d-57a5-4bfe-867f-ed488665d16c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1, 1, 1, 0]), -13, False, {'player pos': (0, 0)})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rme.step(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "10a5c9b7-7fe4-4ba9-98b1-1ecaaba50ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer_config_2 = copy.copy(trainer_config)\n",
    "# trainer_config_2[\"model\"] = {\"fcnet_hiddens\" : [64, 64]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "87345888-8305-4eeb-95e2-a1f7d5bdb8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_config_rme = {\n",
    "    # \"num_workers\": 0,\n",
    "    \"model\": {\n",
    "        \"fcnet_hiddens\": [64, 64],\n",
    "        \"fcnet_activation\": \"relu\",\n",
    "    },\n",
    "    \"evaluation_num_workers\": 1,\n",
    "    # \"create_env_on_driver\" : True,\n",
    "    \"log_level\" : \"ERROR\",\n",
    "    \"framework\" : \"torch\"\n",
    "    # \"_disable_preprocessor_api\" : True\n",
    "    # \"vf_loss_coef\" : 1/20_000 # make this small if the value function loss is big, only if vf_share_layers\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7c761db6-efcb-4efe-9745-eda1d144e11d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-06 09:04:07,443\tWARNING trainer.py:2279 -- You have specified 1 evaluation workers, but your `evaluation_interval` is None! Therefore, evaluation will not occur automatically with each call to `Trainer.train()`. Instead, you will have to call `Trainer.evaluate()` manually in order to trigger an evaluation run.\n",
      "2022-04-06 09:04:07,444\tINFO ppo.py:249 -- In multi-agent mode, policies will be optimized sequentially by the multi-GPU optimizer. Consider setting simple_optimizer=True if this doesn't work for you.\n",
      "2022-04-06 09:04:07,444\tINFO trainer.py:790 -- Current log_level is ERROR. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n"
     ]
    }
   ],
   "source": [
    "trainer = PPOTrainer(trainer_config_rme, env=RandomMazeEnvironment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3906f3cb-5fd3-407b-83af-32cc34f950f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.config[\"train_batch_size\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a95ce2-a4c1-4981-a5ad-219c459944f6",
   "metadata": {},
   "source": [
    "This is measure in individual time steps, per worker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d695d0a2-7a98-4723-bc5d-3a858f93d859",
   "metadata": {},
   "outputs": [],
   "source": [
    "rewards = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e2a7dde1-6392-48ab-b131-8a957d4283bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n"
     ]
    }
   ],
   "source": [
    "for iteration in range(30):\n",
    "    print(iteration)\n",
    "    out = trainer.train();\n",
    "    rewards.append(out['episode_reward_mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "27a8103b-3bcf-48fa-9f55-9729fc0241bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAD4CAYAAAAHHSreAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAA0DUlEQVR4nO3deXiU5bn48e+dnWwkhJB9YRUh7JFNcasIaCti3Tc89mjr0s0u2vo7bbX1dLPLsVV7bPWo3QAXKiqUoqIsIpIACYQtARIyIZA9Ifv2/P6YNzSShCwzk5lJ7s91zZWZ593uYcjceZ9VjDEopZRSnfm4OwCllFKeR5ODUkqpLjQ5KKWU6kKTg1JKqS40OSillOrCz90BOGr06NEmNTXV3WEopZRXyczMLDPGRPe03euTQ2pqKhkZGe4OQymlvIqIFJxvu8urlUTkWyJiRGS09VpE5BkRyRORbBGZ3WnflSKSaz1Wujo2pZRS3XPpnYOIJAFXAyc6FS8DJlqPecDzwDwRGQX8EEgHDJApIuuMMZWujFEppVRXrr5z+A3wXexf9h2WA68au0+ACBGJA5YAm4wxFVZC2AQsdXF8SimluuGy5CAiy4EiY0zWOZsSgMJOr21WWU/lSimlBplD1Uoi8h4Q282mx4HvY69ScjoRuR+4HyA5OdkVl1BKqWHNoeRgjLmqu3IRmQaMBbJEBCAR2C0ic4EiIKnT7olWWRFw+TnlH/Zw3ReAFwDS09N15kCllHIyl1QrGWP2GWPGGGNSjTGp2KuIZhtjTgHrgLutXkvzgWpjTDGwEbhaRCJFJBL7XcdGV8SnlFLq/NwxQno9cAzIA/4IPAhgjKkAfgzssh5PWmVKDQmNLW38dWcBza3t7g5FqV4NyiA46+6h47kBHuphv5eAlwYjJqUG2xu7bTy+dj/+vj7cnJ7U+wFKuZHOraTUIFm/rxiAv396opc9lXI/TQ5KDYLy2iY+OVZB3Mgg9pyo4mBxjbtDUuq8NDkoNQj+deA0be2Gp2+aQYCfD6v07kF5OE0OSg2C9fuKSYkKZuH4KK5Ji+XNPUU0NLe5OyyleqTJQSkXq6xr5uOj5VwzLQ4R4ba5yZxpbOVdqw1CKU+kyUEpF9tkVSldkxYHwNyxoxgXHaIN08qjaXJQysXW7y8madQI0hLCARARbp+bTGZBJYdPnXFzdEp1T5ODUi5UXd/C9rwyrkmzVyl1uGF2IgG+Pnr3oDyWJgelXGjTwdO0tBmWTYv7TPmokACWpsXy5m4bjS3aMK08jyYHpVxo/b5iEiJGMCNxZJdtt81Npqax9ezgOKU8iSYHpVykprGFrbmlLEuL/UyVUof540YxdrQ2TCvPpMlBKRd574C9Suma6XHdbrd3a01iV34luae1YVp5Fk0OSrnI+n2niBsZxMzEiB73+eLsRPx9hb9/WtjjPkq5gyYHpVzgTGMLW3JLWZoWi49P1yqlDlGhgSyZGssb2jCtPIwmB6Vc4INDJTS3tnPttO6rlDq7fW4y1Q0tbNivDdPKc2hyUMoF1u8rJiY8kNnJkb3uO39cFKlRwfx9p1YtKc+hyUEpJ6trauXDw6UsS4s7b5VSBx8f4da5yXyaX0FeiTZMK8+gyUEpJ/vgUAlNre0sS4vt8zE3ztGGaeVZNDko5WTr9xUzOjSQ9NRRfT5mdGggV2vDtPIgLk0OIvJVETkkIjki8otO5d8TkTwROSwiSzqVL7XK8kTkMVfGppQr1De3svlwCcvSYvHtQ5VSZ7fPTaaqvoWNOadcFJ1SfefnqhOLyBXAcmCGMaZJRMZY5VOAW4GpQDzwnohMsg57FlgM2IBdIrLOGHPAVTEq5WybD5XS2NLOsml9r1LqsGBcFClRwfxt5wmWz0xwQXRK9Z0r7xweAH5mjGkCMMaUWOXLgVXGmCZjzHEgD5hrPfKMMceMMc3AKmtfpbzG+v3FRIUEMG9sVL+P9fERbr0omZ3HKzhaWuuC6JTqO1cmh0nAIhHZKSIfichFVnkC0LnVzWaV9VTehYjcLyIZIpJRWlrqgtCV6r+G5jY2HyphyQCqlDrcOCcRPx/RNaaV2zmUHETkPRHZ381jOfYqq1HAfOA7wBrpbvaxATDGvGCMSTfGpEdHRzvjlEo57KMjJdQ3t/Vp4FtPosMCuXpqDK9n2mhq1YZp5T4OtTkYY67qaZuIPAC8aYwxwKci0g6MBoqApE67JlplnKdcKY+3ft8pIoP9mTe2772UunPb3GTW7zvFxpzTXDcj3knRKdU/rqxW+gdwBYDV4BwAlAHrgFtFJFBExgITgU+BXcBEERkrIgHYG63XuTA+pZymsaWN9w+eZsnUWPx8Hfu1unj8aJJGjeDPO/KdE5xSA+DK5PASME5E9mNvXF5p7HKANcAB4J/AQ8aYNmNMK/AwsBE4CKyx9lXK4205UkpdcxvXOFCl1MHHR7j34rHsyq8kI7/CCdEp1X8uSw7GmGZjzJ3GmDRjzGxjzAedtj1ljBlvjLnAGLOhU/l6Y8wka9tTropNKWdbv6+YiGB/Fozvfy+l7tx6UTKjQgJ47sOjTjmfUv2lI6SVclBTaxvvHSzh6ikx+DtYpdRhRIAv/7EwlQ8OlXCwuMYp51SqPzQ5KOWgbbll1Da1sswJVUqd3b0glZAAX57XuwflBpoclHLQ21knCQ/y4+Lxo5163pHB/twxP4V3sk9SUF7n1HMr1RtNDqpHJTWN/P6DXKrqm90disfalV/BW1kn+eKcRAL8nP/r9KVLxuLn48MLW445/dxKnY8mB9Wtj4+Wcc0z23j6X0e49+VdNDTrgKxz1Te38p3XskiIGMG3r77AJdeICQ/ii3MSeS3TRsmZRpdcQ6nuaHJQn9Hebvjd+7nc+aedjBzhx+PXXMiewiq++vfdtLa1uzs8j/KLfx4mv7yeX944g5BAl81hyVcuG0drWzsvbjvusmsodS5NDuqsirpm7nl5F7/adIQvzIhn3cOXcN+l43hyeRrvHSzh8bX7sQ94VzuOlvPyx/ncszDVad1Xe5ISFcK10+P56ycnqG5ocem1lOqgyUEBkFlQwbXPbOWTY+U8tSKN394y8+xfw3fNT+GrV05gdUYhv9l0xM2Rul9dUyvfeT2L1KhgvrvUNdVJ53rgsvHUNrXqqGk1aDQ5DHPGGP645Ri3/O8n+Pv68OYDC7ljXgrnzpH4yOJJ3JKexDMf5PHnTwrcFK1n+OmGgxRVNfD0TTMIDnBddVJnU+LDufyCaF7anq/tP2pQDM7/bOWRqhta+PZrWWw6cJolU2P45U0zCA/y73ZfEeGpFWmU1zXxg7f2Ex0awNI05/br9wbbcsv4yycnuG/R2H4tA+oMD14+gZv/dwdrMgpZuTB1UK/dkx+/c4BNB07j5yv4+/jg7yf4+fjg72v99PPB30fw8xUigwP4r89PcWn7jHIevXMYpvbZqvn877ay+VAJ//X5Kfzhzjk9JoYOfr4+/O622cxKiuBrq/byybHyQYrWM5xpbOG7r2cxLjqEb7mod9L5zB07ivSUSF7YcowWD+gc0NrWzt8/PcEIf18ujAsndXQwY8KCCAvyw8/Hh5a2dqobWjhV08ix0jpW7SpkTUZh7ydWHkFT+DC0do+NR1/fR1RoAKu/vIA5KZF9PnZEgC8vrryIG//wMfe9msFrX1nA5NhwF0brOZ569yCnahp544GFBPn7uiWGB68Yz70vZ7Bur31shTsdOnWG+uY2HrpyQp+mFl/x3HZe3VHAygWp+AxwMSQ1ePTOYZixVdbzvTf3MTM5gne/tqhfiaFDZEgAr35pHsEBvqx86VNslfUuiNSzbD5cwqpdhXz5svHMSu7/v5mzXHHBGCbHhvH8R0dpb3dvz7GOGWPT+/h/6J6FqRwvq2NLrq7e6A00OQwzP37nAILwm1tmMiokYMDnSYgYwSv3zqW+uY2VL31KZd3QHUVdXd/CY29kMykmlG9cNdGtsYgID1w+nrySWjYdPO3WWDIKKokbGUR8xIg+7b8sLY7osEBe3TG8OzR4C00Ow8jmwyVszDnNVz83gYQ+/kKfz+TYcP50dzqFlQ3c+8rQHUX9xDs5lNU286ubZhLo557qpM6unRZH8qhgnvvwqFvHnWQWVPbrzjPAz4fb5yaz+XCJzhXlBTQ5DBONLW38aF0O46JD+M9LxjntvPPGRfHMrTPZW1jFw38beqOoNx04zZu7i3jo8vFMSxzp7nAAe8eA+y8dR1ZhFTvc1CmgqKqB4urGPlcpdbhjXjK+Inr34AU0OQwTf9xyjILyep64bqrTJ4hbmhbHk8vTeP9QCd9fu2/IjKKurGvm+2v3cWFcOA9f6d7qpHPdOCeR6LBAt03nfba9oZ/deceEB7FsWhxrMgqpa2p1RWjKSTQ5DAOFFfX8fnMe106LY9HEaJdc4675KXztygmsybDx9L8Ou+Qag6m93fDDdTlU1jXzq5tmuGTGVUcE+fvypUvGsjW3jH226kG/fmZBJcEBvkyODev3sfcsTOFMYytr9xS5IDLlLNqVdRh48p0D+PoI/+/zF7r0Ot9cPInS2iae3XyU6NBA7rl4rEuv5whjDBV1zRRWNlBYUY+tsoHCyvqzz4sqG2hua+eRxZOYEu+ZXXXvmJfMc5vzeO7DPJ6/c86gXjuzoJJZyRH4DWDlu9nJkaQlhPPqjnzumJfcZTS+8gwuSw4iMhP4AxAEtAIPGmM+Ffv/hP8BrgHqgXuMMbutY1YC/886xU+MMa+4Kr7h4oNDp9l04DSPLZtM3EjHG6HPR0T48fI0ymqbeeKdA4wOC+Tz03vv/z6YXtx2nDW7CimsrKf+nAb0USEBJEWOYEp8OEumxjIpJrRP/ffdJSzIn7sXpPLsh3nkldQyYUzooFy3tqmVg8U1A65qExFWLkjlO69ns+NYOQudvEiScg5X3jn8AnjCGLNBRK6xXl8OLAMmWo95wPPAPBEZBfwQSAcMkCki64wxlS6McUizN0IfYHx0CPcO0l/x9lHUs7jrxZ08sjqLUSEBHvPL395ueHZzHhHB/txyURJJkcEkjQomadQIEiODCfXCaR3+4+JUXtp+nN9/kMtvb501KNfce6KKdtP38Q3d+cKMeP57/UFe+TjfY/5/qM9yZUWqATrux0cCJ63ny4FXjd0nQISIxAFLgE3GmAorIWwClrowviHvfz86xomKep5cnjaodeZB/r786e6LSB0dzP2vZpJzcvDrxLtz8FQNFXXNPHzFBH74hance8lYFk+JYXJsuFcmBoCo0EDump/CuqyTHC2tHZRrZhRUIAIzkyMGfI4gf19unZvMpgOnh8UgSm/kym+MbwC/FJFC4Gnge1Z5AtB5ghWbVdZTeRcicr+IZIhIRmmpjrbszonyep77MI/PT4/j4gmD/5fZyGB/Xrl3LuFBftzzf7sorHD/F8D2vDIAt/x7uNJ9l44j0M+X33+QNyjXyyyo5IKYsF7n4urNnfNTAPjLJyecEZZyMoeSg4i8JyL7u3ksBx4AvmmMSQK+CbzojIABjDEvGGPSjTHp0dGu6X3j7Z58J8feCH3tFLfFEDdyBK9+aS4tbe3c9eJOymqb3BYLwLa8ciaOCSUmPMitcTjb6NBA7lqQwlt7izjm4ruHtnbDnhNVpKc6PoVIQsQIrp4Sy6pdJ2hsGZoDKL2ZQ8nBGHOVMSatm8dbwErgTWvX14C51vMiIKnTaRKtsp7KVT+9d+A07x0s4RtXTSR2pHu/CCeMCePFlRdxqqaRe1/e5ba+7U2tbXx6vHzI3TV0uG/ROAL8fPj9ZtfePRw6VUNtUyvpKc6ZrnzlwlSq6ltYt/dk7zurQeXKaqWTwGXW8yuBXOv5OuBusZsPVBtjioGNwNUiEikikcDVVpnqh8aWNp54J4eJY0L5Dw/pSjonJZJnb59NzskavvKXTJpbB38U9e6CKhpb2rlkiCaH6LBA7pyXwj/2FHG8zHVTU2QW2PuHDGTCxu7MHzeKC2LCePnj/CEzeHKocGVyuA/4lYhkAf8N3G+VrweOAXnAH4EHAYwxFcCPgV3W40mrTPXDcx8epbCigSeWT8V/AH3QXeVzF8bw0xumsTW3jO+8nkVRVcOgfhlszyvD10eYN25wF+gZTPdfZt09uLDtISO/kpjwQBIjndMtWkS4e2EKB4prziYe5Rlc1kXDGLMN6DIyx9i/ER7q4ZiXgJdcFdNQl19Wxx8+Osp1M+I9snvgzelJlJ5p4pcbD/PW3pNEBPszJS6cqfHhTI0fydT4cMaODhnQwKrebMsrY0biSMIcbET1ZGPCgrhjXgovf5zPV6+cQOroEKdfI7OgkvSUUU4duLZiVgI/33CIlz/OH/TV9VTPvLP/nurCGMMTb+fg7yM8fq1rR0I74qErJnDpxGj22qo4cLKanJM1vLKj4GxVU6CfD5OthDElLpylabGMDg106JrVDS1k26p4+IoJzngLHu3Ll43jL58U8PvNeTx90wynnvtUdSNFVQ186RLnVlcGB/hxc3oSL3+cz+maxiHXYcBbaXLwci1t7WzYf4oXtx4jy1bN49dc6PG/XNMSR35mhtPWtnaOltaRc7KaAydryDlZwztZJ/nbzhO8llHIWw9f4tD1dh4rp90MvS6s3em4e3hlh/3uISXKeXcPGQX2Wl5ntTd0dveCVF7cfpy/flLAI25YglV1pcnBS1U3tLB61wle3p7PyepGxo4O4SfXp3H73GR3h9Zvfr4+XBAbxgWxYdww215mjOEPHx3j5/88xNHSWsZHD3xqiO15ZYzw93XrCm6D6SuXjeOvOwv4/Qd5/NKJdw8Z+ZWM8Pd1yVxTyVHBXHnBGP726QkeunKCR6ybMdx5Toul6pPCinqeeDuHhT99n/9ef4jkqGD+dHc67z9yGXfOTxkya/OKCDfMTkAEh7s5bssrY964UR43s6qrjAkP4ra5yby5p4gT5c4bfJhZUMmMpJEu6+hw98JUymqb2bDvlEvOr/pnePy2eDljDJkFFTzwl0wu++Vm/ryjgCVTY3nnq5ew6v4FXDUlZsgkhc5iwoOYPzaKdVknB9yzqbi6gaOldUO2C2tPHrh8PL4+wrNOGvdQ19TKgeIap41v6M6iCaMZNzqElz/Od9k1VN9pcvBwe05UsuK5j/ni8zvYnlfGly8bz7ZHr+TXt8wkLcEzViZzpetmxnO8rI79RTUDOn57nn2ltOHQ3tBZTHgQt89N5o3dNqdMXZJVWEVbu2GOE0ZG98THR7h7QQp7C6vIKqxy2XVU32hy8HA/XJeDrbKBJ5dPZcf3PsejSye7fdTzYFqWFou/r7Aua2CD5bfnlTE6NIALYvq/KI23+8pl4/ER59w9ZBRUImJfi8GVvjgnkZAAX17Ruwe30+TgwZpa2zhYXMONcxK5e0EqIV46c6gjIoIDuGxSNO9kF9Pe3r+qJWMM2/LKWDh+9JCsdutN7MggbpubxOuZjt89ZBZUMmlMGCNHuHacSFiQP1+ck8g72cVU1DW79Frq/DQ5eLCDxWdoaTPM8JCF7d3lCzPiKa5uZFd+/wbM55bUUnqmiYsnRLkoMs/3lcvtdw/PfTjwu4f2dsPuE5UurVLq7M75KTS3tbN6V2HvOw8xa/fY2HG03N1hAJocPFq2rQqA6UkRbo3D3RZPiWGEvy9vZfWv19JQnaK7P+JGjuCWi5J4LcM24HUTjpSc4UxjK3MGqSvwpJgw5o8bxV93FtDWz7tFb5Ztq+KRNVk89Lfd1DS2uDscTQ6eLKuwmtGhAcQPozaG7gQH+HHVlBg27Cumpa3vk/ZtzysjNSqYxMhgF0bn+R44e/dwdEDHZ+Tb5zxyxjTdfXX3glRslQ18eLhk0K7pTu3thh+8lUNYoB8Vdc08P8DPypk0OXiwbFsV0xMjdAF24LoZ8VTWt7Att6xP+7e0tfPJsYphfdfQIT5iBDdflMhrGYUUVTX0+/jMgkpGhwaSPGrwkuziKTHEhAfy6o6CQbumO72+28bewip+8IWprJiVwEvbjnNyAJ+VM2ly8FC1Ta3kldYyfZi3N3S4bFI0I0f4s66PVUvZtipqm1qH3fiGnjxwuX1eqd9uOtLvYzMKKkhPiRzUP1L8fX24bW4yHx0ppaDcdVOQe4LqhhZ+vuEQc1IiuWFWAt+6ehIGePpfh90alyYHD7W/qBpjYEZihLtD8QgBfj4sS4vlXzmnaGjufdWwbbnliMCC8cO3MbqzhIgR3HvJWF7LtLHpwOk+H1dS00hhRcOgVil1uG1uMn4+wl8+Gdp3D7/ZdISK+maeuG4qPj5CYmQw9148lrV7ithf5L711zU5eKizjdF653DWdTPiqWtu4/1DvX+5bc8rY1rCSCKCAwYhMu/wrcUXMDU+nO++nsXpmsY+HZPh5MV9+iMmPIglU2NZk2EbssuIHiyu4dUd+dwxL/kzg1ofvGI8ESP8+emGg25bBEmTg4fKslWTEDGCKAenqx5K5o2LYkxYYK9zLdU1tbL7RKW2N5wjwM+HZ26bRWNLO4+s2duncSMZ+ZUE+vkwNd49f6TcOT+F6oaWPlcnehNjDD98K4eRI/z59jkz0YYH+fO1z01ke145Hx4pdUt8mhw8VLatihlJetfQma+PcO30OD48XEp1Q89d/T49XkFru9H2hm6Mjw7lh1+Ywva8cv649Viv+2eeqGRGUoTbJi2cP24Uk2JCh2TV0rqsk3yaX8F3l07u9g73jnkppEYF89P1B2ntRy89Z9Hk4IEq6poprGhgurY3dHHdjHia29rZmNPzzJ3b88oI8PNxS1WIN7jloiSWpcXyy42Hz1ZfdqehuY2comq3/juKCHfNTyHbVs3eITTf0pnGFp569yDTE0dyc3pSt/sE+Pnw6NLJHDldy+uZtkGOUJODR9L2hp7NTIogeVQwb5+nmmFbXhkXpUYS5K9rAnRHRPjpDdOIDgvk66v2UtfU2u1+WbYqWtsN6W5OstfPSiAkwJdXd+S7NQ5n+t0HeZScaeKJ66bie56pXZamxTInJZJfbzrS4+fkKg4lBxG5SURyRKRdRNLP2fY9EckTkcMisqRT+VKrLE9EHutUPlZEdlrlq0Vk2LYkZtuqEYFpw2DW1f4SEa6bEc/2vDJKzzR12V56polDp85oe0MvIoID+M0tM8kvr+OJt3O63SfTjY3RnYUF+XPD7KEz31JeyRle2nacm9MTe12ASkT4/jUXUnKmqU/VgM7k6J3DfuAGYEvnQhGZAtwKTAWWAs+JiK+I+ALPAsuAKcBt1r4APwd+Y4yZAFQCX3IwNq+Vbati3OgQwoJcO8mZt7puZjztBt7N7nr38PFR+yA5bW/o3fxxUTx0+QTWZNh4p5t/y4z8CiaMCfWIHl93LUihubWdNRnePd+SMYYfrsshOMCXR5dO7tMxc1IiuWZaLC9sOUbJmb71MnMGh5KDMeagMaa7kRrLgVXGmCZjzHEgD5hrPfKMMceMMc3AKmC52EfXXAm8bh3/CnC9I7F5K2MMWbZqHd9wHpNiwpgcG9ZtD5bteWWMHOHvtt413ubrV01kZlIE33tz32fmXmpvN2QWVLq9SqnDpJgw5o31/vmWNuw/xfa8cr519QX96on43SWTaWlr5zebcl0Y3We5qs0hAeic4m1WWU/lUUCVMab1nPJuicj9IpIhIhmlpe7p5uUqp2oaKT3TpO0NvfjCjHh2n6j6zFTUxhi25ZaxcHzUeetx1b/5+/rwzK2zMAa+uXrv2S/evNJaahpb3V6l1NndC1IprGjgoyPeOd9SfXMrP3nnAJNjw7hjXv/Wek8dHcKd81NYvesER06fcVGEn9VrchCR90RkfzeP5YMRYHeMMS8YY9KNMenR0dHuCsMlsgrtIyKH+0ysvbluRjwAb3eqDskvr+dkdaO2N/RTclQwP75+KrvyK88uDPTvyfZctyxof109NYYxYYH82UvnW3pu81FOVjfy5PI0/AawDvfXrpxISKAfP9twyAXRddVrhMaYq4wxad083jrPYUVA5/5ZiVZZT+XlQISI+J1TPuxk26rw8xGmxIW7OxSPljQqmNnJEZ8ZELctT9sbBmrFrESunxnP/7yfS2ZBBZkFlUSFBJAa5Tkz2nbMt/ThkVJOlDu+9OlgOl5WxwtbjrFiVgJzxw4s4UaGBPDwFRP44FAJH+f1bQJKR7hqabF1wN9E5NdAPDAR+BQQYKKIjMX+5X8rcLsxxojIZuBG7O0QK4HzJZ8hK9tWzQWxYdoNsw+umxHPj94+wJHTZ5gUE8bHeWUkRIwgxYO+0LzJk9enkXmikq+v2osxMHuQJ9vri9vmJvP7zXn8dWcB37vmwkG//umaRvYXVbO/qIb9J6tpam0nMtifyOAARo7wtz8PCSAiOOBseUSwP0++nYO/r/C9ZX1rhO7JyoWpvLqjgKfWH+Tthy9x6QqHDiUHEVkB/A6IBt4Vkb3GmCXGmBwRWQMcAFqBh4wxbdYxDwMbAV/gJWNMRz+6R4FVIvITYA/woiOxeSNjDNm2Kq6dHu/uULzCtdPjefKdA6zbe5JvLp7Ex0fLWTI1xuO+0LxFeJA/v71lFjf/7w7a2g13L0hxd0hdxI4MYsnUGFZnFPLNxZNc9keUMYaT1Y3ss1WTc7LanhBO1pztPi0CY0eHEBboR35ZHZX1zZxpPP84hMevuZAx4Y6tzRLk78t3llzAN1bv5a2sIlbMSnTofOfjUHIwxqwF1vaw7SngqW7K1wPruyk/hr0307CVX15PTWPrsF8WtK+iwwJZOH4067JOsnhKDNUNLdre4KA5KZF843MT+dWmIx47o+1d81NZv+8Ub2ed5KYeRhcPVFFVA//1j/3sOVFJZb19ihZfH2HimFAunRhNWkI4aQkjmRIX3mVN99a2dqobWqisb6GqvpnK+hYq65upqm9GEO65ONUpMV43I54Xtx3n6Y1HWJYW57IEOfxWrPdg/x4ZHeHWOLzJdTPi+e4b2WfXSF44XpODox6+cgJL02KZGBPm7lC6NX/cKCaOsc+35Ozk8N/vHmTH0XKWz4xnasJI0uLDuTAuvE9fwH6+PkSFBrp8skwfH/vAuK+v2sOx0jqmxLumfVKnz/AgWYXVBPn7MCkm1N2heI0labEE+PqwMec0k2PDiA7TWWwdJSIemxjAmm9pQQpZtmqynDjfUratinf3FXPfpeP42Renc9f8FGYle+Y0LAvGR7Hlu1e4LDGAJgePkm2rYmr8yAF1cxuuRo7w5/IL7N2ZtZfS8LHCmm/pz06crfUX/zzMqJAA7ls01mnndCVXJy39FvIQrW3t7D9ZrYPfBuD6WfbxkpdOGlpjXlTPwoL8WTE7gXVZJ7udY6u/tuWWsS2vjIeumKDT1lg0OXiI3JJaGlvaddqMAViWFssbDyxg0US9cxhOvnTJOAB+8NZ+h1ZLM8bwi42HSIgYwZ3z+zdyeSjT5OAhdJrugRMR5qSM0i6sw8zY0SF886pJbNh/inf3FQ/4PBv2nyLbVs03F08i0M/z2hfcRZODh8iyVRMW5EdqVIi7Q1HKa9y3aCwzkiL4wVs5lNX2v3qpta2dpzceZlJMKCtm9Tid27CkycFDZNuqmJ440qUjHpUaavx8ffjVTdOpbWrlv/7R/+qlNRk2jpXV8Z0lk3WyxnNocvAAjS1tHCo+o+MblBqACWPCzlYvvZPd9+qlhuY2/uf9I8xJieSqC8e4MELvpMnBAxwsrqG13ejIaKUG6N/VS/v73Hvp5Y/zOV3TxKNLJ2t7VTc0OXiAbJs1TbfeOSg1IB3VS3XNbX2qXqqub+H5D/O4cvKYAc+SOtRpcvAAWbYqRocGEjfSsUm5lBrOOqqX/pnTe/XS8x8d5UxTK99ZcsEgRed9NDl4gGxbNTMSR+qtrVIO6kv10qnqRv5v+3Gun5nAhbpuSo80ObhZbVMrR0trtUpJKSfoS/XS/7yfS7sxPLJ4khsi9B6aHNxsn60aY2B6kjZGK+UM56teOlZay5qMQu6Yl0LSKF0U6nw0ObhZx8honTZDKefpqXrpV/86QqCfDw9dMcGN0XkHTQ5ulm2rJjFyBKNCAtwdilJDRnfVSx1Tcv/nonE6tXsfaHJwsyxbld41KOUCnauX3s4u9ropud1Nk4Mbldc2Yats0Mn2lHKRjuqlR1/P1im5+8mh5CAiN4lIjoi0i0h6p/LFIpIpIvusn1d22jbHKs8TkWfE6r8pIqNEZJOI5Fo/Ix2JzRtkF+ngN6VcqaN6qc0YEiJGcMc8nZK7rxy9c9gP3ABsOae8DPiCMWYasBL4c6dtzwP3AROtx1Kr/DHgfWPMROB96/WQll1YjQhM0zsHpVxmwpgw/vqf83j5Py7yyCU/PZWfIwcbYw4CXQZvGWP2dHqZA4wQkUBgFBBujPnEOu5V4HpgA7AcuNw65hXgQ+BRR+LzdNm2KsZHhxIa6NDHoJTqxUWpOkVGfw1Gm8MXgd3GmCYgAbB12mazygBijDEdnZJPATE9nVBE7heRDBHJKC0tdUXMLmeMIbtIlwVVSnmmXv9kFZH3gNhuNj1ujHmrl2OnAj8Hru5PUMYYIyI9zpxljHkBeAEgPT194OsDutGpmkZKzzRpTyWllEfqNTkYY64ayIlFJBFYC9xtjDlqFRcBiZ12S7TKAE6LSJwxplhE4oCSgVzXW2QVdjRG652DUsrzuKRaSUQigHeBx4wx2zvKrWqjGhGZb/VSuhvouPtYh73xGuvnee9KvF22rQo/H9GJv5RSHsnRrqwrRMQGLADeFZGN1qaHgQnAD0Rkr/XoWGrpQeBPQB5wFHtjNMDPgMUikgtcZb0esrJt1UyOC9PeE0opj+Rob6W12KuOzi3/CfCTHo7JANK6KS8HPudIPN6iYyj/52fEuzsUpZTqlo6QdoOjpbXUNLbqsqBKKY+lycENntt8lAA/Hy6dFO3uUJRSqluaHAbZPls1b+4p4t6LxxI3coS7w1FKqW5pchhExhh+8u4BRoUE8OAV490djlJK9UiTwyDadOA0O49X8M2rJhKuM0MqpTyYJodB0tLWzs82HGJ8dAi3zdWZIZVSnk2TwyD5284THCur4/vXXIifr/6zK6U8m35LDYLqhhZ++94RFoyL4srJY3o/QCml3EyTwyB4bnMeVQ0tPH7thV2mN1dKKU+kycHFCivq+b/t+dwwK5G0BB30ppTyDpocXOwXGw/j4wPfXjLJ3aEopVSfaXJwoT0nKnk76yT3LRqnA96UUl5Fk4OL2Ae8HWR0aCBfvkwHvCmlvIsmBxfZsP8UmQWVfOvqSbpGtFLK62hycIHmVvuAtwtiwrg5Pcnd4SilVL9pcnCBV3fkc6Kinu9feyG+Ptp1VSnlfTQ5OFlVfTO/+yCPRRNHc5lOya2U8lKaHJzsmffzONNoH/CmlFLeSpODE+WX1fHnT/K5OT2JybHh7g5HKaUGzKHkICI3iUiOiLSLSHo325NFpFZEvt2pbKmIHBaRPBF5rFP5WBHZaZWvFpEAR2Jzh19vOoK/rw+PXK0D3pRS3s3RO4f9wA3Alh62/xrY0PFCRHyBZ4FlwBTgNhGZYm3+OfAbY8wEoBL4koOxDary2iY27C/mlouSGBMW5O5wlFLKIQ4lB2PMQWPM4e62icj1wHEgp1PxXCDPGHPMGNMMrAKWi302uiuB1639XgGudyS2wbZ2TxEtbYZbL9K1GpRS3s8lbQ4iEgo8CjxxzqYEoLDTa5tVFgVUGWNazynv6fz3i0iGiGSUlpY6L/ABMsawelchM5MiuCA2zN3hKKWUw3pNDiLynojs7+ax/DyH/Qh7FVGt0yLtxBjzgjEm3RiTHh3t/u6iewqryC2p5daLdMCbUmpo6HVeB2PMVQM47zzgRhH5BRABtItII5AJdP4GTQSKgHIgQkT8rLuHjnKvsPrTQoIDfPn8jHh3h6KUUk7hkkl/jDGLOp6LyI+AWmPM70XED5goImOxf/nfCtxujDEishm4EXs7xErgLVfE5my1Ta28nX2Sz0+P0zmUlFJDhqNdWVeIiA1YALwrIhvPt791V/AwsBE4CKwxxnQ0WD8KPCIiedjbIF50JLbB8m72Seqb27hFG6KVUkOIQ3/qGmPWAmt72edH57xeD6zvZr9j2HszeZVVuwqZMCaU2ckR7g5FKaWcRkdIO+DI6TPsOVHFrRcl6drQSqkhRZODA1bvKsTfV1gxq8det0op5ZU0OQxQU2sba/cUsXhKDFGhge4ORymlnEqTwwC9d6CEirpmXcxHKTUkaXIYoNUZhcSPDGLRRPcPwlNKKWfT5DAAtsp6tuaWclN6kq70ppQakjQ5DMDrmTYAbkpPdHMkSinlGpoc+qmt3fBaho1LJowmMTLY3eEopZRLaHLop+15ZRRVNXCLTrKnlBrCNDn00+pdhUQG+7N4Soy7Q1FKKZfR5NAPFXXN/OvAKVbMSiTQz9fd4SillMtocuiHN3fbaGkzWqWklBryNDn0ka72ppQaTjQ59JGu9qaUGk40OfSRrvamlBpONDn0ga72ppQabjQ59IGu9qaUGm40OfTBal3tTSk1zGhy6MXR0lp262pvSqlhxqHkICI3iUiOiLSLSPo526aLyA5r+z4RCbLK51iv80TkGbG+cUVklIhsEpFc62ekI7E5y+ZDJQAsmxbn5kiUUmrwOHrnsB+4AdjSuVBE/IC/AF8xxkwFLgdarM3PA/cBE63HUqv8MeB9Y8xE4H3rtdttzS1jfHQICREj3B2KUkoNGoeSgzHmoDHmcDebrgayjTFZ1n7lxpg2EYkDwo0xnxhjDPAqcL11zHLgFev5K53K3aaxpY2dx8u5dJIu6KOUGl5c1eYwCTAislFEdovId63yBMDWaT+bVQYQY4wptp6fAnqc2U5E7heRDBHJKC0tdXbsZ2XkV9LY0s6lutqbUmqY6bXTvoi8B8R2s+lxY8xb5znvJcBFQD3wvohkAtV9CcoYY0TEnGf7C8ALAOnp6T3u56gtuaUE+Powb9woV11CKaU8Uq/JwRhz1QDOawO2GGPKAERkPTAbeztE5+XTEoEi6/lpEYkzxhRb1U8lA7iuU205Ukp6aiTBATrwTSk1vLiqWmkjME1Egq3G6cuAA1a1UY2IzLd6Kd0NdNx9rANWWs9Xdip3i5KaRg6dOqPtDUqpYcnRrqwrRMQGLADeFZGNAMaYSuDXwC5gL7DbGPOuddiDwJ+APOAosMEq/xmwWERygaus126zNbcMgEUTR7szDKWUcguH6kuMMWuBtT1s+wv2aqRzyzOAtG7Ky4HPORKPM23NLWV0aAAXxoa7OxSllBp0OkK6G+3thq25ZSyaGI2Pj46KVkoNP5ocunGguIbyumatUlJKDVuaHLqxJdc+duISTQ5KqWFKk0M3th4p48K4cMaEBbk7FKWUcgtNDueoa2olo6CCSyfpXYNSavjS5HCOncfLaWkzOmWGUmpY0+Rwji1Hygjy92FOikfMGK6UUm6hyeEcW3JLmT8uiiB/X3eHopRSbqPJoRNbZT3HSutYpFVKSqlhTpNDJx1TZlymjdFKqWFOk0MnW3NLiRsZxPjoUHeHopRSbqXJwdLa1s623DIunRiNtay1UkoNW5ocLNlF1dQ0trJIq5SUUkqTQ4ctR0oRgYvHa3JQSilNDpatuWVMT4wgMiTA3aEopZTbaXIAqhta2FtYxaU60Z5SSgGaHADYcbSMtnajS4IqpZRFkwPw0ZEyQgP9mJkU4e5QlFLKIwz75GCMYcuRUhaOj8Lfd9j/cyilFOBgchCRm0QkR0TaRSS9U7m/iLwiIvtE5KCIfK/TtqUiclhE8kTksU7lY0Vkp1W+WkQGpWU4v7yeoqoGFmmVklJKneXon8r7gRuALeeU3wQEGmOmAXOAL4tIqoj4As8Cy4ApwG0iMsU65ufAb4wxE4BK4EsOxtYnW47YV33TxmillPo3h5KDMeagMeZwd5uAEBHxA0YAzUANMBfIM8YcM8Y0A6uA5WIfknwl8Lp1/CvA9Y7E1ldbc0tJiQomJSpkMC6nlFJewVWV7K8DdUAxcAJ42hhTASQAhZ32s1llUUCVMab1nPJuicj9IpIhIhmlpaUDDrK5tZ0dR8tZpHcNSin1GX697SAi7wGx3Wx63BjzVg+HzQXagHggEthqnccpjDEvAC8ApKenm4GeZ/eJSuqa23TVN6WUOkevycEYc9UAzns78E9jTAtQIiLbgXTsdw1JnfZLBIqAciBCRPysu4eOcpfacqQUPx9hwfgoV19KKaW8iquqlU5gb0NAREKA+cAhYBcw0eqZFADcCqwzxhhgM3CjdfxKoKe7EqfZmlvG7ORIwoL8XX0ppZTyKo52ZV0hIjZgAfCuiGy0Nj0LhIpIDvaE8H/GmGzrruBhYCNwEFhjjMmxjnkUeERE8rC3QbzoSGy9Ka9tYv/Jam1vUEqpbvRarXQ+xpi1wNpuymuxd2ft7pj1wPpuyo9hb6sYFNvyyjAGHd+glFLdGLZDgrfmlhER7M+0hJHuDkUppTyOQ3cO3mxcdAi3hibj66Orviml1LmGbXJ48PIJ7g5BKaU81rCtVlJKKdUzTQ5KKaW60OSglFKqC00OSimlutDkoJRSqgtNDkoppbrQ5KCUUqoLTQ5KKaW6EPuEqN5LREqBggEePhooc2I4nmCovSd9P55vqL2nofZ+oPv3lGKM6XFyOa9PDo4QkQxjTLq743Cmofae9P14vqH2noba+4GBvSetVlJKKdWFJgellFJdDPfk8IK7A3CBofae9P14vqH2noba+4EBvKdh3eaglFKqe8P9zkEppVQ3NDkopZTqYtgmBxFZKiKHRSRPRB5zdzyOEpF8EdknIntFJMPd8QyEiLwkIiUisr9T2SgR2SQiudbPSHfG2B89vJ8fiUiR9TntFZFr3Bljf4hIkohsFpEDIpIjIl+3yr35M+rpPXnl5yQiQSLyqYhkWe/nCat8rIjstL7vVotIQK/nGo5tDiLiCxwBFgM2YBdwmzHmgFsDc4CI5APpxhivHbwjIpcCtcCrxpg0q+wXQIUx5mdWEo80xjzqzjj7qof38yOg1hjztDtjGwgRiQPijDG7RSQMyASuB+7Bez+jnt7TzXjh5yQiAoQYY2pFxB/YBnwdeAR40xizSkT+AGQZY54/37mG653DXCDPGHPMGNMMrAKWuzmmYc8YswWoOKd4OfCK9fwV7L+4XqGH9+O1jDHFxpjd1vMzwEEgAe/+jHp6T17J2NVaL/2thwGuBF63yvv0GQ3X5JAAFHZ6bcOL/0NYDPAvEckUkfvdHYwTxRhjiq3np4AYdwbjJA+LSLZV7eQ1VTCdiUgqMAvYyRD5jM55T+Cln5OI+IrIXqAE2AQcBaqMMa3WLn36vhuuyWEousQYMxtYBjxkVWkMKcZeB+rt9aDPA+OBmUAx8Cu3RjMAIhIKvAF8wxhT03mbt35G3bwnr/2cjDFtxpiZQCL2WpLJAznPcE0ORUBSp9eJVpnXMsYUWT9LgLXY/1MMBaeteuGO+uESN8fjEGPMaeuXtx34I172OVn12G8AfzXGvGkVe/Vn1N178vbPCcAYUwVsBhYAESLiZ23q0/fdcE0Ou4CJVgt+AHArsM7NMQ2YiIRYjWmISAhwNbD//Ed5jXXASuv5SuAtN8bisI4vUcsKvOhzsho7XwQOGmN+3WmT135GPb0nb/2cRCRaRCKs5yOwd7o5iD1J3Gjt1qfPaFj2VgKwuqb9FvAFXjLGPOXeiAZORMZhv1sA8AP+5o3vR0T+DlyOfXrh08APgX8Aa4Bk7FOz32yM8YpG3h7ez+XYqyoMkA98uVN9vUcTkUuArcA+oN0q/j72Onpv/Yx6ek+34YWfk4hMx97g7Iv9j/81xpgnre+IVcAoYA9wpzGm6bznGq7JQSmlVM+Ga7WSUkqp89DkoJRSqgtNDkoppbrQ5KCUUqoLTQ5KKaW60OSglFKqC00OSimluvj/N39j8EdViwgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(rewards);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "09fbfb57-e202-4280-8081-1679048df783",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(out[\"hist_stats\"][\"episode_reward\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cea043e-9dc7-4e80-94cd-764ab2deb153",
   "metadata": {},
   "source": [
    "^ number of episodes in one call to `trainer.train()`\n",
    "\n",
    "Keeping the last 100 in memory for a moving average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "94a09a1d-3ad9-45e6-b5e4-b5a46465c83f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'evaluation': {'episode_reward_max': -28.0,\n",
       "  'episode_reward_min': -6500.0,\n",
       "  'episode_reward_mean': -705.6,\n",
       "  'episode_len_mean': 63.3,\n",
       "  'episode_media': {},\n",
       "  'episodes_this_iter': 10,\n",
       "  'policy_reward_min': {},\n",
       "  'policy_reward_max': {},\n",
       "  'policy_reward_mean': {},\n",
       "  'custom_metrics': {},\n",
       "  'hist_stats': {'episode_reward': [-51.0,\n",
       "    -6500.0,\n",
       "    -89.0,\n",
       "    -28.0,\n",
       "    -53.0,\n",
       "    -39.0,\n",
       "    -43.0,\n",
       "    -75.0,\n",
       "    -150.0,\n",
       "    -28.0],\n",
       "   'episode_lengths': [14, 500, 22, 8, 12, 10, 11, 19, 29, 8]},\n",
       "  'sampler_perf': {'mean_raw_obs_processing_ms': 0.053394104027973746,\n",
       "   'mean_inference_ms': 0.267953150655945,\n",
       "   'mean_action_processing_ms': 0.0174684855464129,\n",
       "   'mean_env_wait_ms': 0.020346430949984288,\n",
       "   'mean_env_render_ms': 0.0},\n",
       "  'off_policy_estimator': {},\n",
       "  'timesteps_this_iter': 0}}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "18ca07c4-22cc-4b83-9acd-2b420e751e4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PX...\n",
      ".X..X\n",
      ".....\n",
      "...X.\n",
      "X...E\n"
     ]
    }
   ],
   "source": [
    "rme = RandomMazeEnvironment({})\n",
    "obs = rme.reset() \n",
    "rme.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1f5e7c49-db20-442e-b054-a358362d0050",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".X...\n",
      "PX..X\n",
      ".....\n",
      "...X.\n",
      "X...E\n",
      "\n",
      "action: down\n",
      "reward: -7\n",
      "done: False\n",
      "obs: [0 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "action = trainer.compute_single_action(input_dict={\"obs\": obs})#, explore=False)\n",
    "res = rme.step(action)\n",
    "obs = res[0]\n",
    "rme.render()\n",
    "\n",
    "print(\"\\naction:\", action_names[action])\n",
    "print(\"reward:\", res[1])\n",
    "print(\"done:\", res[2])\n",
    "print(\"obs:\", obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a0146852-4768-419d-a3fb-966ae7d17978",
   "metadata": {},
   "outputs": [],
   "source": [
    "policy = trainer.get_policy()\n",
    "model = policy.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "50c3e584-f28c-4b50-8ff2-e7752568aab5",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'float'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/f5/138zmtfd159g5x_f1t80qr440000gp/T/ipykernel_4389/757805685.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"obs\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mobs\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/rllib/lib/python3.8/site-packages/ray/rllib/models/modelv2.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, input_dict, state, seq_lens)\u001b[0m\n\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 243\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrestored\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_lens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSampleBatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/rllib/lib/python3.8/site-packages/ray/rllib/models/torch/fcnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_dict, state, seq_lens)\u001b[0m\n\u001b[1;32m    120\u001b[0m                 \u001b[0mstate\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensorType\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m                 seq_lens: TensorType) -> (TensorType, List[TensorType]):\n\u001b[0;32m--> 122\u001b[0;31m         \u001b[0mobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"obs_flat\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_last_flat_in\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hidden_layers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_last_flat_in\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'float'"
     ]
    }
   ],
   "source": [
    "# model_output = model({\"obs\": torch.from_numpy(obs)})[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3d1b1569-a125-4380-962f-6d6c988bc64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6033a529-8087-48a9-8336-a29b3adf917b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FullyConnectedNetwork(\n",
      "  (_logits): SlimFC(\n",
      "    (_model): Sequential(\n",
      "      (0): Linear(in_features=64, out_features=4, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (_hidden_layers): Sequential(\n",
      "    (0): SlimFC(\n",
      "      (_model): Sequential(\n",
      "        (0): Linear(in_features=8, out_features=64, bias=True)\n",
      "        (1): ReLU()\n",
      "      )\n",
      "    )\n",
      "    (1): SlimFC(\n",
      "      (_model): Sequential(\n",
      "        (0): Linear(in_features=64, out_features=64, bias=True)\n",
      "        (1): ReLU()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (_value_branch_separate): Sequential(\n",
      "    (0): SlimFC(\n",
      "      (_model): Sequential(\n",
      "        (0): Linear(in_features=8, out_features=64, bias=True)\n",
      "        (1): ReLU()\n",
      "      )\n",
      "    )\n",
      "    (1): SlimFC(\n",
      "      (_model): Sequential(\n",
      "        (0): Linear(in_features=64, out_features=64, bias=True)\n",
      "        (1): ReLU()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (_value_branch): SlimFC(\n",
      "    (_model): Sequential(\n",
      "      (0): Linear(in_features=64, out_features=1, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20160f3e-ec04-4776-9b6d-adaa0a33d0f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab22e41b-8557-423a-8bc6-6868e7ad4508",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b94b57b-aeea-40d0-85fc-a83d60548fef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "725d0186-654d-4ae3-b804-6f58d869a403",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(trainer.get_policy().get_weights().values())[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "79294b81-830a-4e21-a556-c9d5ab2a8982",
   "metadata": {},
   "outputs": [],
   "source": [
    "# q_values = model.get_q_value_distributions(model_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "672dfcfa-252e-4074-a0f9-084e9d41990f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# q_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d2626e7-0ccc-4901-9b1c-444ef16834e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dda28df1-1e40-47c4-a8c1-f32ff54d388d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_output' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/f5/138zmtfd159g5x_f1t80qr440000gp/T/ipykernel_4389/2501196030.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpolicy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdist_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model_output' is not defined"
     ]
    }
   ],
   "source": [
    "dist = policy.dist_class(model_output, model) \n",
    "dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "080e58fe-c5d6-4b61-b186-8058840e3051",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dist' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/f5/138zmtfd159g5x_f1t80qr440000gp/T/ipykernel_4389/3498768396.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'dist' is not defined"
     ]
    }
   ],
   "source": [
    "dist.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c2c0b3-183d-41bb-bce3-89e25caa6625",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist.dist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2be3ba1-aa3b-478e-855b-d300ec19be32",
   "metadata": {},
   "source": [
    "## Questions for Sven\n",
    "\n",
    "- How many episodes are actually getting run during training/evaluation? Only 10?\n",
    "  - It's complicated for training, but the batch size is measured in time steps (rather than episodes) so it also depends on episode length\n",
    "- `compute_action` vs `compute_single_action` \n",
    "  - Use `compute_single_action`\n",
    "- Can we go through the results of `print(model)` and understand why it looks the way it does?\n",
    "  - for Pytorch specifically, the layers are shown alphabetically and not in order (it only gets linked up in the call to `forward`)\n",
    "- How to get q values from `ComplexInputNetwork`?\n",
    "  - Don't use `ComplexInputNetwork`, avoid at all costs\n",
    "- What happens if you don't call `ray.init()` - the code still seems to run?\n",
    "- DQN vs PPO\n",
    "  - DQN more interpretable if you dig into the model, PPO more complicated.\n",
    "  - PPO learns action probabilities, will sample from this distribution by default\n",
    "- Is it fine to call `ray.init(ignore_reinit_error=True)` repeatedly?\n",
    "  - Yes\n",
    "- Why does `episode_reward_mean` not get better with more iterations? Is it because we've reaching the \"ceiling\" given the environment/model?\n",
    "  - Wasn't working at all with `MultiBinary`\n",
    "- What would be your next step to improve performance here? Ideas...\n",
    "  - Reward crafting\n",
    "  - Observation crafting\n",
    "  - Model/algo tuning / ray tune\n",
    "  - More iterations (how do you decide this? look for a plateau? results are generally quite noisy, I guess due to the randomness in the env)\n",
    "  - ...?\n",
    "- Higher-level question: in my google doc I have a list of envs for the tuned examples - which ones would be good for the course? can they be rendered?\n",
    "- Can I reuse recsim material from Sven's tutorial in the course? (And if so, do we think it's a good idea)\n",
    "- Ok to do the whole course with the Python API instead of the CLI?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "682312f9-ba07-4a99-ad73-96d56bc1fdd2",
   "metadata": {},
   "source": [
    "Things that seem to have magically fixed themselves:\n",
    "\n",
    "- Why does it say episode lengths are always 500 when it clearly seems to work (below)?\n",
    "- When I do `dist.sample()`, why do I get numbers larger than 3?\n",
    "- And, why is `model_output` size 64 instead of 4?\n",
    "\n",
    "I wonder why this was happening before... could it have been with `DQN`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805d5e8d-2de0-40ad-a9e4-55a865b1db60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f6dc77-a789-4cd2-9f86-95c3920c639c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e8d72d-55bc-4954-b429-5b4bcb566407",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e4cbb7-ca08-4fe7-98c8-832331434c7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bf563cb9-e516-49d4-b022-910c49d1e696",
   "metadata": {},
   "source": [
    "Idea: give the agent an action that says \"give up\", take a reward hit, but move on.\n",
    "So basically, see if they can figure out if it's unsolvable."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:rllib]",
   "language": "python",
   "name": "conda-env-rllib-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
